<?xml version="1.0" encoding="UTF-8"?><rss version="2.0"
	xmlns:content="http://purl.org/rss/1.0/modules/content/"
	xmlns:dc="http://purl.org/dc/elements/1.1/"
	xmlns:atom="http://www.w3.org/2005/Atom"
	xmlns:sy="http://purl.org/rss/1.0/modules/syndication/"
	
	xmlns:georss="http://www.georss.org/georss"
	xmlns:geo="http://www.w3.org/2003/01/geo/wgs84_pos#"
	
	>
<channel>
	<title>
	Comments on: An argument for using mysqldump	</title>
	<atom:link href="https://shlomi-noach.github.io/blog/mysql/an-argument-for-using-mysqldump/feed" rel="self" type="application/rss+xml" />
	<link>https://shlomi-noach.github.io/blog/mysql/an-argument-for-using-mysqldump</link>
	<description>Blog by Shlomi Noach</description>
	<lastBuildDate>Thu, 02 May 2013 17:42:11 +0000</lastBuildDate>
	<sy:updatePeriod>
	hourly	</sy:updatePeriod>
	<sy:updateFrequency>
	1	</sy:updateFrequency>
	<generator>https://wordpress.org/?v=5.3.3</generator>
			<item>
				<title>
				By: Sherzod Odinaev				</title>
				<link>https://shlomi-noach.github.io/blog/mysql/an-argument-for-using-mysqldump/comment-page-1#comment-204059</link>
		<dc:creator><![CDATA[Sherzod Odinaev]]></dc:creator>
		<pubDate>Thu, 02 May 2013 17:42:11 +0000</pubDate>
		<guid isPermaLink="false">https://shlomi-noach.github.io/blog/?p=3080#comment-204059</guid>
					<description><![CDATA[I am couple years late to this conversation, but the technique I used to speed up mysqldump was to  backup tables by groups, and run them simultaneously. If I had 1K tables, I would split them into group of 50 tables (where a group has at least one of the largest tables), process them in parallel by piping to gzip. Couple hundred Gs in 30 minutes.]]></description>
		<content:encoded><![CDATA[<p>I am couple years late to this conversation, but the technique I used to speed up mysqldump was to  backup tables by groups, and run them simultaneously. If I had 1K tables, I would split them into group of 50 tables (where a group has at least one of the largest tables), process them in parallel by piping to gzip. Couple hundred Gs in 30 minutes.</p>
]]></content:encoded>
						</item>
						<item>
				<title>
				By: Log Buffer #207, A Carnival of the Vanities for DBAs &#124; The Pythian Blog				</title>
				<link>https://shlomi-noach.github.io/blog/mysql/an-argument-for-using-mysqldump/comment-page-1#comment-21601</link>
		<dc:creator><![CDATA[Log Buffer #207, A Carnival of the Vanities for DBAs &#124; The Pythian Blog]]></dc:creator>
		<pubDate>Fri, 26 Nov 2010 15:41:07 +0000</pubDate>
		<guid isPermaLink="false">https://shlomi-noach.github.io/blog/?p=3080#comment-21601</guid>
					<description><![CDATA[[...] Noach shed a positive light on mysqldump in response to Morgan&#8217;s blog post. Even though he agrees with some of Morgan&#8217;s [...]]]></description>
		<content:encoded><![CDATA[<p>[&#8230;] Noach shed a positive light on mysqldump in response to Morgan&#8217;s blog post. Even though he agrees with some of Morgan&#8217;s [&#8230;]</p>
]]></content:encoded>
						</item>
						<item>
				<title>
				By: shlomi				</title>
				<link>https://shlomi-noach.github.io/blog/mysql/an-argument-for-using-mysqldump/comment-page-1#comment-20939</link>
		<dc:creator><![CDATA[shlomi]]></dc:creator>
		<pubDate>Mon, 15 Nov 2010 08:15:15 +0000</pubDate>
		<guid isPermaLink="false">https://shlomi-noach.github.io/blog/?p=3080#comment-20939</guid>
					<description><![CDATA[Morgan,

&quot;...A lot of this issue probably comes from actually *running mysqldump*...&quot;
Not sure what you meant, but I was referring to three distinct incidents I had, where innobackup/xtrabackup failed on backup. In two cases, it was (probably) because of tables unlisted in the data dictionary.
Either the backup would fail (consistently) halfway through, or the restore would fail halfway through.
On another case I would get (consistently) duplicate key errors on replication slave set up with innobackup (granted, this was almost 2 years ago).

Just so no one gets me wrong, what I&#039;m saying is:
- XtraBackup is a great tool and I&#039;m using it a LOT. Customers are always surprised to find out how easy it is to take a hot backup.
- It is susceptible to bugs, either withing the backup code itself, as well as to InnoDB code, or inconsistencies within file system.
- LVM based backups, while not as lightweight as XtraBackup in my experience, are not susceptible to such bugs.
- mysqldump just works, with the intolerable runtimes on large data sets.]]></description>
		<content:encoded><![CDATA[<p>Morgan,</p>
<p>&#8220;&#8230;A lot of this issue probably comes from actually *running mysqldump*&#8230;&#8221;<br />
Not sure what you meant, but I was referring to three distinct incidents I had, where innobackup/xtrabackup failed on backup. In two cases, it was (probably) because of tables unlisted in the data dictionary.<br />
Either the backup would fail (consistently) halfway through, or the restore would fail halfway through.<br />
On another case I would get (consistently) duplicate key errors on replication slave set up with innobackup (granted, this was almost 2 years ago).</p>
<p>Just so no one gets me wrong, what I&#8217;m saying is:<br />
&#8211; XtraBackup is a great tool and I&#8217;m using it a LOT. Customers are always surprised to find out how easy it is to take a hot backup.<br />
&#8211; It is susceptible to bugs, either withing the backup code itself, as well as to InnoDB code, or inconsistencies within file system.<br />
&#8211; LVM based backups, while not as lightweight as XtraBackup in my experience, are not susceptible to such bugs.<br />
&#8211; mysqldump just works, with the intolerable runtimes on large data sets.</p>
]]></content:encoded>
						</item>
						<item>
				<title>
				By: Morgan Tocker				</title>
				<link>https://shlomi-noach.github.io/blog/mysql/an-argument-for-using-mysqldump/comment-page-1#comment-20766</link>
		<dc:creator><![CDATA[Morgan Tocker]]></dc:creator>
		<pubDate>Thu, 11 Nov 2010 16:24:18 +0000</pubDate>
		<guid isPermaLink="false">https://shlomi-noach.github.io/blog/?p=3080#comment-20766</guid>
					<description><![CDATA[@Daniël - nope.  Maybe with MySQL cluster, but with InnoDB and MyISAM the endianess doesn&#039;t matter.  There&#039;s even a MySQL certificate question to that effect.  You just need:

- two&#039;s-complement signed integers 
- IEEE floating-point math

This is true for most hardware except for perhaps embedded.

NDB has it&#039;s own backup, which I would use in favor of mysqldump.]]></description>
		<content:encoded><![CDATA[<p>@Daniël &#8211; nope.  Maybe with MySQL cluster, but with InnoDB and MyISAM the endianess doesn&#8217;t matter.  There&#8217;s even a MySQL certificate question to that effect.  You just need:</p>
<p>&#8211; two&#8217;s-complement signed integers<br />
&#8211; IEEE floating-point math</p>
<p>This is true for most hardware except for perhaps embedded.</p>
<p>NDB has it&#8217;s own backup, which I would use in favor of mysqldump.</p>
]]></content:encoded>
						</item>
						<item>
				<title>
				By: Daniël van Eeden				</title>
				<link>https://shlomi-noach.github.io/blog/mysql/an-argument-for-using-mysqldump/comment-page-1#comment-20739</link>
		<dc:creator><![CDATA[Daniël van Eeden]]></dc:creator>
		<pubDate>Thu, 11 Nov 2010 07:55:47 +0000</pubDate>
		<guid isPermaLink="false">https://shlomi-noach.github.io/blog/?p=3080#comment-20739</guid>
					<description><![CDATA[mysqldump is needed when migrating from a LSB to MSB architecture. 
mysqldump works for all table types. XtraBackup doesn&#039;t work for NDB or custom storage engines.

XtraBackup is the fastest tool for 80% of the backup/restores, for the other 20% there is mysqlbackup.]]></description>
		<content:encoded><![CDATA[<p>mysqldump is needed when migrating from a LSB to MSB architecture.<br />
mysqldump works for all table types. XtraBackup doesn&#8217;t work for NDB or custom storage engines.</p>
<p>XtraBackup is the fastest tool for 80% of the backup/restores, for the other 20% there is mysqlbackup.</p>
]]></content:encoded>
						</item>
						<item>
				<title>
				By: Morgan Tocker				</title>
				<link>https://shlomi-noach.github.io/blog/mysql/an-argument-for-using-mysqldump/comment-page-1#comment-20652</link>
		<dc:creator><![CDATA[Morgan Tocker]]></dc:creator>
		<pubDate>Tue, 09 Nov 2010 18:51:28 +0000</pubDate>
		<guid isPermaLink="false">https://shlomi-noach.github.io/blog/?p=3080#comment-20652</guid>
					<description><![CDATA[Hi Shlomi,

I like the clean state as well.  I depend on it for moving between major versions - as I do not trust that just using the old data files in a new release will work without issues.

I do not like people to pin me down to saying &quot;what is too large for mysqldump&quot; (because it&#039;s the table structure that really matters).  I tell them if they need a number it&#039;s 10G for day-to-day backups.  After that you may want to switch.

&quot;I’ve had similar incidents in the past. Not to mention the issue of compressing shared tablespace file.&quot;

A lot of this issue probably comes from actually *running mysqldump*.  Using --single-transaction requires old versions of rows need to be kept around while the backup runs, so it can be very dangerous on large systems with a lot of modifications.  It also churns all content through the buffer pool, which prior to InnoDB plugin releases can be particularly problematic due to bug #45015.  If you stop using mysqldump, you may stop having to do this tablespace compaction :)

Compare this to xtrabackup, which uses the end of the backup as a synchronization point - and does not load the data through your InnoDB buffer pool.  The way it works is actually very intelligent:

http://www.percona.com/docs/wiki/percona-xtrabackup:xtrabackup:internals#tuning_the_os_buffers

---

Answering some other points:

You do not need to use mysqldump to restore from Windows-&#062;Linux or 64-bit to 32-bit as other comments have noted.  The only incompatibilities you will have come from case sensitivity, but this can be solved with lower_case_table_names http://dev.mysql.com/doc/refman/5.0/en/identifier-case-sensitivity.html.

You do not need mysqldump to restore a table at a time either.  xtrabackup can prepare tables for export (from a MySQL/Percona server), and import them into any Percona server.  (Note: a regular MySQL servers can import back to the same server 1 table at a time, but not back to any server).

You do not need mysqldump to pull from another server - xtrabackup can do a streaming backup.  Use ssh user@server [cmd] to start the backup and receive it locally.

You do need mysqldump if you want to restore individual rows in an adhoc fashion.  This is very common, which is why many people take more than one type of backup.  But what I am saying in my original post, is that the primary backup to be used in failure situations should not be mysqldump.  That is at least for anyone with just a little data.]]></description>
		<content:encoded><![CDATA[<p>Hi Shlomi,</p>
<p>I like the clean state as well.  I depend on it for moving between major versions &#8211; as I do not trust that just using the old data files in a new release will work without issues.</p>
<p>I do not like people to pin me down to saying &#8220;what is too large for mysqldump&#8221; (because it&#8217;s the table structure that really matters).  I tell them if they need a number it&#8217;s 10G for day-to-day backups.  After that you may want to switch.</p>
<p>&#8220;I’ve had similar incidents in the past. Not to mention the issue of compressing shared tablespace file.&#8221;</p>
<p>A lot of this issue probably comes from actually *running mysqldump*.  Using &#8211;single-transaction requires old versions of rows need to be kept around while the backup runs, so it can be very dangerous on large systems with a lot of modifications.  It also churns all content through the buffer pool, which prior to InnoDB plugin releases can be particularly problematic due to bug #45015.  If you stop using mysqldump, you may stop having to do this tablespace compaction 🙂</p>
<p>Compare this to xtrabackup, which uses the end of the backup as a synchronization point &#8211; and does not load the data through your InnoDB buffer pool.  The way it works is actually very intelligent:</p>
<p><a href="http://www.percona.com/docs/wiki/percona-xtrabackup:xtrabackup:internals#tuning_the_os_buffers" rel="nofollow ugc">http://www.percona.com/docs/wiki/percona-xtrabackup:xtrabackup:internals#tuning_the_os_buffers</a></p>
<p>&#8212;</p>
<p>Answering some other points:</p>
<p>You do not need to use mysqldump to restore from Windows-&gt;Linux or 64-bit to 32-bit as other comments have noted.  The only incompatibilities you will have come from case sensitivity, but this can be solved with lower_case_table_names <a href="http://dev.mysql.com/doc/refman/5.0/en/identifier-case-sensitivity.html" rel="nofollow ugc">http://dev.mysql.com/doc/refman/5.0/en/identifier-case-sensitivity.html</a>.</p>
<p>You do not need mysqldump to restore a table at a time either.  xtrabackup can prepare tables for export (from a MySQL/Percona server), and import them into any Percona server.  (Note: a regular MySQL servers can import back to the same server 1 table at a time, but not back to any server).</p>
<p>You do not need mysqldump to pull from another server &#8211; xtrabackup can do a streaming backup.  Use ssh user@server [cmd] to start the backup and receive it locally.</p>
<p>You do need mysqldump if you want to restore individual rows in an adhoc fashion.  This is very common, which is why many people take more than one type of backup.  But what I am saying in my original post, is that the primary backup to be used in failure situations should not be mysqldump.  That is at least for anyone with just a little data.</p>
]]></content:encoded>
						</item>
						<item>
				<title>
				By: Ronald Bradford				</title>
				<link>https://shlomi-noach.github.io/blog/mysql/an-argument-for-using-mysqldump/comment-page-1#comment-20642</link>
		<dc:creator><![CDATA[Ronald Bradford]]></dc:creator>
		<pubDate>Tue, 09 Nov 2010 17:36:18 +0000</pubDate>
		<guid isPermaLink="false">https://shlomi-noach.github.io/blog/?p=3080#comment-20642</guid>
					<description><![CDATA[mysqldump has other benefits.

You can and should always dump schema and data separately. This gives you a version of your schema.

mysqldump allows for incremental data recovery, e.g. one table. Even if in one data file you can extract it as it&#039;s text.

You can use mysqldump to modify data during a restore.  Ideal for test environments where CLI tools are more effective then DB commands.

mysqldump is the only way to cross OS boundaries.]]></description>
		<content:encoded><![CDATA[<p>mysqldump has other benefits.</p>
<p>You can and should always dump schema and data separately. This gives you a version of your schema.</p>
<p>mysqldump allows for incremental data recovery, e.g. one table. Even if in one data file you can extract it as it&#8217;s text.</p>
<p>You can use mysqldump to modify data during a restore.  Ideal for test environments where CLI tools are more effective then DB commands.</p>
<p>mysqldump is the only way to cross OS boundaries.</p>
]]></content:encoded>
						</item>
						<item>
				<title>
				By: Jason				</title>
				<link>https://shlomi-noach.github.io/blog/mysql/an-argument-for-using-mysqldump/comment-page-1#comment-20626</link>
		<dc:creator><![CDATA[Jason]]></dc:creator>
		<pubDate>Tue, 09 Nov 2010 15:47:36 +0000</pubDate>
		<guid isPermaLink="false">https://shlomi-noach.github.io/blog/?p=3080#comment-20626</guid>
					<description><![CDATA[You can also *pull* a backup from a remote host using mysqldump.]]></description>
		<content:encoded><![CDATA[<p>You can also *pull* a backup from a remote host using mysqldump.</p>
]]></content:encoded>
						</item>
						<item>
				<title>
				By: Daniël van Eeden				</title>
				<link>https://shlomi-noach.github.io/blog/mysql/an-argument-for-using-mysqldump/comment-page-1#comment-20595</link>
		<dc:creator><![CDATA[Daniël van Eeden]]></dc:creator>
		<pubDate>Tue, 09 Nov 2010 12:15:38 +0000</pubDate>
		<guid isPermaLink="false">https://shlomi-noach.github.io/blog/?p=3080#comment-20595</guid>
					<description><![CDATA[There is yet another thing why I also like mysqldump: you can more easily grep for some data which should or shouldn&#039;t be there which is great for security.

And restore on a completely other platform and/or mysql version also needs mysqldump.

With mysqldump is should also be possible to load data in another RDBMS, but I never thried that.]]></description>
		<content:encoded><![CDATA[<p>There is yet another thing why I also like mysqldump: you can more easily grep for some data which should or shouldn&#8217;t be there which is great for security.</p>
<p>And restore on a completely other platform and/or mysql version also needs mysqldump.</p>
<p>With mysqldump is should also be possible to load data in another RDBMS, but I never thried that.</p>
]]></content:encoded>
						</item>
			</channel>
</rss>
