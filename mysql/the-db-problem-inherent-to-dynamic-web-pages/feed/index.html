<?xml version="1.0" encoding="UTF-8"?><rss version="2.0"
	xmlns:content="http://purl.org/rss/1.0/modules/content/"
	xmlns:dc="http://purl.org/dc/elements/1.1/"
	xmlns:atom="http://www.w3.org/2005/Atom"
	xmlns:sy="http://purl.org/rss/1.0/modules/syndication/"
	
	xmlns:georss="http://www.georss.org/georss"
	xmlns:geo="http://www.w3.org/2003/01/geo/wgs84_pos#"
	
	>
<channel>
	<title>
	Comments on: The DB problem inherent to dynamic web pages	</title>
	<atom:link href="https://shlomi-noach.github.io/blog/mysql/the-db-problem-inherent-to-dynamic-web-pages/feed" rel="self" type="application/rss+xml" />
	<link>https://shlomi-noach.github.io/blog/mysql/the-db-problem-inherent-to-dynamic-web-pages</link>
	<description>Blog by Shlomi Noach</description>
	<lastBuildDate>Wed, 22 Jul 2009 07:48:43 +0000</lastBuildDate>
	<sy:updatePeriod>
	hourly	</sy:updatePeriod>
	<sy:updateFrequency>
	1	</sy:updateFrequency>
	<generator>https://wordpress.org/?v=5.3.3</generator>
			<item>
				<title>
				By: Roland Bouman				</title>
				<link>https://shlomi-noach.github.io/blog/mysql/the-db-problem-inherent-to-dynamic-web-pages/comment-page-1#comment-2757</link>
		<dc:creator><![CDATA[Roland Bouman]]></dc:creator>
		<pubDate>Wed, 22 Jul 2009 07:48:43 +0000</pubDate>
		<guid isPermaLink="false">https://shlomi-noach.github.io/blog/?p=955#comment-2757</guid>
					<description><![CDATA[&quot; in itself, can slow down loading time; plus the page can get rendered awkwardly before all ajax calls are returned&quot;

sure it can. but the trick is of course to make sure the most important things are rendered ASAP with the initial request. The remainder of the page gcan then trickle in through one ore more ajax requests.]]></description>
		<content:encoded><![CDATA[<p>&#8221; in itself, can slow down loading time; plus the page can get rendered awkwardly before all ajax calls are returned&#8221;</p>
<p>sure it can. but the trick is of course to make sure the most important things are rendered ASAP with the initial request. The remainder of the page gcan then trickle in through one ore more ajax requests.</p>
]]></content:encoded>
						</item>
						<item>
				<title>
				By: shlomi				</title>
				<link>https://shlomi-noach.github.io/blog/mysql/the-db-problem-inherent-to-dynamic-web-pages/comment-page-1#comment-2754</link>
		<dc:creator><![CDATA[shlomi]]></dc:creator>
		<pubDate>Wed, 22 Jul 2009 05:20:55 +0000</pubDate>
		<guid isPermaLink="false">https://shlomi-noach.github.io/blog/?p=955#comment-2754</guid>
					<description><![CDATA[@Roland,

True, with Ajax you can do nifty things. It does make for multiple HTTP connections, which, in itself, can slow down loading time; plus the page can get rendered awkwardly before all ajax calls are returned.]]></description>
		<content:encoded><![CDATA[<p>@Roland,</p>
<p>True, with Ajax you can do nifty things. It does make for multiple HTTP connections, which, in itself, can slow down loading time; plus the page can get rendered awkwardly before all ajax calls are returned.</p>
]]></content:encoded>
						</item>
						<item>
				<title>
				By: Robert Wultsch				</title>
				<link>https://shlomi-noach.github.io/blog/mysql/the-db-problem-inherent-to-dynamic-web-pages/comment-page-1#comment-2751</link>
		<dc:creator><![CDATA[Robert Wultsch]]></dc:creator>
		<pubDate>Wed, 22 Jul 2009 04:39:00 +0000</pubDate>
		<guid isPermaLink="false">https://shlomi-noach.github.io/blog/?p=955#comment-2751</guid>
					<description><![CDATA[In a short time I think lib drizzle will provide the answer that we are looking for in term of parallelization of queries. 

When I worked on a newspaper website I got the front page down to around 5 queries, and story pages around 10. However even these few fast queries are not fast enough for many applications. One way or another cache management needs to be part of the discussion as I think it is a a powerful stop gap and part of an ideal complete solution.]]></description>
		<content:encoded><![CDATA[<p>In a short time I think lib drizzle will provide the answer that we are looking for in term of parallelization of queries. </p>
<p>When I worked on a newspaper website I got the front page down to around 5 queries, and story pages around 10. However even these few fast queries are not fast enough for many applications. One way or another cache management needs to be part of the discussion as I think it is a a powerful stop gap and part of an ideal complete solution.</p>
]]></content:encoded>
						</item>
						<item>
				<title>
				By: Roland Bouman				</title>
				<link>https://shlomi-noach.github.io/blog/mysql/the-db-problem-inherent-to-dynamic-web-pages/comment-page-1#comment-2724</link>
		<dc:creator><![CDATA[Roland Bouman]]></dc:creator>
		<pubDate>Mon, 20 Jul 2009 15:33:05 +0000</pubDate>
		<guid isPermaLink="false">https://shlomi-noach.github.io/blog/?p=955#comment-2724</guid>
					<description><![CDATA[Hi!

&quot;Parallelization with web pages is not so simple, and requires understanding of multi threading programming. &quot;

For many cases, it might be easier to use Ajax to do parallel HTTP requests. Of course, this requires client side javascript, and you can&#039;t parrallelize a whole lot due to a limited number of simultaneous HTTP connections, but still, Ajax does get the job done many times without requiring multi-threaded server side programming. 

I do agree that a multi-threaded server side programming language would be nice - I have considered trying Java instead of PHP for that reason. But it&#039;d be even nicer if there would be some way to do it in PHP too.

kind regards,

Roland]]></description>
		<content:encoded><![CDATA[<p>Hi!</p>
<p>&#8220;Parallelization with web pages is not so simple, and requires understanding of multi threading programming. &#8221;</p>
<p>For many cases, it might be easier to use Ajax to do parallel HTTP requests. Of course, this requires client side javascript, and you can&#8217;t parrallelize a whole lot due to a limited number of simultaneous HTTP connections, but still, Ajax does get the job done many times without requiring multi-threaded server side programming. </p>
<p>I do agree that a multi-threaded server side programming language would be nice &#8211; I have considered trying Java instead of PHP for that reason. But it&#8217;d be even nicer if there would be some way to do it in PHP too.</p>
<p>kind regards,</p>
<p>Roland</p>
]]></content:encoded>
						</item>
						<item>
				<title>
				By: shlomi				</title>
				<link>https://shlomi-noach.github.io/blog/mysql/the-db-problem-inherent-to-dynamic-web-pages/comment-page-1#comment-2723</link>
		<dc:creator><![CDATA[shlomi]]></dc:creator>
		<pubDate>Mon, 20 Jul 2009 15:12:32 +0000</pubDate>
		<guid isPermaLink="false">https://shlomi-noach.github.io/blog/?p=955#comment-2723</guid>
					<description><![CDATA[Jsled,

You are absolutely right. I could have blocked on the collection of Futures.
I chose the above code because I believe it is slightly easier to understand for non-Java programmers. At least that was my thinking.

Thanks,
Shlomi]]></description>
		<content:encoded><![CDATA[<p>Jsled,</p>
<p>You are absolutely right. I could have blocked on the collection of Futures.<br />
I chose the above code because I believe it is slightly easier to understand for non-Java programmers. At least that was my thinking.</p>
<p>Thanks,<br />
Shlomi</p>
]]></content:encoded>
						</item>
						<item>
				<title>
				By: jsled				</title>
				<link>https://shlomi-noach.github.io/blog/mysql/the-db-problem-inherent-to-dynamic-web-pages/comment-page-1#comment-2721</link>
		<dc:creator><![CDATA[jsled]]></dc:creator>
		<pubDate>Mon, 20 Jul 2009 13:44:44 +0000</pubDate>
		<guid isPermaLink="false">https://shlomi-noach.github.io/blog/?p=955#comment-2721</guid>
					<description><![CDATA[If you&#039;re going to block until all of the queries have returned anyways, you might as well dispense with the CountDownLatch … just submit the queries and use the Futures to either return immediately (if they&#039;re already finished) or block until they have finished.  It&#039;s a bit more straightforward, and will have the same runtime behavior.]]></description>
		<content:encoded><![CDATA[<p>If you&#8217;re going to block until all of the queries have returned anyways, you might as well dispense with the CountDownLatch … just submit the queries and use the Futures to either return immediately (if they&#8217;re already finished) or block until they have finished.  It&#8217;s a bit more straightforward, and will have the same runtime behavior.</p>
]]></content:encoded>
						</item>
			</channel>
</rss>
