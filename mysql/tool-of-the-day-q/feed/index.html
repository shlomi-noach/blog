<?xml version="1.0" encoding="UTF-8"?><rss version="2.0"
	xmlns:content="http://purl.org/rss/1.0/modules/content/"
	xmlns:dc="http://purl.org/dc/elements/1.1/"
	xmlns:atom="http://www.w3.org/2005/Atom"
	xmlns:sy="http://purl.org/rss/1.0/modules/syndication/"
	
	xmlns:georss="http://www.georss.org/georss"
	xmlns:geo="http://www.w3.org/2003/01/geo/wgs84_pos#"
	
	>
<channel>
	<title>
	Comments on: Tool of the day: q	</title>
	<atom:link href="https://shlomi-noach.github.io/blog/mysql/tool-of-the-day-q/feed" rel="self" type="application/rss+xml" />
	<link>https://shlomi-noach.github.io/blog/mysql/tool-of-the-day-q</link>
	<description>Blog by Shlomi Noach</description>
	<lastBuildDate>Mon, 13 Jan 2014 17:29:33 +0000</lastBuildDate>
	<sy:updatePeriod>
	hourly	</sy:updatePeriod>
	<sy:updateFrequency>
	1	</sy:updateFrequency>
	<generator>https://wordpress.org/?v=5.3.3</generator>
			<item>
				<title>
				By: Valerie Parham-Thompson				</title>
				<link>https://shlomi-noach.github.io/blog/mysql/tool-of-the-day-q/comment-page-1#comment-228737</link>
		<dc:creator><![CDATA[Valerie Parham-Thompson]]></dc:creator>
		<pubDate>Mon, 13 Jan 2014 17:29:33 +0000</pubDate>
		<guid isPermaLink="false">https://shlomi-noach.github.io/blog/?p=6417#comment-228737</guid>
					<description><![CDATA[Oh, happy day. A dream come true. Thanks for sharing!]]></description>
		<content:encoded><![CDATA[<p>Oh, happy day. A dream come true. Thanks for sharing!</p>
]]></content:encoded>
						</item>
						<item>
				<title>
				By: Rabin				</title>
				<link>https://shlomi-noach.github.io/blog/mysql/tool-of-the-day-q/comment-page-1#comment-216765</link>
		<dc:creator><![CDATA[Rabin]]></dc:creator>
		<pubDate>Sat, 10 Aug 2013 17:59:57 +0000</pubDate>
		<guid isPermaLink="false">https://shlomi-noach.github.io/blog/?p=6417#comment-216765</guid>
					<description><![CDATA[It can be a nice addition to my script/tool collection,
for most part of my needs i use bash scripting.

And if the data is messy, i use OpenRefine( http://openrefine.org/) formally know as GoogleRefine.]]></description>
		<content:encoded><![CDATA[<p>It can be a nice addition to my script/tool collection,<br />
for most part of my needs i use bash scripting.</p>
<p>And if the data is messy, i use OpenRefine( <a href="http://openrefine.org/" rel="nofollow ugc">http://openrefine.org/</a>) formally know as GoogleRefine.</p>
]]></content:encoded>
						</item>
						<item>
				<title>
				By: shlomi				</title>
				<link>https://shlomi-noach.github.io/blog/mysql/tool-of-the-day-q/comment-page-1#comment-216651</link>
		<dc:creator><![CDATA[shlomi]]></dc:creator>
		<pubDate>Thu, 08 Aug 2013 19:16:20 +0000</pubDate>
		<guid isPermaLink="false">https://shlomi-noach.github.io/blog/?p=6417#comment-216651</guid>
					<description><![CDATA[@Tomer,

I&#039;ll pass along :)
While I don&#039;t speak for Harel, my personal opinion is that for importing XML and JSON you really need an altogether different tool, based on XPath or similar expression language; not SQL.

SQL over unstructured data would be limited, to say the least.

Moreover, I don&#039;t see that SQL, having the diversities it offers, can ever be a stream editor. a GROUP BY over random data is example enough to present the need of &quot;get all the data upfront&quot;.

For the really large data, well, that&#039;s what RDBMS is for. I agree q should be used with the smaller datasets.

Again, all the above my own personal understanding.

Cheers]]></description>
		<content:encoded><![CDATA[<p>@Tomer,</p>
<p>I&#8217;ll pass along ðŸ™‚<br />
While I don&#8217;t speak for Harel, my personal opinion is that for importing XML and JSON you really need an altogether different tool, based on XPath or similar expression language; not SQL.</p>
<p>SQL over unstructured data would be limited, to say the least.</p>
<p>Moreover, I don&#8217;t see that SQL, having the diversities it offers, can ever be a stream editor. a GROUP BY over random data is example enough to present the need of &#8220;get all the data upfront&#8221;.</p>
<p>For the really large data, well, that&#8217;s what RDBMS is for. I agree q should be used with the smaller datasets.</p>
<p>Again, all the above my own personal understanding.</p>
<p>Cheers</p>
]]></content:encoded>
						</item>
						<item>
				<title>
				By: Tomer Cohen				</title>
				<link>https://shlomi-noach.github.io/blog/mysql/tool-of-the-day-q/comment-page-1#comment-216630</link>
		<dc:creator><![CDATA[Tomer Cohen]]></dc:creator>
		<pubDate>Thu, 08 Aug 2013 12:25:09 +0000</pubDate>
		<guid isPermaLink="false">https://shlomi-noach.github.io/blog/?p=6417#comment-216630</guid>
					<description><![CDATA[This is indeed a nice idea, but I&#039;d appreciate if it will have some additional file formats, such as CSV, XML and JSON ready for importing and exporting directly from the tool. Also, since it does create temporary sqlite table, I afraid it&#039;d be inefficient for processing large files as well as repeated tasks.]]></description>
		<content:encoded><![CDATA[<p>This is indeed a nice idea, but I&#8217;d appreciate if it will have some additional file formats, such as CSV, XML and JSON ready for importing and exporting directly from the tool. Also, since it does create temporary sqlite table, I afraid it&#8217;d be inefficient for processing large files as well as repeated tasks.</p>
]]></content:encoded>
						</item>
			</channel>
</rss>
