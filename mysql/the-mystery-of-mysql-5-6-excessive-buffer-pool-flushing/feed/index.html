<?xml version="1.0" encoding="UTF-8"?><rss version="2.0"
	xmlns:content="http://purl.org/rss/1.0/modules/content/"
	xmlns:dc="http://purl.org/dc/elements/1.1/"
	xmlns:atom="http://www.w3.org/2005/Atom"
	xmlns:sy="http://purl.org/rss/1.0/modules/syndication/"
	
	xmlns:georss="http://www.georss.org/georss"
	xmlns:geo="http://www.w3.org/2003/01/geo/wgs84_pos#"
	
	>
<channel>
	<title>
	Comments on: The mystery of MySQL 5.6 excessive buffer pool flushing	</title>
	<atom:link href="https://shlomi-noach.github.io/blog/mysql/the-mystery-of-mysql-5-6-excessive-buffer-pool-flushing/feed" rel="self" type="application/rss+xml" />
	<link>https://shlomi-noach.github.io/blog/mysql/the-mystery-of-mysql-5-6-excessive-buffer-pool-flushing</link>
	<description>Blog by Shlomi Noach</description>
	<lastBuildDate>Mon, 09 Jun 2014 07:03:38 +0000</lastBuildDate>
	<sy:updatePeriod>
	hourly	</sy:updatePeriod>
	<sy:updateFrequency>
	1	</sy:updateFrequency>
	<generator>https://wordpress.org/?v=5.3.3</generator>
			<item>
				<title>
				By: Introducing Orchestrator: manage and visualize your MySQL replication topologies and get home for dinner &#124; code.openark.org				</title>
				<link>https://shlomi-noach.github.io/blog/mysql/the-mystery-of-mysql-5-6-excessive-buffer-pool-flushing/comment-page-1#comment-244307</link>
		<dc:creator><![CDATA[Introducing Orchestrator: manage and visualize your MySQL replication topologies and get home for dinner &#124; code.openark.org]]></dc:creator>
		<pubDate>Mon, 09 Jun 2014 07:03:38 +0000</pubDate>
		<guid isPermaLink="false">https://shlomi-noach.github.io/blog/?p=6843#comment-244307</guid>
					<description><![CDATA[[&#8230;] The mystery of MySQL 5.6 excessive buffer pool flushing [&#8230;]]]></description>
		<content:encoded><![CDATA[<p>[&#8230;] The mystery of MySQL 5.6 excessive buffer pool flushing [&#8230;]</p>
]]></content:encoded>
						</item>
						<item>
				<title>
				By: Introducing Orchestrator: manage and visualize your MySQL replication topologies and get home for dinner &#124; Outbrain Techblog				</title>
				<link>https://shlomi-noach.github.io/blog/mysql/the-mystery-of-mysql-5-6-excessive-buffer-pool-flushing/comment-page-1#comment-244306</link>
		<dc:creator><![CDATA[Introducing Orchestrator: manage and visualize your MySQL replication topologies and get home for dinner &#124; Outbrain Techblog]]></dc:creator>
		<pubDate>Mon, 09 Jun 2014 07:02:37 +0000</pubDate>
		<guid isPermaLink="false">https://shlomi-noach.github.io/blog/?p=6843#comment-244306</guid>
					<description><![CDATA[[&#8230;] not GTID? We&#8217;re using MySQL 5.5. We&#8217;ve had issues while evaluating 5.6; and besides, migrating to GTID is a mess (several solutions or proposed [&#8230;]]]></description>
		<content:encoded><![CDATA[<p>[&#8230;] not GTID? We&#8217;re using MySQL 5.5. We&#8217;ve had issues while evaluating 5.6; and besides, migrating to GTID is a mess (several solutions or proposed [&#8230;]</p>
]]></content:encoded>
						</item>
						<item>
				<title>
				By: Vassil Velichkov				</title>
				<link>https://shlomi-noach.github.io/blog/mysql/the-mystery-of-mysql-5-6-excessive-buffer-pool-flushing/comment-page-1#comment-239603</link>
		<dc:creator><![CDATA[Vassil Velichkov]]></dc:creator>
		<pubDate>Mon, 05 May 2014 04:20:54 +0000</pubDate>
		<guid isPermaLink="false">https://shlomi-noach.github.io/blog/?p=6843#comment-239603</guid>
					<description><![CDATA[We have upgraded one of our MySQL servers from Percona MySQL 5.5 to Percona MySQL 5.6, while at the same time we have upgraded another server from plain 5.5. to 5.6. After the upgrade, without any changes in the application code, both servers experience constant spikes in flushing activity, well beyond the innodb_io_capaicty_max setting. In the last 20 hours I&#039;ve tried any combination of the same parameters described by Shlomi in his post + some more:
innodb_flush_method = O_DIRECT / O_DIRECT_NO_FSYNC (actually this helped a bit - same IOPS spikes, but causing only 1/3 of the max disk latency
innodb_lru_scan_depth = 1024 / 2048 / 4096
innodb_flushing_avg_loops = 10 / 20 / 30 / 40 / 50 / 60

I will continue to investigate, but what makes feel weird is that the adaptive flushing never really kicks in, until is too late and then buffer_flush_background_total_pages shows rapid increase and all 50K dirty pages are being flushed at a rate approx. 3 x innodb_io_capacity_max...]]></description>
		<content:encoded><![CDATA[<p>We have upgraded one of our MySQL servers from Percona MySQL 5.5 to Percona MySQL 5.6, while at the same time we have upgraded another server from plain 5.5. to 5.6. After the upgrade, without any changes in the application code, both servers experience constant spikes in flushing activity, well beyond the innodb_io_capaicty_max setting. In the last 20 hours I&#8217;ve tried any combination of the same parameters described by Shlomi in his post + some more:<br />
innodb_flush_method = O_DIRECT / O_DIRECT_NO_FSYNC (actually this helped a bit &#8211; same IOPS spikes, but causing only 1/3 of the max disk latency<br />
innodb_lru_scan_depth = 1024 / 2048 / 4096<br />
innodb_flushing_avg_loops = 10 / 20 / 30 / 40 / 50 / 60</p>
<p>I will continue to investigate, but what makes feel weird is that the adaptive flushing never really kicks in, until is too late and then buffer_flush_background_total_pages shows rapid increase and all 50K dirty pages are being flushed at a rate approx. 3 x innodb_io_capacity_max&#8230;</p>
]]></content:encoded>
						</item>
						<item>
				<title>
				By: shlomi				</title>
				<link>https://shlomi-noach.github.io/blog/mysql/the-mystery-of-mysql-5-6-excessive-buffer-pool-flushing/comment-page-1#comment-239422</link>
		<dc:creator><![CDATA[shlomi]]></dc:creator>
		<pubDate>Sat, 03 May 2014 03:38:31 +0000</pubDate>
		<guid isPermaLink="false">https://shlomi-noach.github.io/blog/?p=6843#comment-239422</guid>
					<description><![CDATA[@Rolando, as per my comment #9, my submitted bug report turns into &quot;valid behaviour&quot;. I am still without solution for excessive flushing.]]></description>
		<content:encoded><![CDATA[<p>@Rolando, as per my comment #9, my submitted bug report turns into &#8220;valid behaviour&#8221;. I am still without solution for excessive flushing.</p>
]]></content:encoded>
						</item>
						<item>
				<title>
				By: Rolando Edwards				</title>
				<link>https://shlomi-noach.github.io/blog/mysql/the-mystery-of-mysql-5-6-excessive-buffer-pool-flushing/comment-page-1#comment-239383</link>
		<dc:creator><![CDATA[Rolando Edwards]]></dc:creator>
		<pubDate>Fri, 02 May 2014 17:41:48 +0000</pubDate>
		<guid isPermaLink="false">https://shlomi-noach.github.io/blog/?p=6843#comment-239383</guid>
					<description><![CDATA[Correction on my post : I meant to say &quot;If the flushing algorithm has to look for contiguous dirty pages only, there should be no reason for excessive flushing.&quot;]]></description>
		<content:encoded><![CDATA[<p>Correction on my post : I meant to say &#8220;If the flushing algorithm has to look for contiguous dirty pages only, there should be no reason for excessive flushing.&#8221;</p>
]]></content:encoded>
						</item>
						<item>
				<title>
				By: Rolando Edwards				</title>
				<link>https://shlomi-noach.github.io/blog/mysql/the-mystery-of-mysql-5-6-excessive-buffer-pool-flushing/comment-page-1#comment-239382</link>
		<dc:creator><![CDATA[Rolando Edwards]]></dc:creator>
		<pubDate>Fri, 02 May 2014 17:39:32 +0000</pubDate>
		<guid isPermaLink="false">https://shlomi-noach.github.io/blog/?p=6843#comment-239382</guid>
					<description><![CDATA[It&#039;s ironic how in the MySQL Doc on &quot;Controlling the Flushing Rate of Dirty Pages from the InnoDB Buffer Pool&quot; reads a little differently of late.

MySQL 5.5 says : InnoDB performs certain tasks in the background, including flushing of dirty pages (those pages that have been changed but are not yet written to the database files) from the buffer pool, a task performed by the master thread. Currently, InnoDB aggressively flushes buffer pool pages if the percentage of dirty pages in the buffer pool exceeds innodb_max_dirty_pages_pct.

MySQL 5.6 says : InnoDB performs certain tasks in the background, including flushing of dirty pages (those pages that have been changed but are not yet written to the database files) from the buffer pool. Currently, InnoDB flushes buffer pool pages if the percentage of dirty pages in the buffer pool exceeds innodb_max_dirty_pages_pct.

Interstng how the MySQL 5.6 Doc does not say &quot;aggressively&quot;. Maybe something did change.

Someone should look into whether the introduction of innodb_flush_neighbors may have altered the way flushing is evaluated and subsequently performed.

The option innodb_flush_neighbors was introduced in MySQL 5.6. It&#039;s default behavior to flush contiguous dirty pages.

MySQL 5.5 flushing can rightly be called &quot;aggressive&quot; if it flushes anything dirty in the buffer pool, contiguous or not.

MySQL 5.6 is supposed to be conservative in its default innodb_flush_neighbors setting. If the flushing algorithm has to look for contiguous dirty pages only, there should be reason for excessive flushing.

If this algorithm is faulty and not properly taking innodb_max_dirty_pages_pct in account, this excessive flushing could possibly be a manifestation of such code.

Of course, all this is just my conjecture. Notwithstanding, I would like to see what your submitted bug report turns up.]]></description>
		<content:encoded><![CDATA[<p>It&#8217;s ironic how in the MySQL Doc on &#8220;Controlling the Flushing Rate of Dirty Pages from the InnoDB Buffer Pool&#8221; reads a little differently of late.</p>
<p>MySQL 5.5 says : InnoDB performs certain tasks in the background, including flushing of dirty pages (those pages that have been changed but are not yet written to the database files) from the buffer pool, a task performed by the master thread. Currently, InnoDB aggressively flushes buffer pool pages if the percentage of dirty pages in the buffer pool exceeds innodb_max_dirty_pages_pct.</p>
<p>MySQL 5.6 says : InnoDB performs certain tasks in the background, including flushing of dirty pages (those pages that have been changed but are not yet written to the database files) from the buffer pool. Currently, InnoDB flushes buffer pool pages if the percentage of dirty pages in the buffer pool exceeds innodb_max_dirty_pages_pct.</p>
<p>Interstng how the MySQL 5.6 Doc does not say &#8220;aggressively&#8221;. Maybe something did change.</p>
<p>Someone should look into whether the introduction of innodb_flush_neighbors may have altered the way flushing is evaluated and subsequently performed.</p>
<p>The option innodb_flush_neighbors was introduced in MySQL 5.6. It&#8217;s default behavior to flush contiguous dirty pages.</p>
<p>MySQL 5.5 flushing can rightly be called &#8220;aggressive&#8221; if it flushes anything dirty in the buffer pool, contiguous or not.</p>
<p>MySQL 5.6 is supposed to be conservative in its default innodb_flush_neighbors setting. If the flushing algorithm has to look for contiguous dirty pages only, there should be reason for excessive flushing.</p>
<p>If this algorithm is faulty and not properly taking innodb_max_dirty_pages_pct in account, this excessive flushing could possibly be a manifestation of such code.</p>
<p>Of course, all this is just my conjecture. Notwithstanding, I would like to see what your submitted bug report turns up.</p>
]]></content:encoded>
						</item>
						<item>
				<title>
				By: shlomi				</title>
				<link>https://shlomi-noach.github.io/blog/mysql/the-mystery-of-mysql-5-6-excessive-buffer-pool-flushing/comment-page-1#comment-238573</link>
		<dc:creator><![CDATA[shlomi]]></dc:creator>
		<pubDate>Thu, 24 Apr 2014 13:56:12 +0000</pubDate>
		<guid isPermaLink="false">https://shlomi-noach.github.io/blog/?p=6843#comment-238573</guid>
					<description><![CDATA[For completeness, it seems like the buffer_pool_pages_* weird values are actually valid, according to this: http://bugs.mysql.com/bug.php?id=59550 (compressed pages are counted inconsistently with total num pages the way I understand it)]]></description>
		<content:encoded><![CDATA[<p>For completeness, it seems like the buffer_pool_pages_* weird values are actually valid, according to this: <a href="http://bugs.mysql.com/bug.php?id=59550" rel="nofollow ugc">http://bugs.mysql.com/bug.php?id=59550</a> (compressed pages are counted inconsistently with total num pages the way I understand it)</p>
]]></content:encoded>
						</item>
						<item>
				<title>
				By: shlomi				</title>
				<link>https://shlomi-noach.github.io/blog/mysql/the-mystery-of-mysql-5-6-excessive-buffer-pool-flushing/comment-page-1#comment-238397</link>
		<dc:creator><![CDATA[shlomi]]></dc:creator>
		<pubDate>Tue, 22 Apr 2014 18:03:25 +0000</pubDate>
		<guid isPermaLink="false">https://shlomi-noach.github.io/blog/?p=6843#comment-238397</guid>
					<description><![CDATA[Hair turning grey. After some hunting, I came upon this:

&lt;pre&gt;
mysql&gt; select name, count from INNODB_METRICS where name like &#039;%buff%pool%page%&#039;;
+-------------------------+----------+
&#124; name                    &#124; count    &#124;
+-------------------------+----------+
&#124; buffer_pool_pages_total &#124;  3014627 &#124;
&#124; buffer_pool_pages_misc  &#124; -1808588 &#124;
&#124; buffer_pool_pages_data  &#124;  4822230 &#124;
&#124; buffer_pool_pages_dirty &#124;   488383 &#124;
&#124; buffer_pool_pages_free  &#124;      985 &#124;
+-------------------------+----------+
&lt;/pre&gt;

At this stage I will stop 5.6 evaluation and wait for higher forces to put sense into life. Have submitted bug report: http://bugs.mysql.com/bug.php?id=72423]]></description>
		<content:encoded><![CDATA[<p>Hair turning grey. After some hunting, I came upon this:</p>
<pre>
mysql> select name, count from INNODB_METRICS where name like '%buff%pool%page%';
+-------------------------+----------+
| name                    | count    |
+-------------------------+----------+
| buffer_pool_pages_total |  3014627 |
| buffer_pool_pages_misc  | -1808588 |
| buffer_pool_pages_data  |  4822230 |
| buffer_pool_pages_dirty |   488383 |
| buffer_pool_pages_free  |      985 |
+-------------------------+----------+
</pre>
<p>At this stage I will stop 5.6 evaluation and wait for higher forces to put sense into life. Have submitted bug report: <a href="http://bugs.mysql.com/bug.php?id=72423" rel="nofollow ugc">http://bugs.mysql.com/bug.php?id=72423</a></p>
]]></content:encoded>
						</item>
						<item>
				<title>
				By: shlomi				</title>
				<link>https://shlomi-noach.github.io/blog/mysql/the-mystery-of-mysql-5-6-excessive-buffer-pool-flushing/comment-page-1#comment-238387</link>
		<dc:creator><![CDATA[shlomi]]></dc:creator>
		<pubDate>Tue, 22 Apr 2014 15:18:55 +0000</pubDate>
		<guid isPermaLink="false">https://shlomi-noach.github.io/blog/?p=6843#comment-238387</guid>
					<description><![CDATA[Laurynas, Dimitry,
thanks both - will take further measurement and report.]]></description>
		<content:encoded><![CDATA[<p>Laurynas, Dimitry,<br />
thanks both &#8211; will take further measurement and report.</p>
]]></content:encoded>
						</item>
						<item>
				<title>
				By: Dimitri Kravtchuk				</title>
				<link>https://shlomi-noach.github.io/blog/mysql/the-mystery-of-mysql-5-6-excessive-buffer-pool-flushing/comment-page-1#comment-238385</link>
		<dc:creator><![CDATA[Dimitri Kravtchuk]]></dc:creator>
		<pubDate>Tue, 22 Apr 2014 15:16:10 +0000</pubDate>
		<guid isPermaLink="false">https://shlomi-noach.github.io/blog/?p=6843#comment-238385</guid>
					<description><![CDATA[[posting on behalf of Dimitri; SN]

what is great that since MySQL 5.6 there is more and more instrumentation generally present in the code and yet more in InnoDB via its METRICS table.

so, let&#039;s try to understand first from where the suspected flushing is coming..

first of all you have to enable METRICS counters :
mysql&gt; set global innodb_monitor_enable = &#039;%&#039;

(or just have innodb_monitor_enable=&#039;%&#039; in your my.conf file on startup)

then, using information_schema, start to monitor your flushing activity :

&lt;pre&gt;
mysql&gt; select name, count from INNODB_METRICS where name like &#039;%flush%tot%&#039;;
+-------------------------------------+-------+
&#124; name                                &#124; count &#124;
+-------------------------------------+-------+
&#124; buffer_flush_batch_total_pages      &#124;    96 &#124;
&#124; buffer_flush_neighbor_total_pages   &#124;     0 &#124;
&#124; buffer_flush_adaptive_total_pages   &#124;     0 &#124;
&#124; buffer_flush_sync_total_pages       &#124;     0 &#124;
&#124; buffer_flush_background_total_pages &#124;    96 &#124;
&#124; buffer_LRU_batch_flush_total_pages  &#124;     0 &#124;
+-------------------------------------+-------+
6 rows in set (0.00 sec)
&lt;/pre&gt;
(of course more helpful will be to get the diff/sec graphed from these values to see the tendency)..

once you&#039;ll have an idea to which flush processing your IO activity is related, you may then get a look on all %flush% counters, etc..]]></description>
		<content:encoded><![CDATA[<p>[posting on behalf of Dimitri; SN]</p>
<p>what is great that since MySQL 5.6 there is more and more instrumentation generally present in the code and yet more in InnoDB via its METRICS table.</p>
<p>so, let&#8217;s try to understand first from where the suspected flushing is coming..</p>
<p>first of all you have to enable METRICS counters :<br />
mysql> set global innodb_monitor_enable = &#8216;%&#8217;</p>
<p>(or just have innodb_monitor_enable=&#8217;%&#8217; in your my.conf file on startup)</p>
<p>then, using information_schema, start to monitor your flushing activity :</p>
<pre>
mysql> select name, count from INNODB_METRICS where name like '%flush%tot%';
+-------------------------------------+-------+
| name                                | count |
+-------------------------------------+-------+
| buffer_flush_batch_total_pages      |    96 |
| buffer_flush_neighbor_total_pages   |     0 |
| buffer_flush_adaptive_total_pages   |     0 |
| buffer_flush_sync_total_pages       |     0 |
| buffer_flush_background_total_pages |    96 |
| buffer_LRU_batch_flush_total_pages  |     0 |
+-------------------------------------+-------+
6 rows in set (0.00 sec)
</pre>
<p>(of course more helpful will be to get the diff/sec graphed from these values to see the tendency)..</p>
<p>once you&#8217;ll have an idea to which flush processing your IO activity is related, you may then get a look on all %flush% counters, etc..</p>
]]></content:encoded>
						</item>
			</channel>
</rss>
