<?xml version="1.0" encoding="UTF-8"?><rss version="2.0"
	xmlns:content="http://purl.org/rss/1.0/modules/content/"
	xmlns:wfw="http://wellformedweb.org/CommentAPI/"
	xmlns:dc="http://purl.org/dc/elements/1.1/"
	xmlns:atom="http://www.w3.org/2005/Atom"
	xmlns:sy="http://purl.org/rss/1.0/modules/syndication/"
	xmlns:slash="http://purl.org/rss/1.0/modules/slash/"
	
	xmlns:georss="http://www.georss.org/georss"
	xmlns:geo="http://www.w3.org/2003/01/geo/wgs84_pos#"
	>

<channel>
	<title>Open Source &#8211; code.openark.org</title>
	<atom:link href="https://shlomi-noach.github.io/blog/tag/open-source/feed" rel="self" type="application/rss+xml" />
	<link>http://shlomi-noach.github.io/blog/</link>
	<description>Blog by Shlomi Noach</description>
	<lastBuildDate>Tue, 26 May 2020 17:52:52 +0000</lastBuildDate>
	<language>en-US</language>
	<sy:updatePeriod>
	hourly	</sy:updatePeriod>
	<sy:updateFrequency>
	1	</sy:updateFrequency>
	<generator>https://wordpress.org/?v=5.3.3</generator>
<site xmlns="com-wordpress:feed-additions:1">32412571</site>	<item>
		<title>orchestrator on DB AMA: show notes</title>
		<link>https://shlomi-noach.github.io/blog/mysql/orchestrator-on-db-ama-show-notes</link>
				<comments>https://shlomi-noach.github.io/blog/mysql/orchestrator-on-db-ama-show-notes#respond</comments>
				<pubDate>Tue, 26 May 2020 17:52:52 +0000</pubDate>
		<dc:creator><![CDATA[shlomi]]></dc:creator>
				<category><![CDATA[MySQL]]></category>
		<category><![CDATA[Open Source]]></category>
		<category><![CDATA[orchestrator]]></category>

		<guid isPermaLink="false">https://shlomi-noach.github.io/blog/?p=8101</guid>
				<description><![CDATA[Earlier today I presented orchestrator on DB AMA. Thank you to the organizers Morgan Tocker, Liz van Dijk and Frédéric Descamps for hosting me, and thank you to all who participated! This was a no-slides, all command-line walkthrough of some of orchestrator&#8216;s capabilities, highlighting refactoring, topology analysis, takeovers and failovers, and discussing a bit of [&#8230;]]]></description>
								<content:encoded><![CDATA[<p>Earlier today I presented <a href="https://github.com/openark/orchestrator">orchestrator</a> on <a href="https://dbama.now.sh/">DB AMA</a>. Thank you to the organizers Morgan Tocker, Liz van Dijk and Frédéric Descamps for hosting me, and thank you to all who participated!</p>
<p>This was a no-slides, all command-line walkthrough of some of <code>orchestrator</code>&#8216;s capabilities, highlighting refactoring, topology analysis, takeovers and failovers, and discussing a bit of scripting and HTTP API tips.</p>
<p>The recording is available <a href="https://www.youtube.com/watch?v=UngtSlZ1iTQ&amp;feature=emb_logo">on YouTube</a> (also embedded on <a href="https://dbama.now.sh/#history">https://dbama.now.sh/#history</a>).</p>
<p>To present <code>orchestrator</code>, I used the new shiny docker CI environment; it&#8217;s a single docker image running <code>orchestrator</code>, a 4-node MySQL replication topology (courtesy <a href="https://www.dbdeployer.com/">dbdeployer</a>), heartbeat injection, <code>Consul</code>, <code>consul-template</code> and <code>HAProxy</code>. You can run it, too! Just clone the <code>orchestrator</code> repo, then run:</p>
<pre>./script/dock system</pre>
<p>From there, you may follow the same playbook I used in the presentation, available as <a href="https://gist.github.com/shlomi-noach/28986cb30f0e14d51594f0bc741b464c">orchestrator-demo-playbook.sh</a>.</p>
<p>Hope you find the presentation and the playbook to be useful resources.</p>
]]></content:encoded>
							<wfw:commentRss>https://shlomi-noach.github.io/blog/mysql/orchestrator-on-db-ama-show-notes/feed</wfw:commentRss>
		<slash:comments>0</slash:comments>
						<post-id xmlns="com-wordpress:feed-additions:1">8101</post-id>	</item>
		<item>
		<title>orchestrator: what&#8217;s new in CI, testing &#038; development</title>
		<link>https://shlomi-noach.github.io/blog/mysql/orchestrator-whats-new-in-ci-testing-development</link>
				<comments>https://shlomi-noach.github.io/blog/mysql/orchestrator-whats-new-in-ci-testing-development#respond</comments>
				<pubDate>Mon, 11 May 2020 08:01:08 +0000</pubDate>
		<dc:creator><![CDATA[shlomi]]></dc:creator>
				<category><![CDATA[MySQL]]></category>
		<category><![CDATA[dbdeployer]]></category>
		<category><![CDATA[docker]]></category>
		<category><![CDATA[GitHub]]></category>
		<category><![CDATA[Open Source]]></category>
		<category><![CDATA[orchestrator]]></category>
		<category><![CDATA[testing]]></category>

		<guid isPermaLink="false">https://shlomi-noach.github.io/blog/?p=8077</guid>
				<description><![CDATA[Recent focus on development &#38; testing yielded with new orchestrator environments and offerings for developers and with increased reliability and trust. This post illustrates the new changes, and see Developers section on the official documentation for more details. Testing In the past four years orchestrator was developed at GitHub, and using GitHub&#8217;s environments for testing. [&#8230;]]]></description>
								<content:encoded><![CDATA[<p>Recent focus on development &amp; testing yielded with new <a href="https://github.com/openark/orchestrator">orchestrator</a> environments and offerings for developers and with increased reliability and trust. This post illustrates the new changes, and see <a href="https://github.com/openark/orchestrator/tree/master/docs#developers">Developers</a> section on the official documentation for more details.</p>
<h2>Testing</h2>
<p>In the past four years <code>orchestrator</code> was <a href="https://github.blog/2016-12-08-orchestrator-github/">developed at GitHub</a>, and using GitHub&#8217;s environments for <a href="https://github.blog/2017-07-06-mysql-testing-automation-at-github/">testing</a>. This is very useful for testing <code>orchestrator</code>&#8216;s behavior within GitHub, interacting with its internal infrastructure, and validating failover behavior in a production environment. These tests and their results are not visible to the public, though.</p>
<p>Now that <code>orchestrator</code> is developed <a href="https://shlomi-noach.github.io/blog/mysql/the-state-of-orchestrator-2020-spoiler-healthy">outside GitHub</a> (that is, outside GitHub the <em>company</em>, not GitHub the <em>platform</em>) I wanted to improve on the testing framework, making it visible, accessible and contribute-able to the community. Thankfully, the GitHub platform has much to offer on that front and <code>orchestrator</code> now uses <a href="https://github.com/features/actions">GitHub Actions</a> more heavily for testing.</p>
<p>GitHub Actions provide a way to run code in a container in the context of the repository. The most common use case is to run CI tests on receiving a Pull Request. Indeed, when GitHub Actions became available, we switched out of Travis CI and into Actions for <code>orchestrator</code>&#8216;s CI.</p>
<p>Today, <code>orchestrator</code> runs three different tests:</p>
<ul>
<li>Build, unit testing, integration testing, code &amp; doc validation</li>
<li>Upgrade testing</li>
<li>System testing</li>
</ul>
<p>To highlight what each does:<span id="more-8077"></span></p>
<h3>Build, unit testing, integration testing</h3>
<p>Based on the original CI (and possibly will split into distinct tests), this CI Action compiles the code, runs unit tests, runs the suite of <a href="https://github.com/openark/orchestrator/tree/master/tests/integration">integration tests</a> (spins up both <code>MySQL</code> and <code>SQLite</code> databases and runs a series of tests on each backend), this CI job is the &#8220;basic&#8221; test to see that the contributed code even makes sense.</p>
<p>What&#8217;s new in this test is that it now produces an <em>artifact</em>: an <code>orchestrator</code> binary for Linux/amd64. This is again a feature for GitHub Actions; the artifact is kept for a couple months or so per Actions retention policy. <a href="https://github.com/openark/orchestrator/actions/runs/94337568">Here</a>&#8216;s an example; by the time you read this the binary artifact may or may not still be there.</p>
<p>This means you don&#8217;t actually need a development environment on your laptop to be able to build and <code>orchestrator</code> binary. More on this later.</p>
<h3>Upgrade testing</h3>
<p>Until recently not formalized; I&#8217;d test upgrades by deploying them internally at GitHub onto a staging environment. Now upgrades are tested per Pull Request: we spin up a container, deploy <code>orchestrator</code> from <code>master</code> branch using both <code>MySQL</code> and <code>SQLite</code> backends, then checkout the PR branch, and redeploy <code>orchestrator</code> using the existing backends &#8212; this verifies that at least backend-database wise, there&#8217;s not upgrade errors.</p>
<p>At this time the test only validates the database changes are applicable; in the future this may expand onto more elaborate tests.</p>
<h3>System testing</h3>
<p>I&#8217;m most excited about this one. Taking ideas from our approach to <a href="https://shlomi-noach.github.io/blog/mysql/using-dbdeployer-in-ci-tests">testing gh-ost with dbdeployer</a>, I created <a href="https://github.com/openark/orchestrator-ci-env">https://github.com/openark/orchestrator-ci-env</a>, which offers a full blown testing enviroment for <code>orchestrator</code>, including a MySQL replication topology (courtesy <a href="https://www.dbdeployer.com/">dbdeployer</a>), Consul, HAProxy and more.</p>
<p>This CI testing environment can also serve as a playground in your local docker setup, see shortly.</p>
<p>The <a href="https://github.com/openark/orchestrator/tree/master/tests/system">system tests suite</a> offers full blown cluster-wide operations such as graceful takeovers, master failovers, errant GTID transaction analysis and recovery and more. The suite utilizes the CI testing environment, breaks it, rebuilds it, validates it&#8230; Expects specific output, expects specific failure messages, specific analysis, specific outcomes.</p>
<p>As example, with the system tests suite, we can test the behavior of a master failover in a multi-DC, multi-region (obviously simulated) environment, where a server marked as &#8220;candidate&#8221; is lagging behind all others, with strict rules for cross-site/cross-region failovers, and still we wish to see that particular replica get promoted as master. We can test not only the topology aspect of the failover, but also the failover hooks, Consul integration and its effects, etc.</p>
<h2>Development</h2>
<p>There&#8217;s now multiple options for developers/contributors to build or just try out <code>orchestrator</code>.</p>
<h3>Build on GitHub</h3>
<p>As mentioned earlier, you actually don&#8217;t need a development environment. You can use <code>orchestrator</code> CI to build and generate a Linux/amd64 <code>orchestrator</code> binary, which you can download &amp; deploy as you see fit.</p>
<p>I&#8217;ve signed up for the GitHub Codespaces beta program, and hope to make that available for <code>orchestrator</code>, as well.</p>
<h3>Build via Docker</h3>
<p><code>orchestrator</code> offers various Docker build/run environments, accessible via the <code>script/dock</code> script:</p>
<ul>
<li>`script/dock alpine` will build and spawn `orchestrator` on a minimal <code>alpine</code> linux</li>
<li>`script/dock test` will build and run the same CI tests (unit, integration) as mentioned earlier, but on your own docker environemtn</li>
<li>`script/dock pkg` will build and generate `.rpm` and `.deb` packages</li>
</ul>
<h3>CI environment: the &#8220;full orchestrator experience&#8221;</h3>
<p>This is the <code>orchestrator</code> amusement park. Run <code>script/dock system</code> to spawn the aforementioned CI environment used in system tests, and on top of that, an <code>orchestrator</code> setup fully integrated with that system.</p>
<p>So that&#8217;s an <code>orchestrator</code>-MySQL topology-Consul-HAProxy setup, where <code>orchestrator</code> already has the credentials for, and pre-loads the MySQL topology, pre-configured to update Consul upon failover, HAProxy config populated by <code>consul-template</code>, heartbeat injection, and more. It resembles the <a href="https://github.blog/2018-06-20-mysql-high-availability-at-github/">HA setup at GitHub</a>, and in the future I expect to provide alternate setups (on top).</p>
<p>Once in that docker environment, one can try running relocations, failovers, test <code>orchestrator</code>&#8216;s behavior, etc.</p>
<h2>Community</h2>
<p>GitHub recently announced <a href="https://github.blog/2020-05-06-new-from-satellite-2020-github-codespaces-github-discussions-securing-code-in-private-repositories-and-more/#discussions">GitHub Discussions</a> ; think a stackoverflow like place within one&#8217;s repo to ask questions, discuss, vote on answers. It&#8217;s expected to be available this summer. When it does, I&#8217;ll encourage the community to use it instead of today&#8217;s <a href="https://groups.google.com/forum/#!forum/orchestrator-mysql">orchestrator-mysql</a> Google Group and of course the many questions posted as Issues.</p>
<p>There&#8217;s been a bunch of PRs merged recently, with more to come later on. I&#8217;m grateful for all contributions. Please understand if I&#8217;m still slow to respond.</p>
]]></content:encoded>
							<wfw:commentRss>https://shlomi-noach.github.io/blog/mysql/orchestrator-whats-new-in-ci-testing-development/feed</wfw:commentRss>
		<slash:comments>0</slash:comments>
						<post-id xmlns="com-wordpress:feed-additions:1">8077</post-id>	</item>
		<item>
		<title>The state of Orchestrator, 2020 (spoiler: healthy)</title>
		<link>https://shlomi-noach.github.io/blog/mysql/the-state-of-orchestrator-2020-spoiler-healthy-2</link>
				<comments>https://shlomi-noach.github.io/blog/mysql/the-state-of-orchestrator-2020-spoiler-healthy-2#respond</comments>
				<pubDate>Tue, 18 Feb 2020 19:14:12 +0000</pubDate>
		<dc:creator><![CDATA[shlomi]]></dc:creator>
				<category><![CDATA[MySQL]]></category>
		<category><![CDATA[GitHub]]></category>
		<category><![CDATA[Open Source]]></category>
		<category><![CDATA[orchestrator]]></category>

		<guid isPermaLink="false">https://shlomi-noach.github.io/blog/?p=8016</guid>
				<description><![CDATA[This post serves as a pointer to my previous announcement about The state of Orchestrator, 2020. Thank you to Tom Krouper who applied his operational engineer expertise to content publishing problems.]]></description>
								<content:encoded><![CDATA[<p>This post serves as a pointer to my previous announcement about <a href="https://shlomi-noach.github.io/blog/mysql/the-state-of-orchestrator-2020-spoiler-healthy">The state of Orchestrator, 2020</a>.</p>
<p>Thank you to <a href="https://github.com/tomkrouper">Tom Krouper</a> who applied his operational engineer expertise to content publishing problems.</p>
]]></content:encoded>
							<wfw:commentRss>https://shlomi-noach.github.io/blog/mysql/the-state-of-orchestrator-2020-spoiler-healthy-2/feed</wfw:commentRss>
		<slash:comments>0</slash:comments>
						<post-id xmlns="com-wordpress:feed-additions:1">8016</post-id>	</item>
		<item>
		<title>The state of Orchestrator, 2020 (spoiler: healthy)</title>
		<link>https://shlomi-noach.github.io/blog/mysql/the-state-of-orchestrator-2020-spoiler-healthy</link>
				<comments>https://shlomi-noach.github.io/blog/mysql/the-state-of-orchestrator-2020-spoiler-healthy#respond</comments>
				<pubDate>Tue, 18 Feb 2020 08:09:05 +0000</pubDate>
		<dc:creator><![CDATA[shlomi]]></dc:creator>
				<category><![CDATA[MySQL]]></category>
		<category><![CDATA[GitHub]]></category>
		<category><![CDATA[Open Source]]></category>
		<category><![CDATA[orchestrator]]></category>

		<guid isPermaLink="false">https://shlomi-noach.github.io/blog/?p=7996</guid>
				<description><![CDATA[Yesterday was my last day at GitHub, and this post explains what this means for orchestrator. First, a quick historical review: 2014: I began work on orchestrator at Outbrain, as https://github.com/outbrain/orchestrator. I authored several open source projects while working for Outbrain, and created orchestrator to solve discovery, visualization and simple refactoring needs. Outbrain was happy [&#8230;]]]></description>
								<content:encoded><![CDATA[<p>Yesterday was my last day at GitHub, and this post explains what this means for <code>orchestrator</code>. First, a quick historical review:</p>
<ul>
<li><strong>2014</strong>: I began work on <code>orchestrator</code> at <a href="https://www.outbrain.com/">Outbrain</a>, as <a href="https://github.com/outbrain/orchestrator">https://github.com/outbrain/orchestrator</a>. I authored several open source projects while working for Outbrain, and created <code>orchestrator</code> to solve discovery, visualization and simple refactoring needs. Outbrain was happy to have the project developed as a public, open source repo from day 1, and it was released under the Apache 2 license. Interestingly, the idea to develop <code>orchestrator</code> came after I attended Percona Live Santa Clara 2014 and watched &#8220;ChatOps: How GitHub Manages MySQL&#8221; by one Sam Lambert.</li>
<li><strong>2015</strong>: Joined <a href="http://booking.com">Booking.com</a> where my main focus was to redesign and solve issues with the existing high availability setup. With Booking.com&#8217;s support, I continued work on <code>orchestrator</code>, pursuing better failure detection and recovery processes. Booking.com was an incredible playground and testbed for <code>orchestrator</code>, a massive deployment of multiple MySQL/MariaDB flavors and configuration.</li>
<li><strong>2016 &#8211; 2020</strong>: Joined <a href="http://github.com">GitHub</a>. GitHub <a href="https://github.blog/2016-12-08-orchestrator-github/">adopted</a> <code>orchestrator</code> and I developed it under GitHub&#8217;s own org, at <a href="https://github.com/github/orchestrator">https://github.com/github/orchestrator</a>. It became <a href="https://github.blog/2018-06-20-mysql-high-availability-at-github/">a core component</a> in github.com&#8217;s high availability design, running failure detection and recoveries across sites and geographical regions, with more to come. These 4+ years have been critical to <code>orchestrator</code>&#8216;s development and saw its widespread use. At this time I&#8217;m aware of multiple large-scale organizations using <code>orchestrator</code> for high availability and failovers. Some of these are GitHub, Booking.com, Shopify, Slack, Wix, Outbrain, and more. <code>orchestrator</code> is the underlying failover mechanism for <a href="https://vitess.io/">vitess</a>, and is also included in Percona&#8217;s <a href="https://www.percona.com/software/database-tools/percona-monitoring-and-management">PMM</a>. These years saw a significant increase in community adoption and contributions, in published content, such as Pythian and Percona technical blog posts, and, not surprisingly, increase in issues and feature requests.</li>
</ul>
<h3><strong><br />
</strong>2020</h3>
<p>GitHub was very kind to support moving the <code>orchestrator</code> repo under my own <a href="https://github.com/openark">https://github.com/openark</a> org. This means all issues, pull requests, releases, forks, stars and watchers have automatically transferred to the new location: <a href="https://github.com/openark/orchestrator">https://github.com/openark/orchestrator</a>. The old links do a &#8220;follow me&#8221; and implicitly direct to the new location. All external links to code and docs still work. I&#8217;m grateful to GitHub for supporting this transfer.</p>
<p>I&#8217;d like to thank all the above companies for their support of <code>orchestrator</code> and of open source in general. Being able to work on the same product throughout three different companies is mind blowing and an incredible opportunity. <code>orchestrator</code> of course remains open source and licensed with Apache 2. Existing Copyrights are unchanged.</p>
<p>As for what&#8217;s next: some personal time off, please understand if there&#8217;s delays to reviews/answers. My intention is to continue developing <code>orchestrator</code>. Naturally, the shape of future development depends on how <code>orchestrator</code> meets my future work. Nothing changes in that respect: my focus on <code>orchestrator</code> has always been first and foremost the pressing business needs, and then community support as possible. There are some interesting ideas by prominent <code>orchestrator</code> users and adopters and I&#8217;ll share more thoughts in due time.</p>
<p>&nbsp;</p>
]]></content:encoded>
							<wfw:commentRss>https://shlomi-noach.github.io/blog/mysql/the-state-of-orchestrator-2020-spoiler-healthy/feed</wfw:commentRss>
		<slash:comments>0</slash:comments>
						<post-id xmlns="com-wordpress:feed-additions:1">7996</post-id>	</item>
		<item>
		<title>Un-split brain MySQL via gh-mysql-rewind</title>
		<link>https://shlomi-noach.github.io/blog/mysql/un-split-brain-mysql-via-gh-mysql-rewind</link>
				<comments>https://shlomi-noach.github.io/blog/mysql/un-split-brain-mysql-via-gh-mysql-rewind#respond</comments>
				<pubDate>Tue, 05 Mar 2019 13:51:43 +0000</pubDate>
		<dc:creator><![CDATA[shlomi]]></dc:creator>
				<category><![CDATA[MySQL]]></category>
		<category><![CDATA[Open Source]]></category>
		<category><![CDATA[Replication]]></category>

		<guid isPermaLink="false">https://shlomi-noach.github.io/blog/?p=7928</guid>
				<description><![CDATA[We are pleased to release gh-mysql-rewind, a tool that allows us to move MySQL back in time, automatically identify and rewind split brain changes, restoring a split brain server into a healthy replication chain. I recently had the pleasure of presenting gh-mysql-rewind at FOSDEM. Video and slides are available. Consider following along with the video. [&#8230;]]]></description>
								<content:encoded><![CDATA[<p>We are pleased to release <a href="https://github.com/github/gh-mysql-tools/tree/master/rewind">gh-mysql-rewind</a>, a tool that allows us to move MySQL back in time, automatically identify and rewind split brain changes, restoring a split brain server into a healthy replication chain.</p>
<p>I recently had the pleasure of presenting <code>gh-mysql-rewind</code> at <a href="https://fosdem.org/2019/schedule/track/mysql_mariadb_and_friends/">FOSDEM</a>. <a href="https://www.youtube.com/watch?v=UL--ew3n3QI">Video</a> and <a href="https://speakerdeck.com/shlominoach/un-split-brain-mysql">slides</a> are available. Consider following along with the video.</p>
<h2>Motivation</h2>
<p>Consider a split brain scenario: a &#8220;standard&#8221; MySQL replication topology suffered network isolation, and one of the replicas was promoted as new master. Meanwhile, the old master was still receiving writes from co-located apps.</p>
<p>Once the network isolation is over, we have a new master and an old master, and a split-brain situation: some writes only took place on one master; others only took place on the other. What if we wanted to converge the two? What paths do we have to, say, restore the old, demoted master, as a replica of the newly promoted master?</p>
<p>The old master is unlikely to agree to replicate from the new master. Changes have been made. <code>AUTO_INCREMENT</code> values have been taken. <code>UNIQUE</code> constraints will fail.</p>
<p>A few months ago, we at GitHub had <a href="https://github.blog/2018-10-30-oct21-post-incident-analysis/">exactly this scenario</a>. An entire data center went network isolated. Automation failed over to a 2nd DC. Masters in the isolated DC meanwhile kept receiving writes. At the end of the failover we ended up with a split brain scenario &#8211; which we <a href="https://githubengineering.com/mysql-high-availability-at-github/#limitations-and-drawbacks">expected</a>. However, an additional, unexpected constraint forced us to fail back to the original DC.</p>
<p>We had to make a choice: we&#8217;ve already operated for a long time in the 2nd DC and took many writes, that we were unwilling to lose. We were OK to lose (after auditing) the few seconds of writes on the isolated DC. But, how do we converge the data?</p>
<p>Backups are the trivial way out, but they incur long recovery time. Shipping backup data over the network for dozens of servers takes time. Restore time, catching up with changes since backup took place, warming up the servers so that they can handle production traffic, all take time.</p>
<p>Could we have reduces the time for recovery?</p>
<p><span id="more-7928"></span></p>
<p>There are multiple ways to do that: local backups, local delayed replicas, snapshots&#8230; We have embarked on several. In this post I wish to outline <a href="https://github.com/github/gh-mysql-tools/tree/master/rewind">gh-mysql-rewind</a>, which programmatically identifies the rogue (aka &#8220;bad&#8221;) transactions on the network isolated master, rewinds/reverts them, applies some bookkeeping and restores the demoted master as a healthy replica under the newly promoted master, thereby prepared to be promoted if needed.</p>
<h2>General overview</h2>
<p><code>gh-mysql-rewind</code> is a <code>shell</code> script. It utilizes multiple technologies, some of which do not speak to each other, to be able to do the magic. It assumes and utilizes the following:</p>
<ul>
<li>MySQL <a href="https://dev.mysql.com/doc/refman/5.7/en/replication-gtids-concepts.html">GTID replication</a></li>
<li>Row based replication (<code>binlog_format=ROW</code>)</li>
<li><code>binlog_row_image=FULL</code></li>
<li>Use of <a href="https://mariadb.com/kb/en/library/flashback/">MariaDB Flashback</a></li>
<li>Some limitations apply</li>
</ul>
<p>Some breakdown follows.</p>
<h2>GTID</h2>
<p>MySQL GTIDs keep track of all transactions executed on a given server. GTIDs indicate which server (UUID) originated a write, and ranges of transaction sequences. In a clean state, only one writer will generate GTIDs, and on all the replicas we would see the same GTID set, originated with the writer&#8217;s UUID.</p>
<p>In a split brain scenario, we would see divergence. It is possible to use <a href="https://dev.mysql.com/doc/refman/5.7/en/gtid-functions.html#function_gtid-subtract">GTID_SUBTRACT(old_master-GTIDs, new-master-GTIDs)</a> to identify the exact set of transactions executed on the old, demoted master, right after the failover. This is the essence of the split brain.</p>
<p>For example, assume that just before the network partition, GTID on the master was <code>00020192-1111-1111-1111-111111111111:1-5000</code>. Assume after the network partition the new master has UUID of <code>00020193-2222-2222-2222-222222222222</code>. It began to take writes, and after some time its GTID set showed <code>00020192-1111-1111-1111-111111111111:1-5000,00020193-2222-2222-2222-222222222222:1-200</code>.</p>
<p>On the demoted master, other writes took place, leading to the GTID set <code>00020192-1111-1111-1111-111111111111:1-5042</code>.</p>
<p>We will run&#8230;</p>
<pre><code class="sql">SELECT GTID_SUBTRACT(
  '00020192-1111-1111-1111-111111111111:1-5042',
  '00020192-1111-1111-1111-111111111111:1-5000,00020193-2222-2222-2222-222222222222:1-200'
);

&gt; '00020192-1111-1111-1111-111111111111:5001-5042'
</code></pre>
<p>&#8230;to identify the exact set of &#8220;bad transactions&#8221; on the demoted master.</p>
<h2>Row Based Replication</h2>
<p>With row based replication, and with <code>FULL</code> image format, each DML (<code>INSERT</code>, <code>UPDATE</code>, <code>DELETE</code>) writes to the binary log the complete row data before and after the operation. This means the binary log has enough information for us to revert the operation.</p>
<h2>Flashback</h2>
<p>Developed by Alibaba, <code>flashback</code> has been incorporated in <a href="https://mariadb.com/kb/en/library/flashback/">MariaDB</a>. MariaDB&#8217;s <code>mysqlbinlog</code> utility supports a <code>--flashback</code> flag, which interprets the binary log in a special way. Instead of printing out the events in the binary log in order, it prints the inverted operations in reverse order.</p>
<p>To illustrate, let&#8217;s assume this pseudo-code sequence of events in the binary log:</p>
<pre><code class="sql">insert(1, 'a')
insert(2, 'b')
insert(3, 'c')
update(2, 'b')-&gt;(2, 'second')
update(3, 'c')-&gt;(3, 'third')
insert(4, 'd')
delete(1, 'a')
</code></pre>
<p>A <code>--flashback</code> of this binary log would produce:</p>
<pre><code>insert(1, 'a')
delete(4, 'd')
update(3, 'third')-&gt;(3, 'c')
update(2, 'second')-&gt;(2, 'b')
delete(3, 'c')
delete(2, 'b')
delete(1, 'a')
</code></pre>
<p>Alas, MariaDB and <code>flashback</code> do not speak MySQL GTID language. GTIDs are one of the major points where MySQL and MariaDB have diverged beyond compatibility.</p>
<p>The output of MariaDB&#8217;s <code>mysqlbinlog --flashback</code> has neither any mention of GTIDs, nor does the tool take notice of GTIDs in the binary logs in the first place.</p>
<h2>gh-mysql-rewind</h2>
<p>This is where we step in. GTIDs provide the information about <em>what went wrong</em>. <code>flashback</code> has the mechanism to generate the reverse sequence of statements. <code>gh-mysql-rewind</code>:</p>
<ul>
<li>uses GTIDs to detect what went wrong</li>
<li>correlates those GTID entries with binary log files: identifies which binary logs actually contain those GTID events</li>
<li>invokes MariaDB&#8217;s <code>mysqlbinlog --flashback</code> to generate the reverse of those binary logs</li>
<li>injects (dummy) GTID information into the output</li>
<li>computes ETA</li>
</ul>
<p>This last part is worth elaborating. We have created a time machine. We have the mechanics to make it work. But as any Sci-Fi fan knows, one of the most important parts of time travel is knowing ahead where (when) you are going to land. Are you back in the Renaissance? Or are you suddenly to appear on board the French Revolution? Better dress accordingly.</p>
<p>In our scenario it is not enough to move MySQL back in time to <em>some consistent state</em>. We want to know at what time we landed, so that we can instruct the rewinded server to join the replication chain as a healthy replica. In MySQL terms, we need to make MySQL &#8220;forget&#8221; everything that ever happened after the split brain: not only in terms of data (which we already did), but in terms of GTID history.</p>
<p><code>gh-mysql-rewind</code> will do the math to project, ahead of time, at what &#8220;time&#8221; (i.e. GTID set) our time machine arrived. It will issue a `RESET MASTER; SET GLOBAL gtid_purged=&#8217;gtid-of-the-landing-time'&#8221; to make our re-winded MySQL consistent not only with some past dataset, but also with its own perception of the point in time where that dataset existed.</p>
<h2>Limitations</h2>
<p>Some limitations are due to MariaDB&#8217;s incompatibility with MySQL, some are due to MySQL DDL nature, some due to the fact <code>gh-mysql-rewind</code> is a <code>shell</code> script.</p>
<ul>
<li>Cannot rewind DDL. DDLs are silently ignored, and will impose a problem when trying to re-apply them.</li>
<li><code>JSON</code>, <code>POINT</code> data types are not supported.</li>
<li>The logic rewinds the MySQL server farther into the past than strictly required. This simplifies the code considerably, but imposed superfluous time to rewind+reapply, i.e. time to recover.</li>
<li>Currently, this only works one server at a time. If a group of 10 servers were network isolated together, the operation would need to run on each of these 10 servers.</li>
<li>Runs locally on each server. Requires both MySQL&#8217;s <code>mysqlbinlog</code> as well as MariaDB&#8217;s <code>mysqlbinlog</code>.</li>
</ul>
<h2>Testing</h2>
<p>There&#8217;s lot of moving parts to this mechanism. A mixture of technologies that don&#8217;t normally speak to each other, injection of data, prediction of ETA&#8230; How reliable is all this?</p>
<p>We run continuous <code>gh-mysql-rewind</code> testing in production to consistently prove that it works as expected. Our testing uses a non-production, dedicated, functional replica. It contaminates the data on the replica. It lets <code>gh-mysql-rewind</code> automatically move it back in time, it joins the replica back into the healthy chain.</p>
<p>That&#8217;s not enough. We actually create a scenario where we can predict, ahead of testing, what the time-of-arrival will be. We checksum the data on that replica at that time. After contaminating and effectively breaking replication, we expect <code>gh-mysql-rewind</code> to revert the changes back to our predicted point in time. We checksum the data again. We expect 100% match.</p>
<p>See the video or slides for more detail on our testing setup.</p>
<h2>Status</h2>
<p>At this time the tool in one of several solutions we hope to never need to employ. It is stable and tested. We are looking forward to a promising MySQL development that will provide GTID-revert capabilities using standard commands, such as <code>SELECT undo_transaction('00020192-1111-1111-1111-111111111111:5042')</code>.</p>
<p>We have <a href="https://github.com/github/gh-mysql-tools/tree/master/rewind">released</a> <code>gh-mysql-rewind</code> as open source, under the MIT license. The public release is a stripped down version of our own script, which has some GitHub-specific integration. We have general ideas in incorporating this functionality into higher level tools.</p>
<p><code>gh-mysql-rewind</code> is developed by the database-infrastructure team at GitHub.</p>
]]></content:encoded>
							<wfw:commentRss>https://shlomi-noach.github.io/blog/mysql/un-split-brain-mysql-via-gh-mysql-rewind/feed</wfw:commentRss>
		<slash:comments>0</slash:comments>
						<post-id xmlns="com-wordpress:feed-additions:1">7928</post-id>	</item>
		<item>
		<title>Using dbdeployer in CI tests</title>
		<link>https://shlomi-noach.github.io/blog/mysql/using-dbdeployer-in-ci-tests</link>
				<comments>https://shlomi-noach.github.io/blog/mysql/using-dbdeployer-in-ci-tests#respond</comments>
				<pubDate>Tue, 20 Feb 2018 07:29:58 +0000</pubDate>
		<dc:creator><![CDATA[shlomi]]></dc:creator>
				<category><![CDATA[MySQL]]></category>
		<category><![CDATA[dbdeployer]]></category>
		<category><![CDATA[gh-ost]]></category>
		<category><![CDATA[Open Source]]></category>
		<category><![CDATA[Replication]]></category>
		<category><![CDATA[testing]]></category>

		<guid isPermaLink="false">https://shlomi-noach.github.io/blog/?p=7848</guid>
				<description><![CDATA[I was very pleased when Giuseppe Maxia (aka datacharmer) unveiled dbdeployer in his talk at pre-FOSDEM MySQL day. The announcement came just at the right time. I wish to briefly describe how we use dbdeployer (work in progress). The case for gh-ost A user opened an issue on gh-ost, and the user was using MySQL [&#8230;]]]></description>
								<content:encoded><![CDATA[<p>I was very pleased when Giuseppe Maxia (aka <a href="http://datacharmer.blogspot.co.il/">datacharmer</a>) unveiled <a href="https://github.com/datacharmer/dbdeployer">dbdeployer</a> in his talk at <a href="http://lefred.be/content/pre-fosdem-mysql-day-2018-the-schedule/">pre-FOSDEM MySQL day</a>. The announcement came just at the right time. I wish to briefly describe how we use <code>dbdeployer</code> (work in progress).</p>
<h3>The case for gh-ost</h3>
<p>A user opened <a href="https://github.com/github/gh-ost/issues/538">an issue</a> on <a href="https://github.com/github/gh-ost"><code>gh-ost</code></a>, and the user was using MySQL <code>5.5</code>. <code>gh-ost</code> is being tested on <code>5.7</code> where the problem does not reproduce. A discussion with Gillian Gunson raised the concern of not testing on all versions. Can we run <code>gh-ost</code> tests for all MySQL/Percona/MariaDB versions? Should we? How easy would it be?</p>
<h3>gh-ost tests</h3>
<p><code>gh-ost</code> has three different test types:</p>
<ul>
<li>Unit tests: these are plain <code>golang</code> logic tests which are very easy and quick to run.</li>
<li>Integration tests: the topic of this post, see following. Today these do not run as part of an automated CI testing.</li>
<li>System tests: putting our production tables to the test, continuously migrating our production data on dedicated replicas, verifying checksums are identical and data is intact, <a href="https://githubengineering.com/mysql-testing-automation-at-github/#schema-migrations">read more</a>.</li>
</ul>
<p>Unit tests are already running as part of automated CI (every PR is subjected to those tests). Systems tests are clearly tied to our production servers. What&#8217;s the deal with the integration tests?<span id="more-7848"></span></p>
<h3>gh-ost integration tests</h3>
<p>The <code>gh-ost</code> <a href="https://github.com/github/gh-ost/tree/master/localtests">integration tests </a>are a suite of scenarios which verify <code>gh-ost</code>&#8216;s operation is sound. These scenarios are mostly concerned with data types, special <code>alter</code> statements etc. Is converting <code>DATETIME</code> to <code>TIMESTAMP</code> working properly? Are <code>latin1</code> columns being updated correctly? How about renaming a column? Changing a <code>PRIMARY KEY</code>? Column reorder? <code>5.7</code> JSON values? And so on. Each test will recreate the table, run migration, stop replication, check the result, resume replication&#8230;</p>
<p>The environment for these tests is a master-replica setup, where <code>gh-ost</code> modifies on the table on the replica and can then checksum or compare both the original and the altered <em>ghost</em> table.</p>
<p>We develop <code>gh-ost</code> internally at GitHub, but it&#8217;s also an open source project. We have our own internal CI environment, but then we also wish the public to have visibility into test failures (so that a user can submit a PR and get a reliable automated feedback). We use <a href="https://travis-ci.org/">Travis CI</a> for the public facing tests.</p>
<p>To run <code>gh-ost</code>&#8216;s integration tests as described above as part of our CI tests we should be able to:</p>
<ul>
<li>Create a master/replica setup in CI.</li>
<li>Actually, create a master/replica setup in <em>any</em> CI, and namely in Travis CI.</li>
<li>Actually, create multiple master/replica setups, of varying versions and vendors, in any ci, including both our internal CI and Travis CI.</li>
</ul>
<p>I was about to embark on a MySQL Sandbox setup, which I was not keen on. But FOSDEM was around the corner and I had other things to complete beforehand. Lucky me, <code>dbdeplyer</code> stepped in.</p>
<h3>dbdeployer</h3>
<p><code>dbdeployer</code> is a rewrite, a replacement to <a href="https://mysqlsandbox.net/">MySQL Sandbox</a>. I&#8217;ve been using MySQL Sandbox for many years, and my laptop is running two sandboxes at this very moment. But MySQL Sandbox has a few limitations or complications:</p>
<ul>
<li>Perl. Versions of Perl. Dependencies of packages of Perl. I mean, it&#8217;s fine, we can automate that.</li>
<li>Command line flag complexity: I always get lost in the complexity of the flags.</li>
<li>Get it right or prepare for battle: if you deployed something, but not the way you wanted, there&#8217;s sometimes limbo situations where you cannot re-deploy the same sandbox again, or you should start deleting files everywhere.</li>
<li>Deploy, not remove. Adding a sandbox is one thing. How about removing it?</li>
</ul>
<p><code>dbdeployer</code> is a <code>golang</code> rewrite, which solves the dependency problem. It ships as a single binary and nothing more is needed. It is simple to use. While it generates the equivalence of a that of a MySQL Sandbox, it does so with less command line flags and less confusion. There&#8217;s first class handling of the MySQL binaries: you unpack MySQL tarballs, you can list what&#8217;s available. You can then create sandbox environments: replication, standalone, etc. You can then delete those.</p>
<p>It&#8217;s pretty simple and I have not much more to add &#8212; which is the best thing about it.</p>
<p>So, with <code>dbdeployer</code> it is easy to create a master/replica. Something like:</p>
<blockquote>
<pre>dbdeployer unpack path/to/5.7.21.tar.gz --unpack-version=5.7.21 --sandbox-binary <span class="pl-smi">${PWD}</span>/sandbox/binary
dbdeployer replication 5.7.21 --nodes 2 --sandbox-binary <span class="pl-smi">${PWD}</span>/sandbox/binary --sandbox-home <span class="pl-smi">${PWD}</span>/sandboxes --gtid --my-cnf-options log_slave_updates --my-cnf-options log_bin --my-cnf-options binlog_format=ROW</pre>
</blockquote>
<h3>Where does it all fit in, and what about the MySQL binaries though?</h3>
<p>So, should <code>dbdeployer</code> be part of the <code>gh-ost</code> repo? And where does one get those MySQL binaries from? Are they to be part of the <code>gh-ost</code> repo? Aren&#8217;t they a few GB to extract?</p>
<p>Neither <code>dbdeployer</code> nor MySQL binaries should be added to the <code>gh-ost</code> repo. And fortunately, Giuseppe also <a href="https://github.com/datacharmer/mysql-docker-minimal">solved</a> the MySQL binaries problem.</p>
<p>The scheme I&#8217;m looking at right now is as follows:</p>
<ul>
<li>A new public repo, <a href="https://github.com/github/gh-ost-ci-env">gh-ost-ci-env</a> is created. This repo includes:
<ul>
<li><code>dbdeployer</code> compiled binaries</li>
<li>Minimal MySQL tarballs for selected versions. Those tarballs are reasonably small: between `14MB` and `44MB` at this time.</li>
</ul>
</li>
<li><code>gh-ost</code>&#8216;s CI to <code>git clone https://github.com/github/gh-ost-ci-env.git</code> (<a href="https://github.com/github/gh-ost/pull/546/files#diff-d78e7acd07ce8a2aad92026ae10cbec2R7">code</a>)</li>
<li><code>gh-ost</code>&#8216;s CI to setup a master/replica sandbox (<a href="https://github.com/github/gh-ost/pull/546/files#diff-d78e7acd07ce8a2aad92026ae10cbec2R13">one</a>, <a href="https://github.com/github/gh-ost/pull/546/files#diff-d78e7acd07ce8a2aad92026ae10cbec2R15">two</a>).</li>
<li><a href="https://github.com/github/gh-ost/pull/546/files#diff-d78e7acd07ce8a2aad92026ae10cbec2R30">Kick the tests</a>.</li>
</ul>
<p>The above is a work in progress:</p>
<ul>
<li>At this time only runs a single MySQL version.</li>
<li>There is a known issue where after a test, replication may take time to resume. Currently on slower boxes (such as the Travis CI containers) this leads to failures.</li>
</ul>
<p>Another concern I have at this time is build time. For a single MySQL version, it takes some <code>5-7</code> minutes on my local laptop to run all integration tests. It will be faster on our internal CI. It will be considerably <em>slower</em> on Travis CI, I can expect between <code>10m - 15m</code>. Add multiple versions and we&#8217;re looking at a <code>1hr</code> build. Such long build times will affect our development and delivery times, and so we will split them off the main build. I need to consider what the best approach is.</p>
<p>That&#8217;s all for now. I&#8217;m pretty excited for the potential of <code>dbdeployer</code> and will be looking into incorporating the same for <code>orchestrator</code> CI tests.</p>
<p>&nbsp;</p>
<p>&nbsp;</p>
]]></content:encoded>
							<wfw:commentRss>https://shlomi-noach.github.io/blog/mysql/using-dbdeployer-in-ci-tests/feed</wfw:commentRss>
		<slash:comments>0</slash:comments>
						<post-id xmlns="com-wordpress:feed-additions:1">7848</post-id>	</item>
		<item>
		<title>orchestrator 3.0.6: faster crash detection &#038; recoveries, auto Pseudo-GTID, semi-sync and more</title>
		<link>https://shlomi-noach.github.io/blog/mysql/orchestrator-3-0-6-faster-crash-detection-recoveries-auto-pseudo-gtid-semi-sync-and-more</link>
				<comments>https://shlomi-noach.github.io/blog/mysql/orchestrator-3-0-6-faster-crash-detection-recoveries-auto-pseudo-gtid-semi-sync-and-more#respond</comments>
				<pubDate>Mon, 29 Jan 2018 09:40:05 +0000</pubDate>
		<dc:creator><![CDATA[shlomi]]></dc:creator>
				<category><![CDATA[MySQL]]></category>
		<category><![CDATA[High availability]]></category>
		<category><![CDATA[Open Source]]></category>
		<category><![CDATA[orchestrator]]></category>
		<category><![CDATA[Replication]]></category>

		<guid isPermaLink="false">https://shlomi-noach.github.io/blog/?p=7833</guid>
				<description><![CDATA[orchestrator 3.0.6 is released and includes some exciting improvements and features. It quickly follows up on 3.0.5 released recently, and this post gives a breakdown of some notable changes: Faster failure detection Recall that orchestrator uses a holistic approach for failure detection: it reads state not only from the failed server (e.g. master) but also [&#8230;]]]></description>
								<content:encoded><![CDATA[<p><code>orchestrator</code> <a href="https://github.com/github/orchestrator/releases/tag/v3.0.6"><strong>3.0.6</strong> is released</a> and includes some exciting improvements and features. It quickly follows up on <a href="https://github.com/github/orchestrator/releases/tag/v3.0.5"><strong>3.0.5</strong></a> released recently, and this post gives a breakdown of some notable changes:</p>
<h3>Faster failure detection</h3>
<p>Recall that <code>orchestrator</code> uses a holistic approach for <a href="https://github.com/github/orchestrator/blob/master/docs/failure-detection.md#failure-detection">failure detection</a>: it reads state not only from the failed server (e.g. master) but also from its replicas. <code>orchestrator</code> now detects failure faster than before:</p>
<ul>
<li>A detection cycle has been eliminated, leading to quicker resolution of a failure. On our setup, where we poll servers every <code>5sec</code>, failure detection time dropped from <code>7-10sec</code> to <code>3-5sec</code>, <em>keeping reliability</em>. The reduction in time does not lead to increased false positives.<br />
Side note: you may see increased not-quite-failure analysis such as &#8220;I can&#8217;t see the master&#8221; (<code>UnreachableMaster</code>).</li>
<li>Better handling of network scenarios where packets are dropped. Instead of hanging till TCP timeout, <code>orchestrator</code> now observes server discovery asynchronously. We have <a href="https://githubengineering.com/mysql-testing-automation-at-github/#failovers">specialized failover tests</a> that simulate dropped packets. The change reduces detection time by some <code>5sec</code>.</li>
</ul>
<h3>Faster master recoveries</h3>
<p>Promoting a new master is a complex task which attempts to promote the best replica out of the pool of replicas. It&#8217;s not always the most up-to-date replica. The choice varies depending on replica configuration, version, and state.</p>
<p>With recent changes, <code>orchestrator</code> is able to to recognize, early on, that the replica it would like to promote as master is <em>ideal</em>. Assuming that is the case, <code>orchestrator</code> is able to immediate promote it (i.e. run hooks, set <code>read_only=0</code> etc.), and run the rest of the failover logic, i.e. the rewiring of replicas under the newly promoted master, asynchronously.</p>
<p>This allows the promoted server to take writes sooner, even while its replicas are not yet connected. It also means external hooks are executed sooner.</p>
<p>Between faster detection and faster recoveries, we&#8217;re looking at some <code>10sec</code> reduction in overall recovery time: from moment of crash to moment where a new master accepts writes. We stand now at <code>&lt; 20sec</code> in almost all cases, and <code>&lt; 15s</code> in optimal cases. Those times are measured on our failover tests.</p>
<p>We are working on reducing failover time unrelated to <code>orchestrator</code> and hope to update soon.</p>
<h3>Automated Pseudo-GTID</h3>
<p>As reminder, Pseudo-GTID is an alternative to GTID, without the kind of commitment you make with GTID. It provides similar &#8220;point your replica under any other server&#8221; behavior GTID allows.<span id="more-7833"></span></p>
<p>There&#8217;s still <em>many</em> setups out there where GTID is not (yet?) deployed and enabled. However, Pseudo-GTID is often misunderstood, and though I&#8217;ve blogged and presented Pseudo-GTID many times in the past, I still find myself explaining to people the setup is simple and does not involve change to one&#8217;s topologies.</p>
<p>Well, it just got simpler. <code>orchestrator</code> is now able to automatically inject Pseudo-GTID for you.</p>
<p>Say the word: <code>"AutoPseudoGTID": true</code>, grant <a href="https://github.com/github/orchestrator/blob/master/docs/configuration-discovery-pseudo-gtid.md#automated-pseudo-gtid-injection">the necessary privilege</a>, and your non-GTID topology is suddenly supercharged with magical Pseudo-GTID tokens that provide you with:</p>
<ul>
<li>Arbitrary relocation of replicas</li>
<li>Automated or manual failovers (masters <em>and</em> intermediate masters)</li>
<li>Vendor freedom: runs on Oracle MySQL, Percona Server, MariaDB, or all of the above at the very same time.</li>
<li>Version freedom (still on <code>5.5</code>? No problem. Oh, this gets you crash-safe replication as extra bonus, too)</li>
</ul>
<p>Auto-Pseudo-GTID further simplifies the infrastructure in that you no longer need to take care of injecting Pseudo-GTID onto the master as well as handle master identity changes. No more <code>event_scheduler</code> to enable/disable nor services to <code>start/stop</code>.</p>
<p>More and more setups are moving to GTID. We may, too! But I find it peculiar that Pseudo-GTID was suggested <code>4</code> years ago, when <code>5.6</code> GTID was already released, and still many setups are not yet running GTID. If you&#8217;re not using GTID, please try Pseudo-GTID! <a href="https://github.com/github/orchestrator/blob/master/docs/pseudo-gtid.md">Read more</a>.</p>
<h3>Semi-sync support</h3>
<p>Semi-sync has been internally supported via a specialized patch contributed by Vitess, to flag a server as semi-sync-able and handle enablement of semi-sync upon master failover.</p>
<p><code>orchestrator</code> now supports semi-sync more generically. You may use <code>orchestrator</code> to enable/disable semi-sync master/replica side, via <code>orchestrator -c enable-semi-sync-master</code>, <code>orchestrator -c enable-semi-sync-replica</code>, <code>orchestrator -c disable-semi-sync-master</code>, <code>orchestrator -c disable-semi-sync-replica</code> commands (or API equivalent).</p>
<p>The API will also tell you whether semi-sync is enabled on instances. Noteworthy that configured != enabled. A server can be configured with <code>rpl_semi_sync_master_enabled=ON</code>, but if no semi-sync replicas are found, the <code>Rpl_semi_sync_master_status</code> state is <code>OFF</code>.</p>
<h3>More</h3>
<p>UI changes, removal of prepared statements, documentation updates, raft updates&#8230;</p>
<p><a href="https://github.com/github/orchestrator"><code>orchestrator</code></a> is free and open source and released under the Apache 2 license. It is authored at and used by GitHub.</p>
<p>I&#8217;ll be presenting <code>orchestrator/raft</code> in <a href="https://fosdem.org/2018/schedule/event/orchestrator_raft/">FOSDEM next week</a>, at the MySQL and Friends Room.</p>
]]></content:encoded>
							<wfw:commentRss>https://shlomi-noach.github.io/blog/mysql/orchestrator-3-0-6-faster-crash-detection-recoveries-auto-pseudo-gtid-semi-sync-and-more/feed</wfw:commentRss>
		<slash:comments>0</slash:comments>
						<post-id xmlns="com-wordpress:feed-additions:1">7833</post-id>	</item>
		<item>
		<title>gh-ost 1.0.42 released: JSON support, optimizations</title>
		<link>https://shlomi-noach.github.io/blog/mysql/gh-ost-1-0-42-released-json-support-optimizations</link>
				<comments>https://shlomi-noach.github.io/blog/mysql/gh-ost-1-0-42-released-json-support-optimizations#comments</comments>
				<pubDate>Thu, 14 Sep 2017 07:26:16 +0000</pubDate>
		<dc:creator><![CDATA[shlomi]]></dc:creator>
				<category><![CDATA[MySQL]]></category>
		<category><![CDATA[gh-ost]]></category>
		<category><![CDATA[Open Source]]></category>

		<guid isPermaLink="false">https://shlomi-noach.github.io/blog/?p=7799</guid>
				<description><![CDATA[gh-ost 1.0.42 is released and available for download. JSON MySQL 5.7&#8217;s JSON data type is now supported. There is a soft-limitation, that your JSON may not be part of your PRIMARY KEY. Currently this isn&#8217;t even supported by MySQL anyhow. Performance Two noteworthy changes are: Client side prepared statements reduce network traffic and round trips [&#8230;]]]></description>
								<content:encoded><![CDATA[<p><strong>gh-ost</strong> 1.0.42 is <a href="https://github.com/github/gh-ost/releases/tag/v1.0.42">released and available for download</a>.</p>
<h3>JSON</h3>
<p>MySQL 5.7&#8217;s <code>JSON</code> data type is now supported.</p>
<p>There is a soft-limitation, that your <code>JSON</code> may not be part of your <code>PRIMARY KEY</code>. Currently this isn&#8217;t even supported by MySQL anyhow.</p>
<h3>Performance</h3>
<p>Two noteworthy changes are:</p>
<ul>
<li>Client side prepared statements reduce network traffic and round trips to the server.</li>
<li>Range query iteration avoids creating temporary tables and filesorting.</li>
</ul>
<p>We&#8217;re not running benchmarks at this time to observe performance gains.</p>
<h3>5.7</h3>
<p>More tests validating <code>5.7</code> compatibility (at this time GitHub runs MySQL <code>5.7</code> in production).</p>
<h3>Ongoing</h3>
<p>Many other changes included.</p>
<p>We are grateful for all community feedback in form of open Issues, Pull Requests and questions!</p>
<p><code>gh-ost</code> is authored by <a href="http://github.com/">GitHub</a>. It is free and open source and is available under the MIT license.</p>
<h3>Speaking</h3>
<p>In two weeks time, <a href="https://github.com/jonahberquist">Jonah Berquist</a> will present <a href="https://www.percona.com/live/e17/sessions/gh-ost-triggerless-painless-trusted-online-schema-migrations">gh-ost: Triggerless, Painless, Trusted Online Schema Migrations</a> at Percona Live, Dublin.</p>
<p><a href="https://github.com/tomkrouper">Tom Krouper</a> and myself will present <a href="https://www.percona.com/live/e17/sessions/mysql-infrastructure-testing-automation-at-github">MySQL Infrastructure Testing Automation at GitHub</a>, where, among other things, we describe how we test <code>gh-ost</code> in production.</p>
]]></content:encoded>
							<wfw:commentRss>https://shlomi-noach.github.io/blog/mysql/gh-ost-1-0-42-released-json-support-optimizations/feed</wfw:commentRss>
		<slash:comments>4</slash:comments>
						<post-id xmlns="com-wordpress:feed-additions:1">7799</post-id>	</item>
		<item>
		<title>Speaking at Percona Live Dublin: keynote, orchestrator tutorial, MySQL testing automation</title>
		<link>https://shlomi-noach.github.io/blog/mysql/speaking-at-percona-live-dublin-keynote-orchestrator-tutorial-mysql-testing-automation</link>
				<comments>https://shlomi-noach.github.io/blog/mysql/speaking-at-percona-live-dublin-keynote-orchestrator-tutorial-mysql-testing-automation#respond</comments>
				<pubDate>Wed, 13 Sep 2017 05:20:56 +0000</pubDate>
		<dc:creator><![CDATA[shlomi]]></dc:creator>
				<category><![CDATA[MySQL]]></category>
		<category><![CDATA[Open Source]]></category>
		<category><![CDATA[PerconaLive]]></category>
		<category><![CDATA[secondary]]></category>
		<category><![CDATA[Speaking]]></category>

		<guid isPermaLink="false">https://shlomi-noach.github.io/blog/?p=7794</guid>
				<description><![CDATA[I&#8217;m looking forward to a busy Percona Live Dublin conference, delivering three talks. Chronologically, these are: Practical orchestrator tutorial Attend this 3 hour tutorial for a thorough overview on orchestrator: what, why, how to configure, best advice, deployments, failovers, security, high availability, common operations, &#8230; We will of course discuss the new orchestrator/raft setup and [&#8230;]]]></description>
								<content:encoded><![CDATA[<p>I&#8217;m looking forward to a busy <a href="https://www.percona.com/live/e17/">Percona Live Dublin</a> conference, delivering three talks. Chronologically, these are:</p>
<ul>
<li><a href="https://www.percona.com/live/e17/sessions/practical-orchestrator-tutorial"><strong>Practical orchestrator tutorial</strong></a><br />
Attend this 3 hour tutorial for a thorough overview on orchestrator: what, why, how to configure, best advice, deployments, failovers, security, high availability, common operations, &#8230;<br />
We will of course discuss the new <a href="https://shlomi-noach.github.io/blog/mysql/orchestrator-3-0-2-ga-released-raft-consensus-sqlite">orchestrator/raft</a> setup and share our experience running it in production.<br />
The tutorial will allow for general questions from the audience and open discussions.</li>
<li><a href="https://www.percona.com/live/e17/sessions/why-open-sourcing-our-database-tooling-was-smart-decision-keynote"><strong>Why Open Sourcing Our Database Tooling was the Smart Decision</strong></a><br />
What it says. A 10 minute journey advocating for open sourcing infrastructure.</li>
<li><a href="https://www.percona.com/live/e17/sessions/mysql-infrastructure-testing-automation-at-github"><strong>MySQL Infrastructure Testing Automation at GitHub</strong></a><br />
Co-presenting with <a href="http://github.com/tomkrouper">Tom Krouper</a>, we share how &amp; why we run infrastructure tests in and near production that gives us trust in many of our ongoing, ever changing operations. Essentially this is &#8220;why you should feel OK trusting us with your data&#8221;.</li>
</ul>
<p>See you there!</p>
]]></content:encoded>
							<wfw:commentRss>https://shlomi-noach.github.io/blog/mysql/speaking-at-percona-live-dublin-keynote-orchestrator-tutorial-mysql-testing-automation/feed</wfw:commentRss>
		<slash:comments>0</slash:comments>
						<post-id xmlns="com-wordpress:feed-additions:1">7794</post-id>	</item>
		<item>
		<title>orchestrator 3.0.2 GA released: raft consensus, SQLite</title>
		<link>https://shlomi-noach.github.io/blog/mysql/orchestrator-3-0-2-ga-released-raft-consensus-sqlite</link>
				<comments>https://shlomi-noach.github.io/blog/mysql/orchestrator-3-0-2-ga-released-raft-consensus-sqlite#comments</comments>
				<pubDate>Tue, 12 Sep 2017 08:39:10 +0000</pubDate>
		<dc:creator><![CDATA[shlomi]]></dc:creator>
				<category><![CDATA[MySQL]]></category>
		<category><![CDATA[Open Source]]></category>
		<category><![CDATA[orchestrator]]></category>

		<guid isPermaLink="false">https://shlomi-noach.github.io/blog/?p=7784</guid>
				<description><![CDATA[orchestrator 3.0.2 GA is released and available for download (see also packagecloud repository). 3.0.2 is the first stable release in the 3.0* series, introducing (recap from 3.0 pre-release announcement): orchestrator/raft Raft is a consensus protocol, supporting leader election and consensus across a distributed system.  In an orchestrator/raft setup orchestrator nodes talk to each other via raft protocol, form consensus and [&#8230;]]]></description>
								<content:encoded><![CDATA[<p><strong>orchestrator</strong> 3.0.2 GA is <a href="https://github.com/github/orchestrator/releases/tag/v3.0.2">released</a> and available for download (see also <a href="https://packagecloud.io/github/orchestrator">packagecloud repository</a>).</p>
<p><code>3.0.2</code> is the first stable release in the <code>3.0*</code> series, introducing (recap from <a href="https://shlomi-noach.github.io/blog/mysql/orchestratorraft-pre-release-3-0">3.0 pre-release announcement</a>):</p>
<h3>orchestrator/raft</h3>
<p><a href="https://raft.github.io/">Raft</a> is a consensus protocol, supporting leader election and consensus across a distributed system.  In an <code>orchestrator/raft</code> setup <code>orchestrator</code> nodes talk to each other via raft protocol, form consensus and elect a leader. Each <code>orchestrator</code> node has its own <em>dedicated</em> backend database. The backend databases do not speak to each other; only the <code>orchestrator</code> nodes speak to each other.</p>
<p>No MySQL replication setup needed; the backend DBs act as standalone servers. In fact, the backend server doesn&#8217;t have to be MySQL, and <code>SQLite</code>is supported. <code>orchestrator</code> now ships with <code>SQLite</code> embedded, no external dependency needed.</p>
<p>For details, please refer to the documentation:</p>
<ul>
<li><a href="https://github.com/github/orchestrator/blob/master/docs/raft.md">orchestrator/raft: overview</a></li>
<li><a href="https://github.com/github/orchestrator/blob/master/docs/raft-vs-sync-repl.md">orchestrator/raft vs. shared backend DB setup, comparison</a></li>
</ul>
<h3>SQLite</h3>
<p>Suggested and requested by many, is to remove <code>orchestrator</code>&#8216;s own dependency on a MySQL backend. <code>orchestrator</code> now supports a SQLite backend.</p>
<p><code>SQLite</code> is a transactional, relational, embedded database, and as of <code>3.0</code> it is embedded within <code>orchestrator</code>, no external dependency required.</p>
<h3>orchestrator-client</h3>
<p><a href="https://github.com/github/orchestrator/blob/master/docs/orchestrator-client.md"><strong>orchestrator-client</strong></a> is a client shell script which mimics the command line interface, while running <code>curl | jq</code> requests against the HTTP API. It stands to simplify your deployments: interacting with the orchestrator service via <code>orchestrator-client</code> is easier and only requires you to place a shell script (this is as opposed to installing the <code>orchestrator</code> binary + configuration file).</p>
<p><code>orchestrator-client</code> is the way to interact with your <code>orchestrator/raft</code> cluster. <code>orchestrator-client</code> now has its own <code>RPM/deb</code> release package.</p>
<p>You may still use the web interface, web API ; and a special <code>--ignore-raft-setup</code> keeps power at your hand (use at your own risk).</p>
<h3>State of orchestrator/raft</h3>
<p><code>orchestrator/raft</code> is a big change:<span id="more-7784"></span></p>
<ul>
<li>In the way it is deployed</li>
<li>In the way it is operated</li>
<li>In the high availability it provides</li>
<li>and more</li>
</ul>
<p>This is why it has been tested in production for a few months.</p>
<p><code>orchestrator/raft</code> now runs in production at GitHub ; we&#8217;ve decommissioned the &#8220;old&#8221; <code>orchestrator</code> setup having run both in parallel for a while. It drives our failovers and deploys over three data centers.</p>
<p>We are using MySQL as backend to our <code>orchestrator</code> cluster. We will introduce more staging tests for SQLite-based setups.</p>
<h3>Roadmap</h3>
<p>There&#8217;s much to do, and we chose to release a version that has a way to go. We expect:</p>
<ul>
<li>Dynamic raft cluster join/leave operations (right now the cluster is static and configuration based)</li>
<li>New nodes joining the cluster to auto-populate data from the cluster. This is actually a built-in feature to the <code>hashicorp/raft</code> library that we use, however we intentionally did not use this functionality, and expect to re-introduce it. At this time, adding a newly provisioned node to the cluster requires a backup/restore or dump/load of DB data from an existing node.</li>
<li>Partitioning of probe tasks across nodes</li>
<li>Various thoughts on proxy integrations</li>
<li>More&#8230;</li>
</ul>
<p>We will focus on making operations simpler, and of course keep stability and reliability at highest priority.</p>
<h3>orchestrator tutorial</h3>
<p>In two weeks time I will be presenting the <a href="https://www.percona.com/live/e17/sessions/practical-orchestrator-tutorial">practical orchestrator tutorial</a>, a 3 hour practical walkthrough on deployment, configuration, reasoning and more.</p>
]]></content:encoded>
							<wfw:commentRss>https://shlomi-noach.github.io/blog/mysql/orchestrator-3-0-2-ga-released-raft-consensus-sqlite/feed</wfw:commentRss>
		<slash:comments>1</slash:comments>
						<post-id xmlns="com-wordpress:feed-additions:1">7784</post-id>	</item>
	</channel>
</rss>
