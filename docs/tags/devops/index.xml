<?xml version="1.0" encoding="utf-8" standalone="yes" ?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>Devops on code.openark.org</title>
    <link>/blog/tags/devops/</link>
    <description>Recent content in Devops on code.openark.org</description>
    <generator>Hugo -- gohugo.io</generator>
    <language>en-us</language>
    <copyright>&amp;copy; 2016. All rights reserved.</copyright>
    <lastBuildDate>Fri, 18 Apr 2014 13:15:09 +0000</lastBuildDate>
    <atom:link href="/blog/tags/devops/index.xml" rel="self" type="application/rss+xml" />
    
    <item>
      <title>&#34;Anemomaster&#34;: DML visibility. Your must-do for tomorrow</title>
      <link>/blog/mysql/anemomaster-dml-visibility-your-must-do-for-tomorrow/</link>
      <pubDate>Fri, 18 Apr 2014 13:15:09 +0000</pubDate>
      
      <guid>/blog/mysql/anemomaster-dml-visibility-your-must-do-for-tomorrow/</guid>
      <description>&lt;p&gt;Here&#39;s our take of master DML query monitoring at &lt;a href=&#34;http://www.outbrain.com/&#34;&gt;Outbrain&lt;/a&gt; (&lt;a href=&#34;https://www.percona.com/live/mysql-conference-2014/sessions/mysql-devops-outbrain&#34;&gt;presented April 2014&lt;/a&gt;). It took a half-day to code, implement, automate and deploy, and within the first hour of work we managed to catch multiple ill-doing services and scripts. You might want to try this out for yourself.&lt;/p&gt;
&lt;h4&gt;What&#39;s this about?&lt;/h4&gt;
&lt;p&gt;What queries do you monitor on your MySQL servers? Many don&#39;t monitor queries at all, and only look up slow queries on occasion, using &lt;a href=&#34;http://www.percona.com/doc/percona-toolkit/2.2/pt-query-digest.html&#34;&gt;pt-query-digest&lt;/a&gt;. Some monitor slow queries, where &lt;a href=&#34;https://github.com/box/Anemometer/wiki&#34;&gt;Anemometer&lt;/a&gt; (relying on pt-query-digest) is a very good tool. To the extreme, some monitor TCP traffic on all MySQL servers -- good for you! In between, there&#39;s a particular type of queries that are of special interest: DML (&lt;strong&gt;INSERT/UPDATE/DELETE&lt;/strong&gt;) queries issued against the master.&lt;/p&gt;
&lt;p&gt;They are of particular interest because they are only issued once against the master, yet propagate through replication topology to execute on all slaves. These queries have a direct impact on your slave lag and on your overall replication capacity. I suggest you should be familiar with your DMLs just as you are with your slow queries.&lt;/p&gt;
&lt;p&gt;In particular, we had multiple occasions in the past where all or most slaves started lagging. Frantically we would go to our metrics; yes! We would see a spike in &lt;strong&gt;com_insert&lt;/strong&gt;. Someone (some service) was obviously generating more &lt;strong&gt;INSERT&lt;/strong&gt;s than usual, at a high rate that the slaves could not keep up with. But, &lt;em&gt;which&lt;/em&gt; &lt;strong&gt;INSERT&lt;/strong&gt; was that? Blindly, we would look at the binary logs. Well, erm, what are we looking for, exactly?&lt;/p&gt;
&lt;p&gt;Two such occasions convinced us that there should be a solution, but it took some time till it hit us. We were already using &lt;em&gt;Anemometer&lt;/em&gt; for monitoring our slow logs. We can do the same for monitoring our binary logs. Thus was born &lt;em&gt;&#34;Anemomaster&#34;&lt;/em&gt;.&lt;/p&gt;
&lt;p&gt;Quick recap on how Anemometer works: you issue &lt;em&gt;pt-query-digest&lt;/em&gt; on your slow logs on all MySQL hosts (we actually first ship the slow logs to a central place where we analyse them; same thing). This is done periodically, and slow logs are then rotated. You throw the output of &lt;em&gt;pt-query-digest&lt;/em&gt; to a central database (this is built in with &lt;em&gt;pt-query-digest&lt;/em&gt;; it doesn&#39;t necessarily produce human readable reports). &lt;em&gt;Anemometer&lt;/em&gt; would read this central database and visualize the slow queries.&lt;/p&gt;
&lt;h4&gt;Analysing DMLs&lt;/h4&gt;
&lt;p&gt;But then, &lt;em&gt;pt-query-digest&lt;/em&gt; doesn&#39;t only parse slow logs. It can parse binary logs. Instead of asking for total query time, we ask for query count, and on we go to establish the same mechanism, using same &lt;em&gt;pt-query-digest&lt;/em&gt; and same &lt;em&gt;Anemometer&lt;/em&gt; to store and visualize the DMLs issued on our masters.&lt;/p&gt;
&lt;p&gt;When analysing DMLs we&#39;re interested in parsing binary logs -- and it makes no sense to do the same on all slaves. All slaves just have same copy of binlog entries as the master produces. It only takes &lt;em&gt;one&lt;/em&gt; server to get an accurate picture of the DMLs on your replication topology.&lt;/p&gt;
&lt;p&gt;&lt;!--more--&gt;&lt;/p&gt;
&lt;p&gt;One server could be the master, and this can indeed be done: just &lt;strong&gt;FLUSH MASTER LOGS&lt;/strong&gt;, parse the binary logs with &lt;em&gt;pt-query-digest&lt;/em&gt;, and you&#39;re done. But like others, we tend to look at our masters as tender babies. We care for them, and do not wish to overload them unnecessarily. We chose to get the binlog entries from our slaves, instead. We also chose to get the entries from the relay logs, since these are unaffected by slave performance and as long as network is good, we can expect the relay logs to be &lt;em&gt;very&lt;/em&gt; up to date. At any given time we have two slaves that take this role (this is automated and verified). On a &lt;strong&gt;10&lt;/strong&gt; minute period we would flush the relay logs on these servers, and analyse whatever relay logs we have not analysed as yet.&lt;/p&gt;
&lt;p&gt;The script below is a slightly modified version of our own, and should work for the standard installation. Modify to fit your own data (in particular, it assumes relay logs are named &lt;strong&gt;mysqld-relay-bin&lt;/strong&gt;; &lt;strong&gt;datadir&lt;/strong&gt; is specified in &lt;strong&gt;/etc/my.cnf&lt;/strong&gt;, and please don&#39;t ask me how to do this on Windows):&lt;/p&gt;
&lt;blockquote&gt;&lt;pre&gt;
#!/bin/bash
#
# Digest latest relay logs file, write results to &amp;quot;anemomaster&amp;quot;
#
# This script can run from any machine; it only needs to execute on a single machine per mysql cluster, but for
# analysis availability it should execute on at least two hosts per cluster.
#
DATADIR=`grep datadir /etc/my.cnf|awk -F= &#39;{print $2}&#39;`
TMPDIR=/tmp
DIGESTED_RELAY_LOGS_FILE=${DATADIR}/digested_relay_logs.txt
touch $DIGESTED_RELAY_LOGS_FILE
chown mysql:mysql $DIGESTED_RELAY_LOGS_FILE
hostname=$(hostname)
echo &amp;quot;deleting old relay logs from ${TMPDIR}&amp;quot;
rm ${TMPDIR}/mysqld-relay-bin.[0-9]*
echo &amp;quot;Getting current relay log files&amp;quot;
existing_relay_log_files=$(ls -tr ${DATADIR}/mysqld-relay-bin.[0-9]* | head -n -1)
for existing_relay_log_file in $existing_relay_log_files
do
    cp -u $existing_relay_log_file $TMPDIR
done
echo &amp;quot;flushing relay logs&amp;quot;
/usr/bin/mysql -umyself -psecret -e &#39;flush relay logs\G;&#39; 2&amp;gt;/dev/null
# sleep because the log file takes some time to disappear
sleep 1
echo &amp;quot;Getting current relay log files&amp;quot;
existing_relay_log_files=$(ls -tr ${DATADIR}/mysqld-relay-bin.[0-9]* | head -n -1)
for existing_relay_log_file in $existing_relay_log_files
do
    cp -u $existing_relay_log_file $TMPDIR
done
cd $TMPDIR
for relay_log_file in mysqld-relay-bin.[0-9]*
do
    # Filter this relay log file, since it&#39;s already been digested
    grep $relay_log_file $DIGESTED_RELAY_LOGS_FILE &amp;amp;&amp;amp; rm $relay_log_file
done
for relay_log_file in mysqld-relay-bin.[0-9]*
do
    echo &amp;quot;digesting $relay_log_file&amp;quot;
    mysqlbinlog $relay_log_file | /usr/bin/pt-query-digest \
      --type binlog --order-by Query_time:cnt --group-by fingerprint --limit 100 \
      --review  P=3306,u=anemomaster,p=secret,h=anemomaster_host,D=anemomaster,t=global_query_review \
      --history P=3306,u=anemomaster,p=secret,h=anemomaster_host,D=anemomaster,t=global_query_review_history \
      --filter=&amp;quot; \$event-&amp;gt;{Bytes} = length(\$event-&amp;gt;{arg}) and \$event-&amp;gt;{hostname}=\&amp;quot;$(hostname)\&amp;quot; &amp;quot; \
      --no-report
    echo &amp;quot;$relay_log_file&amp;quot; &amp;gt;&amp;gt; $DIGESTED_RELAY_LOGS_FILE
    rm $relay_log_file
done
# make sure the file does not bloat. 20 entries is more than enough.
tail -n 20 $DIGESTED_RELAY_LOGS_FILE &amp;gt; ${TMPDIR}/DIGESTED_RELAY_LOGS_FILE
cat ${TMPDIR}/DIGESTED_RELAY_LOGS_FILE &amp;gt; $DIGESTED_RELAY_LOGS_FILE
echo &amp;quot;done&amp;quot;
&lt;/pre&gt;&lt;/blockquote&gt;
&lt;p&gt;As for Anemometer, we patched it to support multiple environments (&#34;clusters&#34;) -- but irrelevant to the DML change. If you just want to make it visualize DMLs, here&#39;s the major configuration changes to &lt;strong&gt;config.inc.php&lt;/strong&gt; (marked with &lt;strong&gt;bold&lt;/strong&gt;):&lt;/p&gt;
&lt;blockquote&gt;&lt;pre&gt;
$conf[&#39;history_defaults&#39;] = array(
	&#39;output&#39;		=&amp;gt; &#39;table&#39;,
	&#39;fact-group&#39;	=&amp;gt; &#39;date&#39;,
	&#39;fact-order&#39;	=&amp;gt; &#39;date DESC&#39;,
	&#39;fact-limit&#39; =&amp;gt; &#39;90&#39;,
	&#39;dimension-ts_min_start&#39; =&amp;gt; date(&amp;quot;Y-m-d H:i:s&amp;quot;, strtotime( &#39;-90 day&#39;)),
	&#39;dimension-ts_min_end&#39;	=&amp;gt; date(&amp;quot;Y-m-d H:i:s&amp;quot;),
	&#39;table_fields&#39; =&amp;gt; array(&#39;date&#39;, &#39;query_time_avg&#39;,&#39;ts_cnt&#39;,&#39;Query_time_sum&#39;)
);
$conf[&#39;report_defaults&#39;] = array(
	&#39;fact-group&#39;	=&amp;gt; &#39;checksum&#39;,
	&#39;fact-order&#39;	=&amp;gt; &#39;ts_cnt DESC&#39;,
	&#39;fact-limit&#39; =&amp;gt; &#39;20&#39;,
	&#39;dimension-ts_min_start&#39; =&amp;gt; date(&amp;quot;Y-m-d H:i:s&amp;quot;, strtotime( &#39;-1 day&#39;)),
	&#39;dimension-ts_min_end&#39;	=&amp;gt; date(&amp;quot;Y-m-d H:i:s&amp;quot;),
	&#39;table_fields&#39; =&amp;gt; array(&#39;checksum&#39;,&#39;snippet&#39;, &#39;query_time_avg&#39;,&#39;ts_cnt&#39;,&#39;Query_time_sum&#39;),
	&#39;dimension-pivot-hostname_max&#39; =&amp;gt; null,
	&#39;dimension-pivot-clustername_max&#39; =&amp;gt; null
);
$conf[&#39;graph_defaults&#39;] = array(
	&#39;fact-group&#39;	=&amp;gt; &#39;minute_ts&#39;,
	&#39;fact-order&#39;	=&amp;gt; &#39;minute_ts&#39;,
	&#39;fact-limit&#39; =&amp;gt; &#39;&#39;,
	&#39;dimension-ts_min_start&#39; =&amp;gt; date(&amp;quot;Y-m-d H:i:s&amp;quot;, strtotime( &#39;-7 day&#39;)),
	&#39;dimension-ts_min_end&#39;	=&amp;gt; date(&amp;quot;Y-m-d H:i:s&amp;quot;),
	&#39;table_fields&#39; =&amp;gt; array(&#39;minute_ts&#39;),
	// hack ... fix is to make query builder select the group and order fields,
	// then table fields only has to contain the plot_field
	&#39;plot_field&#39; =&amp;gt; &#39;ts_cnt&#39;,
);
&lt;/pre&gt;&lt;/blockquote&gt;
&lt;p&gt;With a &lt;strong&gt;10&lt;/strong&gt; minute rotation &amp;amp; digestion, we are able to analyze near real-time what&#39;s been done on our masters. If we see a spike in &lt;strong&gt;com_insert/com_update/com_delete&lt;/strong&gt;, or just see slave lags, we turn to &lt;em&gt;Anemomaster &lt;/em&gt;and within a couple minutes know exactly what service is guilty of abusing our database. We are also working to protect our database against abuse, but that&#39;s for another discussion.&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>Speaking at Percona Live: common_schema, MySQL DevOps</title>
      <link>/blog/mysql/speaking-at-perconalive-common_schema-mysql-devops/</link>
      <pubDate>Mon, 10 Mar 2014 10:27:42 +0000</pubDate>
      
      <guid>/blog/mysql/speaking-at-perconalive-common_schema-mysql-devops/</guid>
      <description>&lt;p&gt;In less than a month I&#39;ll be giving these two talks at &lt;a href=&#34;https://www.percona.com/live/mysql-conference-2014/&#34;&gt;Percona Live&lt;/a&gt;:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href=&#34;https://www.percona.com/live/mysql-conference-2014/sessions/commonschema-dbas-framework-mysql&#34;&gt;common_schema: DBA&#39;s framework for MySQL&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;If you are still unfamiliar with &lt;a href=&#34;http://code.google.com/p/common-schema/&#34;&gt;common_schema,&lt;/a&gt; this will make for a good introduction. I&#39;ll give you multiple reasons why you would want to use it, and how it would come to &lt;em&gt;immediate&lt;/em&gt; use at your company. I do mean &lt;em&gt;immediate&lt;/em&gt;, as in previous &lt;em&gt;common_schema&lt;/em&gt; presentations I happened to get feedback emails from attendees within the same or next day letting me know how &lt;em&gt;common_schema&lt;/em&gt; solved an insistent problem of theirs or how it exposed an unknown status.&lt;/p&gt;
&lt;p&gt;I&#39;ll review some useful views &amp;amp; routines, and discuss the ease and power of QueryScript. &lt;em&gt;common_schema&lt;/em&gt; is a Swiss-knife of solutions, and all from within your MySQL server.&lt;/p&gt;
&lt;p&gt;I am using &lt;em&gt;common_schema&lt;/em&gt; in production on a regular basis, and it happened to be hero of the day in multiple occasions. I&#39;ll present a couple such cases.&lt;/p&gt;
&lt;p&gt;http://www.slideshare.net/shlominoach/commonschema-22-dbas-framework-for-mysql&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href=&#34;https://www.percona.com/live/mysql-conference-2014/sessions/mysql-devops-outbrain&#34;&gt;MySQL DevOps @ Outbrain&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;This is a technical talk touching at some cultural issues.&lt;/p&gt;
&lt;p&gt;At &lt;a href=&#34;http://www.outbrain.com/about/what-is-outbrain&#34;&gt;Outbrain&lt;/a&gt;, where I work, we have two blessings: a large group of engineers and a large dataset. We at the infrastructure team, together with the ops team, are responsible for the availability of the data. What we really like is technology which lets the owners of a problem be able to recognize it and take care of it. We want ops guys to do ops, and engineers to do engineering. And we want them to be able to talk to each other and &lt;em&gt;understand&lt;/em&gt; each other.&lt;/p&gt;
&lt;p&gt;What tools can you use to increase visibility? To allow sharing of data between the teams? I&#39;ll share some tools and techniques that allow us to automate deployments, detect a malfunctioning/abusing service, deploy schema changes across dozens of hosts, control data retention, monitor connections, and more.&lt;/p&gt;
&lt;p&gt;We like open source. The tools discussed are mostly open source, or open sourced by Outbrain.&lt;/p&gt;
&lt;p&gt;I&#39;ll explain why these tools matter, and how they serve the purpose of removing friction between teams, allowing for quick analysis of problems and overall visibility on all things that happen.&lt;/p&gt;
&lt;p&gt;http://www.slideshare.net/shlominoach/mysql-devops-at-outbrain&lt;/p&gt;
&lt;h4&gt;Do come by!&lt;/h4&gt;</description>
    </item>
    
  </channel>
</rss>