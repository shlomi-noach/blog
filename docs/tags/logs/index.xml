<?xml version="1.0" encoding="utf-8" standalone="yes" ?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>Logs on code.openark.org</title>
    <link>/blog/tags/logs/</link>
    <description>Recent content in Logs on code.openark.org</description>
    <generator>Hugo -- gohugo.io</generator>
    <language>en-us</language>
    <copyright>&amp;copy; 2016. All rights reserved.</copyright>
    <lastBuildDate>Wed, 15 Dec 2010 19:46:06 +0000</lastBuildDate>
    <atom:link href="/blog/tags/logs/index.xml" rel="self" type="application/rss+xml" />
    
    <item>
      <title>oak-hook-general-log: your poor man&#39;s Query Analyzer</title>
      <link>/blog/2010/12/15/oak-hook-general-log-your-poor-mans-query-analyzer/</link>
      <pubDate>Wed, 15 Dec 2010 19:46:06 +0000</pubDate>
      
      <guid>/blog/2010/12/15/oak-hook-general-log-your-poor-mans-query-analyzer/</guid>
      <description>&lt;p&gt;The latest release of &lt;a href=&#34;http://code.openark.org/forge/openark-kit&#34;&gt;openark kit&lt;/a&gt; introduces &lt;a href=&#34;http://openarkkit.googlecode.com/svn/trunk/openarkkit/doc/html/oak-hook-general-log.html&#34;&gt;oak-hook-general-log&lt;/a&gt;, a handy tool which allows for some analysis of executing queries.&lt;/p&gt;
&lt;p&gt;Initially I just intended for the tool to be able to dump the general log to standard output, from any machine capable to connect to MySQL. Quick enough, I realized the power it brings.&lt;/p&gt;
&lt;p&gt;With this tool, one can dump to standard output all queries using temporary tables; or using a specific index; or doing a full index scan; or just follow up on connections; or... For example, the following execution will only log queries which make for filesort:&lt;/p&gt;
&lt;blockquote&gt;
&lt;pre&gt;oak-hook-general-log --user=root --host=localhost --password=123456 --filter-explain-filesort&lt;/pre&gt;
&lt;/blockquote&gt;
&lt;h4&gt;The problem with using the standard logs&lt;/h4&gt;
&lt;p&gt;So you have the &lt;em&gt;general log&lt;/em&gt;, which you don&#39;t often enable, since it tends to grow huge within moments. You then have the &lt;em&gt;slow log&lt;/em&gt;. Slow log is great, and is among the top tools for MySQL diagnosis.&lt;/p&gt;
&lt;p&gt;The slow log allows for &lt;strong&gt;log-queries-not-using-indexes&lt;/strong&gt;, which is yet another nice feature. Not only should you log any query running for over &lt;strong&gt;X&lt;/strong&gt; seconds, but also log any query which does not use an index.&lt;/p&gt;
&lt;p&gt;Wait. This logs all single-row tables (no single row table will use an index), as well as very small tables (a common &lt;strong&gt;20&lt;/strong&gt; rows lookup table will most often be scanned). These are OK scans. This makes for some noise in the slow log.&lt;/p&gt;
&lt;p&gt;And how about queries which do use an index, but do so poorly? They use an index, but retrieve some &lt;strong&gt;12,500,000&lt;/strong&gt; rows, &lt;em&gt;using temporary&lt;/em&gt; table &amp;amp; &lt;em&gt;filesort&lt;/em&gt;?&lt;/p&gt;
&lt;h4&gt;What oak-hook-general-log does for you&lt;/h4&gt;
&lt;p&gt;This tool streams out the general log, and filters out queries based on their &lt;em&gt;role&lt;/em&gt; or on their &lt;em&gt;execution plan&lt;/em&gt;.&lt;/p&gt;
&lt;p&gt;To work at all, it must enable the general log. Moreover, it directs the general log to log table. Mind that this makes for a performance impact, which is why the tool auto-terminates and restores original log settings (default is &lt;strong&gt;1&lt;/strong&gt; minute, configurable). It&#39;s really not a tool you should keep running for days. But during the few moments it runs, it will:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Routinely rotate the &lt;strong&gt;mysql.general_log&lt;/strong&gt; table so that it doesn&#39;t fill up&lt;/li&gt;
&lt;li&gt;Examine entries found in the general log&lt;/li&gt;
&lt;li&gt;Cross reference entries to the PROCESSLIST so as to deduce database context (&lt;a href=&#34;http://bugs.mysql.com/bug.php?id=52554&#34;&gt;bug #52554&lt;/a&gt;)&lt;/li&gt;
&lt;li&gt;If required and appropriate, evaluate a query&#39;s execution plan&lt;/li&gt;
&lt;li&gt;Decide whether to dump each entry based on filtering rules&lt;/li&gt;
&lt;/ul&gt;
&lt;h4&gt;Filtering rules&lt;/h4&gt;
&lt;p&gt;Filtering rules are passed as command line options. At current, only one filtering rule applies (if more than one specified only one is used, so no point in passing more than one). Some of the rules are:&lt;!--more--&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;filter-connection&lt;/strong&gt;: only log connect/quit entries&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;filter-explain-fullscan&lt;/strong&gt;: only log full table scans&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;filter-explain-temporary&lt;/strong&gt;: only log queries which create implicit temporary tables&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;filter-explain-rows-exceed&lt;/strong&gt;: only log queries where more than &lt;strong&gt;X&lt;/strong&gt; number of rows are being accessed on some table (estimated)&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;filter-explain-total-rows-exceed&lt;/strong&gt;: only log queries where more than &lt;strong&gt;X&lt;/strong&gt; number of rows are accessed on all tables combined (estimated, with possibly incorrect numbers on some queries)&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;filter-explain-key&lt;/strong&gt;: only log queries using a specific index. This feature somewhat overlaps with Maatkit&#39;s &lt;em&gt;mk-index-usage&lt;/em&gt; (read &lt;a href=&#34;http://www.mysqlperformanceblog.com/2010/11/11/advanced-index-analysis-with-mk-index-usage/&#34;&gt;announcement&lt;/a&gt;).&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;filter-explain-contains&lt;/strong&gt;: a general purpose &lt;em&gt;grep&lt;/em&gt; on the execution plan. Log queries where the execution plan contains &lt;em&gt;some text&lt;/em&gt;.&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;There are other filters, and I will possibly add more in due time.&lt;/p&gt;
&lt;p&gt;Here are a couple cases I used &lt;em&gt;oak-hook-general-log&lt;/em&gt; for:&lt;/p&gt;
&lt;h4&gt;Use case: temporary tables&lt;/h4&gt;
&lt;p&gt;I have a server with this alarming chart (courtesy &lt;a href=&#34;http://code.openark.org/forge/mycheckpoint&#34;&gt;mycheckpoint&lt;/a&gt;) of temporary tables:&lt;/p&gt;
&lt;blockquote&gt;
&lt;pre /&gt;&lt;img class=&#34;alignnone&#34; title=&#34;Created tmp tables per second&#34; src=&#34;/blog/blog/assets/chart?cht=lc&amp;amp;chs=370x180&amp;amp;chts=303030,12&amp;amp;chtt=Latest+24+hours:+Dec+9,+06:30++-++Dec+10,+06:30&amp;amp;chf=c,s,ffffff&amp;amp;chdl=created_tmp_tables_psec|created_tmp_disk_tables_psec&amp;amp;chdlp=b&amp;amp;chco=ff8c00,4682b4&amp;amp;chd=s:yzzy02zzz100zzz0rv9zz0zyzyz0yy2xz1t11xzztz0xr1xt2tz07vwzz100100z31z111yz1vzzzzz1zs80r902s1111010y20z03z11487zz011z11011002w0q5rxxz0y00z0s02xy1yy0,gggfghggfgggghhgYekhhghhhhhghfjghhdihfhgdghgZhgcicihpcehhhhhhhifkigjihghjehgiigjgYqiYqgiaihiifkhekhfijgiihhggggggggggfhgghffZoYgggggggggdihfggghg&amp;amp;chxt=x,y&amp;amp;chxr=1,0,35.060000&amp;amp;chxl=0:||08:00||+||12:00||+||16:00||+||20:00||+||00:00||+||04:00||+|&amp;amp;chxs=0,505050,10,0,lt&amp;amp;chg=4.17,25,1,2,2.08,0&amp;amp;chxp=0,2.08,6.25,10.42,14.59,18.76,22.93,27.10,31.27,35.44,39.61,43.78,47.95,52.12,56.29,60.46,64.63,68.80,72.97,77.14,81.31,85.48,89.65,93.82,97.99&amp;amp;tsstart=2010-12-09+06:30:00&amp;amp;tsstep=600&#34; alt=&#34;&#34; width=&#34;370&#34; height=&#34;180&#34; /&gt;

&lt;/blockquote&gt;
What could possibly create &lt;strong&gt;30&lt;/strong&gt; temporary tables per second on average?

The slow log produced nothing helpful, even with &lt;strong&gt;log-queries-not-using-indexes&lt;/strong&gt; enabled. There were a lot of queries not using indexes there, but nothing at these numbers. With:
&lt;blockquote&gt;
&lt;pre&gt;oak-hook-general-log --filter-explain-temporary&lt;/pre&gt;
&lt;/blockquote&gt;
&lt;p&gt;enabled for &lt;strong&gt;1&lt;/strong&gt; minute, nothing came out. Weird. Enabled for &lt;strong&gt;5&lt;/strong&gt; minutes, I got one entry. Turned out a scheduled script, acting once per &lt;strong&gt;5&lt;/strong&gt; minutes, was making a single complicated query involving many nested views, which accounted for some &lt;em&gt;hundreds&lt;/em&gt; of temporary tables created. All of them very small, query time was very fast. There is no temporary tables problem with this server, case closed.&lt;/p&gt;
&lt;h4&gt;Use case: connections&lt;/h4&gt;
&lt;p&gt;A server had issues with some exceptions being thrown on the client side. There was a large number of new connections created per second although the client was using a connection pool. Suspecting the pool didn&#39;t work well, I issued:&lt;/p&gt;
&lt;blockquote&gt;
&lt;pre&gt;oak-hook-general-log --filter-connect&lt;/pre&gt;
&lt;/blockquote&gt;
&lt;p&gt;The pool was working well, all right. No entries for that client were recorder in &lt;strong&gt;1&lt;/strong&gt; minute of testing. However, it turned out some old script was flooding the MySQL server with requests, every second. The log showed root@somehost, and sure enough, the script was disabled. Exceptions were due to another reason; it was good to eliminate a suspect.&lt;/p&gt;
&lt;p&gt;Some of the tool&#39;s use case is relatively easy to solve with tail, grep &amp;amp; awk; others are not. I am using it more and more often, and find it to make significant shortcuts in tracking down queries.&lt;/p&gt;
&lt;h4&gt;Get it&lt;/h4&gt;
&lt;p&gt;Download the tool as part of &lt;em&gt;openark kit&lt;/em&gt;: access the &lt;a href=&#34;http://code.google.com/p/openarkkit/&#34;&gt;openark kit project page&lt;/a&gt;.&lt;/p&gt;
&lt;p&gt;Or get the &lt;a href=&#34;http://openarkkit.googlecode.com/svn/trunk/openarkkit/src/oak/oak-hook-general-log.py&#34;&gt;source code&lt;/a&gt; directly.&lt;/p&gt;
&lt;p&gt;Feedback is most welcome.&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>EXPLAIN: missing db info</title>
      <link>/blog/2010/05/11/explain-missing-db-info/</link>
      <pubDate>Tue, 11 May 2010 06:57:02 +0000</pubDate>
      
      <guid>/blog/2010/05/11/explain-missing-db-info/</guid>
      <description>&lt;p&gt;I&#39;m further developing a general log hook, which can stream queries from the general log.&lt;/p&gt;
&lt;p&gt;A particular direction I&#39;m taking is to filter queries by their type of actions. For example, the tool (&lt;a href=&#34;http://code.google.com/p/openarkkit/source/browse/trunk/openarkkit/src/oak/oak-hook-general-log.py&#34;&gt;oak-hook-general-log&lt;/a&gt;) can be instructed to only stream out those queries which involve creation of a temporary table; or those which cause for a filesort, or full index scan, etc.&lt;/p&gt;
&lt;p&gt;This is done by evaluating of query execution plans on the fly. I suspect the &lt;a href=&#34;http://www.mysql.com/why-mysql/white-papers/mysql_wp_queryanalyzer.php&#34;&gt;MySQL query analyzer&lt;/a&gt; roughly does the same (as a small part of what it does).&lt;/p&gt;
&lt;p&gt;It&#39;s almost nothing one cannot do with sed/awk. However, I bumped into a couple of problems:&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;The general log (and the &lt;strong&gt;mysql.general_log table&lt;/strong&gt;, in  particular) does not indicate the particular database one is using for the query. Since slow log does indicate this data, I &lt;a href=&#34;http://bugs.mysql.com/bug.php?id=52554&#34;&gt;filed a bug&lt;/a&gt; on this. I currently solve this by crossing connection id with the process list, where the current database is listed. It&#39;s shaky, but mostly works.&lt;/li&gt;
&lt;li&gt;Just realized: there&#39;s no DB info in the &lt;strong&gt;EXPLAIN&lt;/strong&gt; output! It&#39;s weird, since I&#39;ve been EXPLAINing queries for years now. But I&#39;ve always had the advantage of &lt;em&gt;knowing&lt;/em&gt; the schema used: either because I was manually executing the query on a known schema, or &lt;a href=&#34;http://www.maatkit.org/doc/mk-query-digest.html&#34;&gt;mk-query-digest&lt;/a&gt; was kind enough to let me know.&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;&lt;!--more--&gt;For example, look at the following imaginary query, involving both the &lt;strong&gt;world&lt;/strong&gt; and &lt;strong&gt;sakila&lt;/strong&gt; databases:&lt;/p&gt;
&lt;blockquote&gt;
&lt;pre&gt;mysql&amp;gt; use test;
Database changed
mysql&amp;gt; EXPLAIN SELECT * FROM world.Country JOIN sakila.city WHERE Country.Capital = city.city_id;
+----+-------------+---------+--------+---------------+---------+---------+-----------------------+------+-------------+
| id | select_type | table   | type   | possible_keys | key     | key_len | ref                   | rows | Extra       |
+----+-------------+---------+--------+---------------+---------+---------+-----------------------+------+-------------+
|  1 | SIMPLE      | Country | ALL    | NULL          | NULL    | NULL    | NULL                  |  239 |             |
|  1 | SIMPLE      | city    | eq_ref | PRIMARY       | PRIMARY | 2       | world.Country.Capital |    1 | Using where |
+----+-------------+---------+--------+---------------+---------+---------+-----------------------+------+-------------+
2 rows in set (0.00 sec)
&lt;/pre&gt;
&lt;/blockquote&gt;
&lt;p&gt;The query is imaginary, since the tables don&#39;t actually have anything in common. But look at the &lt;strong&gt;EXPLAIN&lt;/strong&gt; result: can you tell where &lt;strong&gt;city&lt;/strong&gt; came from? &lt;strong&gt;Country&lt;/strong&gt; can somehow be parsed from the &lt;strong&gt;ref&lt;/strong&gt; column, but no help on &lt;strong&gt;city&lt;/strong&gt;.&lt;/p&gt;
&lt;p&gt;Moreover, table aliases show on the &lt;strong&gt;EXPLAIN&lt;/strong&gt; plan (which is good), but with no reference to the original table.&lt;/p&gt;
&lt;p&gt;So, is it back to parsing of the SQL query? I&#39;m &lt;span style=&#34;text-decoration: line-through;&#34;&gt;lazy&lt;/span&gt; reluctant to do that. It&#39;s error prone, and one needs to implement, or use, a good parser, which also accepts MySQL dialect. Haven&#39;t looked into this yet.&lt;/p&gt;
&lt;p&gt;I&#39;m currently at a standstill with regard to automated query execution plan evaluation where database cannot be determined.&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>oak-hook-general-log: streaming general log</title>
      <link>/blog/2010/03/21/oak-hook-general-log-streaming-general-log/</link>
      <pubDate>Sun, 21 Mar 2010 10:45:58 +0000</pubDate>
      
      <guid>/blog/2010/03/21/oak-hook-general-log-streaming-general-log/</guid>
      <description>&lt;p&gt;I&#39;m seeking input on a new &lt;a href=&#34;http://code.openark.org/forge/openark-kit&#34;&gt;openark kit&lt;/a&gt; utility I&#39;ve started to implement.&lt;/p&gt;
&lt;p&gt;The tool, &lt;strong&gt;oak-hook-general-log&lt;/strong&gt;, will hook up to a MySQL (&amp;gt;= 5.1) server, and stream the general log into standard output. It looks like this:&lt;/p&gt;
&lt;blockquote&gt;
&lt;pre&gt;bash$ python src/oak/oak-hook-general-log.py --socket=/tmp/mysql.sock --user=root
2010-03-21 10:18:42     root[root] @ localhost []       79      1       Query   SELECT COUNT(*) FROM City
2010-03-21 10:18:48     root[root] @ localhost []       79      1       Query   DELETE FROM City WHERE id=1000
2010-03-21 10:18:54     root[root] @ localhost []       79      1       Query   SHOW PROCESSLIST
2010-03-21 10:19:06     root[root] @ localhost []       79      1       Quit
2010-03-21 10:19:07     root[root] @ localhost []       93      1       Connect root@localhost on
2010-03-21 10:19:07     root[root] @ localhost []       93      1       Query   select @@version_comment limit 1
2010-03-21 10:22:33     root[root] @ localhost []       93      1       Query   SELECT City.Name, Country.Name FROM Country JOIN City ON Country.Capit
2010-03-21 10:22:58     root[root] @ localhost []       93      1       Quit
&lt;/pre&gt;
&lt;/blockquote&gt;
&lt;p&gt;Since output is written to &lt;strong&gt;stdout&lt;/strong&gt;, one can further:&lt;/p&gt;
&lt;blockquote&gt;
&lt;pre&gt;bash$ python src/oak/oak-hook-general-log.py --socket=/tmp/mysql.sock --user=root | grep Connect
bash$ python src/oak/oak-hook-general-log.py --socket=/tmp/mysql.sock --user=root | grep webuser@webhost&lt;/pre&gt;
&lt;/blockquote&gt;
&lt;p&gt;What the tool does is to enable table logs, and periodically rotate the &lt;strong&gt;mysql.general_log&lt;/strong&gt; table, read and dump its content.&lt;/p&gt;
&lt;p&gt;&lt;!--more--&gt;The tool:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Stores and restores the original log state (general log enabled/disabled, log output).&lt;/li&gt;
&lt;li&gt;Disables printing of its own queries to the general log.&lt;/li&gt;
&lt;li&gt;Automatically times out (timeout configurable) so as not to enter a situation where the general log is forgotten to be turned on.&lt;/li&gt;
&lt;li&gt;Can discard pre-existing data on the &lt;strong&gt;mysql.general_log&lt;/strong&gt; table.&lt;/li&gt;
&lt;li&gt;Will cleanup the &lt;strong&gt;mysql.slow_log&lt;/strong&gt; table, if it wasn&#39;t originally used (turning on table logs applies to both general log and slow log).&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;What would you have the tool do further? Should it provide filtering, or should we just use &lt;strong&gt;grep&lt;/strong&gt;/&lt;strong&gt;sed&lt;/strong&gt;/&lt;strong&gt;awk&lt;/strong&gt; for that? Any internal aggregation of data?&lt;/p&gt;
&lt;p&gt;I would love to hear your thoughts. Meanwhile, &lt;a href=&#34;http://code.google.com/p/openarkkit/source/browse/trunk/openarkkit/src/oak/oak-hook-general-log.py&#34;&gt;view or grab the python script file&lt;/a&gt;.&lt;/p&gt;</description>
    </item>
    
  </channel>
</rss>