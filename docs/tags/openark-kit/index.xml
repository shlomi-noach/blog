<?xml version="1.0" encoding="utf-8" standalone="yes" ?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>Openark Kit on code.openark.org</title>
    <link>/blog/tags/openark-kit/</link>
    <description>Recent content in Openark Kit on code.openark.org</description>
    <generator>Hugo -- gohugo.io</generator>
    <language>en-us</language>
    <copyright>&amp;copy; 2016. All rights reserved.</copyright>
    <lastBuildDate>Wed, 26 Jun 2013 21:46:57 +0000</lastBuildDate>
    <atom:link href="/blog/tags/openark-kit/index.xml" rel="self" type="application/rss+xml" />
    
    <item>
      <title>common_schema &amp; openark-kit in the media: #DBHangOps, OurSQL</title>
      <link>/blog/2013/06/26/common_schema-openark-kit-in-the-media-dbhangops-oursql/</link>
      <pubDate>Wed, 26 Jun 2013 21:46:57 +0000</pubDate>
      
      <guid>/blog/2013/06/26/common_schema-openark-kit-in-the-media-dbhangops-oursql/</guid>
      <description>&lt;h4&gt;#DBHangOps&lt;/h4&gt;
&lt;p&gt;I had the pleasure of joining into &lt;a href=&#34;https://twitter.com/DBHangops&#34;&gt;@DBHangOps&lt;/a&gt; today, and speak about &lt;a href=&#34;https://code.google.com/p/common-schema/&#34;&gt;common_schema&lt;/a&gt; and &lt;a href=&#34;http://code.google.com/p/openarkkit/&#34;&gt;openark-kit&lt;/a&gt;. What was meant to be a 15 minute session turned to be 50 -- sorry, people, I don&#39;t talk as much at home, but when it comes to my pet projects...&lt;/p&gt;
&lt;p&gt;I also realized I was missing on a great event: DBHangOps is a hangout where you can chat and discuss MySQL &amp;amp; related technologies with friends and colleagues, with whom you typically only meet at conferences. I will certainly want to attend future events.&lt;/p&gt;
&lt;p&gt;Thanks to John Cesario and Geoffrey Anderson who invited me to talk, and to the friends and familiar faces who attended; I was happy to talk about my work, and very interested in hearing about how it&#39;s being put to use. We also had time to discuss &lt;a href=&#34;http://www.markleith.co.uk/ps_helper/&#34;&gt;ps_helper&lt;/a&gt; with no other than Mark Leith!&lt;/p&gt;
&lt;p&gt;The video is &lt;a href=&#34;https://twitter.com/DBHangops/status/349965939690835970&#34;&gt;available on Twitter/YouTube&lt;/a&gt;.&lt;/p&gt;
&lt;h4&gt;OurSQL&lt;/h4&gt;
&lt;p&gt;&lt;em&gt;openark-kit&lt;/em&gt; has also been &lt;a href=&#34;http://technocation.org/content/oursql-episode-143%3A-biblical-tools&#34;&gt;featured on the OurSQL podcast&lt;/a&gt; by Sheeri &amp;amp; Gerry, who did great coverage of some tools. I will disclose that more is to come; I&#39;m happy this is in capable hands and look further to hear the next episode!&lt;/p&gt;
&lt;p&gt;&amp;nbsp;&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>opeark-kit revision 196 released</title>
      <link>/blog/2013/05/07/opeark-kit-revision-196-released/</link>
      <pubDate>Tue, 07 May 2013 07:47:22 +0000</pubDate>
      
      <guid>/blog/2013/05/07/opeark-kit-revision-196-released/</guid>
      <description>&lt;p&gt;This is a long due maintenance release of &lt;a href=&#34;http://code.google.com/p/openarkkit/&#34;&gt;&lt;strong&gt;openark-kit&lt;/strong&gt;.&lt;/a&gt; This release includes bugfixes and some enhancements, mainly to &lt;a href=&#34;http://openarkkit.googlecode.com/svn/trunk/openarkkit/doc/html/oak-online-alter-table.html&#34;&gt;oak-online-alter-table&lt;/a&gt;.&lt;/p&gt;
&lt;p&gt;&lt;em&gt;oak-online-alter-table&lt;/em&gt; Changes / bug fixes include:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Support for keyword-named columns&lt;/li&gt;
&lt;li&gt;Use of FORCE INDEX due to lack of MySQL&#39;s ability for figure out the chunking key at all times&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;--sleep-ratio&lt;/strong&gt; option added; allows for sleep time proportional to execution time (as opposed to constant sleep time with &lt;strong&gt;--sleep&lt;/strong&gt;)&lt;/li&gt;
&lt;li&gt;Support for chunk-retry (in case of deadlock) via &lt;strong&gt;--max-lock-retries&lt;/strong&gt;)&lt;/li&gt;
&lt;li&gt;Fixed order of cleanup&lt;/li&gt;
&lt;li&gt;Fixed bug with verbose messages with non-integer chunking key&lt;/li&gt;
&lt;li&gt;Fixed bug with single-row tables (people, no need for this tool for single row tables :))&lt;/li&gt;
&lt;li&gt;Friendly verbose messages to remind you what&#39;s being executed&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;em&gt;oak-chunk-update&lt;/em&gt; changes includes:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Verbosing query comment if exists (friendly printing of what&#39;s being executed)&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;!--more--&gt;(Do check out &lt;a href=&#34;http://common-schema.googlecode.com/svn/trunk/common_schema/doc/html/query_script_split.html&#34;&gt;QueryScript&#39;s split()&lt;/a&gt;; it&#39;s a simple, server side solution which works almost same way as &lt;em&gt;oak-chunk-update&lt;/em&gt;)&lt;/p&gt;
&lt;p&gt;More issues and changes not listed here.&lt;/p&gt;
&lt;h4&gt;Download&lt;/h4&gt;
&lt;p&gt;&lt;em&gt;openark-kit&lt;/em&gt; is released under the new BSD license, and is freely available.&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href=&#34;http://code.google.com/p/openarkkit/&#34;&gt;Download latest openark-kit revision (#196)&lt;/a&gt;.&lt;/li&gt;
&lt;li&gt;Browse &lt;a href=&#34;http://openarkkit.googlecode.com/svn/trunk/openarkkit/doc/html/introduction.html&#34;&gt;openark-kit documentation&lt;/a&gt;.&lt;/li&gt;
&lt;/ul&gt;</description>
    </item>
    
    <item>
      <title>Speaking at Percona Live 2013: common_schema, lightning talks</title>
      <link>/blog/2013/04/11/speaking-at-percona-live-2013-common_schema-lightning-talks/</link>
      <pubDate>Thu, 11 Apr 2013 07:17:04 +0000</pubDate>
      
      <guid>/blog/2013/04/11/speaking-at-percona-live-2013-common_schema-lightning-talks/</guid>
      <description>&lt;p&gt;In two weeks time I will be giving these talks at Percona Live:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href=&#34;http://www.percona.com/live/mysql-conference-2013/sessions/commonschema-dbas-framework-mysql&#34;&gt;common_schema: DBA&#39;s framework for MySQL&lt;/a&gt;: an introduction to &lt;a href=&#34;https://code.google.com/p/common-schema/&#34;&gt;common_schema&lt;/a&gt;, my evolving server side solutions project. This will be a revised version of the talk I gave at Percona Live London; I have felt some weaknesses during that talk, which I&#39;ve thrown out, letting room for cool stuff. I will discuss &lt;em&gt;common_schema&lt;/em&gt;&#39;s various views, interesting and useful routines, the power of &lt;strong&gt;&lt;a href=&#34;http://common-schema.googlecode.com/svn/trunk/common_schema/doc/html/query_script.html&#34;&gt;QueryScript&lt;/a&gt;&lt;/strong&gt;, and a brief intro to the newcomer &lt;strong&gt;&lt;a href=&#34;http://common-schema.googlecode.com/svn/trunk/common_schema/doc/html/rdebug.html&#34;&gt;rdebug&lt;/a&gt;&lt;/strong&gt;, debugger and debugging API for MySQL. If you&#39;re not familiar with &lt;em&gt;common_schema&lt;/em&gt;, it&#39;s a good time to pick up on what I (being most biased) consider to be your smart assistant to MySQL maintenance and administration!&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;http://www.percona.com/live/mysql-conference-2013/sessions/lt-query-which-peak-my-career&#34;&gt;The query which is the peak of my career&lt;/a&gt;: this is a 6 minute lightning talk. You&#39;re bound to attend if you&#39;re at the community reception (which you are), so I don&#39;t need to do promotional. You already payed the ticket and the doors will be locked. No escapees.&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;As far as I&#39;m concerned the conference can be closed down the moment I provide these two talks, and we can all go to the beach.&lt;/p&gt;
&lt;p&gt;Wait, no, I will also be at the DotOrg Pavillion at the &lt;a href=&#34;http://www.percona.com/live/mysql-conference-2013/exhibit-hall&#34;&gt;Exhibit Hall&lt;/a&gt;, where I present &lt;em&gt;common_schema&lt;/em&gt; and &lt;a href=&#34;http://openarkkit.googlecode.com/svn/trunk/openarkkit/doc/html/introduction.html&#34;&gt;openark-kit&lt;/a&gt;. Come by to hear more about these!&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>common_schema over traditional scripts</title>
      <link>/blog/2012/12/12/common_schema-over-traditional-scripts/</link>
      <pubDate>Wed, 12 Dec 2012 13:55:44 +0000</pubDate>
      
      <guid>/blog/2012/12/12/common_schema-over-traditional-scripts/</guid>
      <description>&lt;p&gt;If you are familiar with both &lt;a href=&#34;http://code.openark.org/forge/openark-kit&#34;&gt;openark kit&lt;/a&gt; and &lt;a href=&#34;http://code.google.com/p/common-schema&#34;&gt;common_schema&lt;/a&gt;, you&#39;ll notice I&#39;ve incorporated some functionality already working in &lt;em&gt;openark kit&lt;/em&gt; into &lt;em&gt;common_schema&lt;/em&gt;, essentially rewriting what used to be a Python script into SQL/&lt;a href=&#34;http://common-schema.googlecode.com/svn/trunk/common_schema/doc/html/query_script.html&#34;&gt;QueryScript&lt;/a&gt;.&lt;/p&gt;
&lt;p&gt;What was my reasoning for rewriting good code? I wish to explain that, and provide with a couple examples.&lt;/p&gt;
&lt;p&gt;I&#39;m generally interested in pushing as much functionality into the MySQL server. When using an external script, one:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Needs the right dependencies (OS, Perl/Python version, Perl/Python modules).&lt;/li&gt;
&lt;li&gt;Needs to provide with connection params,&lt;/li&gt;
&lt;li&gt;Needs to get acquainted with a lot of command line options,&lt;/li&gt;
&lt;li&gt;Is limited by whatever command line options are provided.&lt;/li&gt;
&lt;li&gt;Has to invoke that script (duh!) to get the work done.&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;This last bullet is not so trivial: it means you can&#39;t work some operation with your favorite GUI client, because it has no notion of your Perl script; does not run on the same machine where your Python code resides; simply can&#39;t run those scripts for you.&lt;/p&gt;
&lt;p&gt;With server-side code, functionality is accessible via any client. You run your operation via a query (e.g. &lt;strong&gt;CALL some_procedure&lt;/strong&gt;). That can be done from your GUI client, your command line client, your event scheduler, your cronjob, all equally. You only need access to your MySQL server, which is trivial.&lt;/p&gt;
&lt;p&gt;Of course, server side scripting is &lt;a href=&#34;http://code.openark.org/blog/mysql/things-that-cant-and-some-that-can-be-done-from-within-a-mysql-stored-routine&#34;&gt;limited&lt;/a&gt;. Some stuff simply can&#39;t be written solely on server side. If you want to consult your replicating slave; gracefully take action on user&#39;s &lt;strong&gt;Ctrl+C&lt;/strong&gt;, send data over the web, you&#39;ll have to do it with an external tool. There are actually a lot of surprising limitations to things one would assume &lt;em&gt;are&lt;/em&gt; possible on server side. You may already know how frustrated I am by the fact one can &lt;a href=&#34;http://code.openark.org/blog/mysql/reading-results-of-show-statements-on-server-side&#34;&gt;hardly&lt;/a&gt; get info from &lt;strong&gt;SHOW&lt;/strong&gt; commands.&lt;/p&gt;
&lt;h4&gt;But, when it works, it shines&lt;/h4&gt;
&lt;p&gt;Let&#39;s review a couple examples. The first one is nearly trivial. The second less so.&lt;!--more--&gt;&lt;/p&gt;
&lt;h4&gt;Example: getting AUTO_INCREMENT &#34;free space&#34;&lt;/h4&gt;
&lt;p&gt;&lt;em&gt;openark kit&lt;/em&gt; offers &lt;a href=&#34;http://openarkkit.googlecode.com/svn/trunk/openarkkit/doc/html/oak-show-limits.html&#34;&gt;oak-show-limits&lt;/a&gt;. It&#39;s a tool that tells you if any of your &lt;strong&gt;AUTO_INCREMENT&lt;/strong&gt; columns are running out of space (and so you might want to &lt;strong&gt;ALTER&lt;/strong&gt; that &lt;strong&gt;INT&lt;/strong&gt; to &lt;strong&gt;BIGINT&lt;/strong&gt;).&lt;/p&gt;
&lt;p&gt;It&#39;s a very simple Python script. It gets your &lt;strong&gt;MAX(auto_increment_column) FROM tables_with_auto_increment&lt;/strong&gt;, and compares that &lt;strong&gt;MAX&lt;/strong&gt; value to the column type. It pre-computes:&lt;/p&gt;
&lt;blockquote&gt;
&lt;pre&gt;max_values[&#39;tinyint&#39;] = 2**8
max_values[&#39;smallint&#39;] = 2**16
max_values[&#39;mediumint&#39;] = 2**24
max_values[&#39;int&#39;] = 2**32
max_values[&#39;bigint&#39;] = 2**64&lt;/pre&gt;
&lt;/blockquote&gt;
&lt;p&gt;takes care of &lt;strong&gt;SIGNED/UNSIGNED&lt;/strong&gt;, and does the math. Why is this tool such a perfect candidate for &lt;a href=&#34;http://common-schema.googlecode.com/svn/trunk/common_schema/doc/html/auto_increment_columns.html&#34;&gt;replacement on server side&lt;/a&gt;? For two reasons.&lt;/p&gt;
&lt;p&gt;First, It turns out it takes very little effort to &lt;a href=&#34;http://code.openark.org/blog/mysql/checking-for-auto_increment-capacity-with-single-query&#34;&gt;build a query&lt;/a&gt; which does the same. In which case it is also easy to build a view which provides the same.&lt;/p&gt;
&lt;p&gt;Second, there&#39;s this thing with command line arguments. The &lt;em&gt;openark&lt;/em&gt; tool provides with &lt;strong&gt;--threshold&lt;/strong&gt; (only output those columns where capacity is larger than &lt;strong&gt;x%&lt;/strong&gt;), &lt;strong&gt;--database&lt;/strong&gt; (only scan given database), &lt;strong&gt;--table&lt;/strong&gt; (only for tables matching name), &lt;strong&gt;--column&lt;/strong&gt; (only for columns matching name).&lt;/p&gt;
&lt;p&gt;I don&#39;t like this. See, the above is essentially an extra layer for saying:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;WHERE&lt;/strong&gt; auto_increment_ratio &amp;gt;= x&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;WHERE&lt;/strong&gt; table_schema = ...&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;WHERE&lt;/strong&gt; table_name = ...&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;WHERE&lt;/strong&gt; column_name = ...&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;The command line arguments each take the role of some &lt;strong&gt;WHERE/AND&lt;/strong&gt; condition.Wow, what a &lt;strong&gt;1-1&lt;/strong&gt; mapping. How about if I wanted the results sorted in some specific order? I would have to add a command line argument for that! How about only listing the &lt;strong&gt;SIGNED&lt;/strong&gt; columns? I would have to add a command line argument for that, too! How about showing top &lt;strong&gt;10&lt;/strong&gt;? Yes, another command line argument!&lt;/p&gt;
&lt;p&gt;Some of the above can be solved via shell scripting (&lt;strong&gt;sort -k 3 -n&lt;/strong&gt;, &lt;strong&gt;head -n 10&lt;/strong&gt;, etc.). But, hey, we&#39;re OK with SQL, aren&#39;t we? Why add now these &lt;em&gt;two extra layers&lt;/em&gt;? Get to know all the command line options, get to script it? I love scripting, but this is an abuse.&lt;/p&gt;
&lt;p&gt;So it makes much more sense, in my opinion, to &lt;strong&gt;SELECT * FROM auto_increment_columns WHERE table_schema=&#39;my_db&#39; AND auto_increment_ratio &amp;gt;= 0.8 ORDER BY auto_increment_ratio DESC LIMIT 10&lt;/strong&gt;. It doesn&#39;t require SQL-fu skills, just basic SQL skills which every DBA and DB user are expected to have. And it allows one to work from whatever environment one feels comfortable with. Heck, with your GUI editor you can probably get off with it by right-clicking and left-clicking your mouse buttons, never typing one character.&lt;/p&gt;
&lt;h4&gt;Example: blocking user accounts&lt;/h4&gt;
&lt;p&gt;The above mapped very easily to a query, and was just a read-only query. What if we had to modify data? &lt;a href=&#34;http://openarkkit.googlecode.com/svn/trunk/openarkkit/doc/html/oak-block-account.html&#34;&gt;oak-block-accounts&lt;/a&gt; is a tool which allows one to block grantees from logging in, then releasing them later on. &lt;em&gt;common_schema&lt;/em&gt; offers &lt;a href=&#34;common-schema.googlecode.com/svn/trunk/common_schema/doc/html/sql_accounts.html&#34;&gt;sql_accounts&lt;/a&gt; and &lt;a href=&#34;file:///home/shlomi/workspace/common_schema/doc/html/eval.html&#34;&gt;eval()&lt;/a&gt;.&lt;/p&gt;
&lt;p&gt;Let&#39;s skip the command line arguments issue, as it is identical to the above. How should we best provide with &#34;taking action&#34; interface? A script would have no problem to first &lt;strong&gt;SELECT&lt;/strong&gt; stuff, then &lt;strong&gt;UPDATE&lt;/strong&gt;, or &lt;strong&gt;SET PASSWORD&lt;/strong&gt;, or &lt;strong&gt;DROP&lt;/strong&gt; etc. How easy is it to do the same on server side?&lt;/p&gt;
&lt;p&gt;The immediate solution is to write a stored procedure to do that. I reject the idea. Why? Because the procedure would look like this:&lt;/p&gt;
&lt;blockquote&gt;
&lt;pre&gt;PROCEDURE block_account(user VARCHAR(64), host VARCHAR(64), only_if_empty_password BOOL, ...);&lt;/pre&gt;
&lt;/blockquote&gt;
&lt;p&gt;Can you see where I&#39;m getting at? Doing the above re-introduces command line options, this time disguised as procedure parameters. We would again have to list all available filtering methods, only this time things are worse: since stored procedures have no such notion as overloading, and change to the params will break compatibility. Once we introduce this routine, we&#39;re stuck with it.&lt;/p&gt;
&lt;p&gt;&lt;em&gt;common_schema&lt;/em&gt; tries to stay away as far as it can from this pitfall. It presents another solution: the &lt;em&gt;view&lt;/em&gt; solution. Just as with &lt;em&gt;auto_increment_columns&lt;/em&gt;, &lt;strong&gt;SELECT&lt;/strong&gt; your way to get the right rows. But this time, the result is a SQL query:&lt;/p&gt;
&lt;blockquote&gt;
&lt;pre&gt;mysql&amp;gt; SELECT &lt;strong&gt;sql_block_account&lt;/strong&gt; FROM &lt;strong&gt;sql_accounts&lt;/strong&gt; &lt;strong&gt;WHERE USER = &#39;gromit&#39;&lt;/strong&gt;;
+-------------------------------------------------------------------------------------+
| sql_block_account                                                                   |
+-------------------------------------------------------------------------------------+
| SET PASSWORD FOR &#39;gromit&#39;@&#39;localhost&#39; = &#39;752AA50E562A6B40DE87DF0FA69FACADD908EA32*&#39; |
+-------------------------------------------------------------------------------------+&lt;/pre&gt;
&lt;/blockquote&gt;
&lt;p&gt;Do your own &lt;strong&gt;WHERE&lt;/strong&gt;/&lt;strong&gt;AND&lt;/strong&gt; combination in SQL. But, how to take action? Our view cannot take the actual action for us!&lt;/p&gt;
&lt;p&gt;&lt;em&gt;eval()&lt;/em&gt; is at the core of many common_schema operations, like this one:&lt;/p&gt;
&lt;blockquote&gt;
&lt;pre&gt;CALL &lt;strong&gt;eval&lt;/strong&gt;(&lt;span style=&#34;color: #000080;&#34;&gt;&#34;SELECT &lt;strong&gt;sql_block_account&lt;/strong&gt; FROM &lt;strong&gt;sql_accounts WHERE USER = &#39;gromit&#39;&lt;/strong&gt;&#34;&lt;/span&gt;);&lt;/pre&gt;
&lt;/blockquote&gt;
&lt;p&gt;The &lt;strong&gt;SET PASSWORD&lt;/strong&gt; query just got evaluated. Meaning it was executed. &lt;em&gt;eval()&lt;/em&gt; is a very powerful solution.&lt;/p&gt;
&lt;h4&gt;Conclusion&lt;/h4&gt;
&lt;p&gt;I prefer stuff on server side. It requires basic SQL skills (or a smart GUI editor), and allows you easy access to a lot of functionality, removing dependency requirements. It is not always possible, and external scripts can do miracles not possible on server side, but server side scripting has its own miracles.&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>State of InnDB Online DDL in MySQL 5.6.8-RC</title>
      <link>/blog/2012/11/20/state-of-inndb-online-ddl-in-mysql-5-6-8-rc/</link>
      <pubDate>Tue, 20 Nov 2012 11:49:14 +0000</pubDate>
      
      <guid>/blog/2012/11/20/state-of-inndb-online-ddl-in-mysql-5-6-8-rc/</guid>
      <description>&lt;p&gt;&lt;strong&gt;5.6.8-rc&lt;/strong&gt; is out, and so I&#39;m following up on InnoDB&#39;s online DDL new feature: the ability to SELECT, INSERT, DELETE, UPDATE a table even while an ALTER TABLE is executing on same table.&lt;/p&gt;
&lt;h4&gt;The brief summary&lt;/h4&gt;
&lt;p&gt;Not as advertised; many things can&#39;t be done.&lt;/p&gt;
&lt;h4&gt;The longer review&lt;/h4&gt;
&lt;p&gt;I&#39;m using &lt;strong&gt;5.6.8-rc 64bit&lt;/strong&gt; binary distribution for Linux, installed via &lt;a href=&#34;http://mysqlsandbox.net/&#34;&gt;mysqlsandbox&lt;/a&gt;. My hardware is irrelevant, but the fact I&#39;m testing on my laptop assists me in that &lt;strong&gt;ALTER TABLE&lt;/strong&gt; operations take a while, so that I&#39;m able to easily type commands in two terminals and have the time to watch them being executed. Query cache is disabled.&lt;!--more--&gt;&lt;/p&gt;
&lt;p&gt;I&#39;m using the sakila sample database, and in particular I&#39;m working with the rental table. Here&#39;s the table definition:&lt;/p&gt;
&lt;blockquote&gt;
&lt;pre&gt;CREATE TABLE `rental` (
  `rental_id` int(11) NOT NULL AUTO_INCREMENT,
  `rental_date` datetime NOT NULL,
  `inventory_id` mediumint(8) unsigned NOT NULL,
  `customer_id` smallint(5) unsigned NOT NULL,
  `return_date` datetime DEFAULT NULL,
  `staff_id` tinyint(3) unsigned NOT NULL,
  `last_update` timestamp NOT NULL DEFAULT CURRENT_TIMESTAMP ON UPDATE CURRENT_TIMESTAMP,
  PRIMARY KEY (`rental_id`),
  UNIQUE KEY `rental_date` (`rental_date`,`inventory_id`,`customer_id`),
  KEY `idx_fk_inventory_id` (`inventory_id`),
  KEY `idx_fk_customer_id` (`customer_id`),
  KEY `idx_fk_staff_id` (`staff_id`),
  CONSTRAINT `fk_rental_staff` FOREIGN KEY (`staff_id`) REFERENCES `staff` (`staff_id`) ON UPDATE CASCADE,
  CONSTRAINT `fk_rental_inventory` FOREIGN KEY (`inventory_id`) REFERENCES `inventory` (`inventory_id`) ON UPDATE CASCADE,
  CONSTRAINT `fk_rental_customer` FOREIGN KEY (`customer_id`) REFERENCES `customer` (`customer_id`) ON UPDATE CASCADE
) ENGINE=InnoDB AUTO_INCREMENT=16050 DEFAULT CHARSET=utf8&lt;/pre&gt;
&lt;/blockquote&gt;
&lt;p&gt;Highlights for the table: &lt;strong&gt;AUTO_INCREMENT PRIMARY KEY&lt;/strong&gt;, some columns indexed, some not, and Foreign Keys in place. Pretty much a standard table. It contains &lt;strong&gt;16,044&lt;/strong&gt; rows. Row format is &lt;strong&gt;COMPACT&lt;/strong&gt;.&lt;/p&gt;
&lt;p&gt;What I want to know is: which DDL commands allow for which online DML commands?&lt;/p&gt;
&lt;p&gt;So, on terminal #1 I will issue queries like:&lt;/p&gt;
&lt;blockquote&gt;
&lt;pre&gt;node1 5.6.8-rc-log sakila&amp;gt; alter table &lt;strong&gt;sakila.rental&lt;/strong&gt; ROW_FORMAT=COMPACT &lt;strong&gt;/* or whatever */&lt;/strong&gt;;
Query OK, 0 rows affected (10.57 sec)
Records: 0  Duplicates: 0  Warnings: 0&lt;/pre&gt;
&lt;/blockquote&gt;
&lt;p&gt;And during the above operation, I will execute the following on terminal #2:&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;&lt;strong&gt;select max(rental_id) from sakila.rental;&lt;/strong&gt; this queries the AUTO_INCREMENT value, which is of course a PRIMARY KEY&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;select min(rental_date) from sakila.rental&lt;/strong&gt;; there is an index on rental_date, and normal execution plan is to optimize table away and just use the index&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;select min(return_date) from sakila.rental&lt;/strong&gt;; there is no index on return_date, and full table scan is required&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;update rental set return_date = return_date + interval 1 second where rental_id=3&lt;/strong&gt;; the UPDATE uses the PRIMARY KEY&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;update rental set return_date = return_date + interval 1 second where return_date = NOW()&lt;/strong&gt;; won&#39;t actually affect anything, but requires full scan.&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;So here are the results:&lt;/p&gt;
&lt;blockquote&gt;
&lt;pre&gt;+-------------------------------------------------------------+-------+---------------------------+---------------+---------------------+-------------------------+--------------+---------------------+
| ALTER statement                                             | Time  | General comments          | select max PK | select min by index | select min by full scan | update by PK | update by full scan |
+-------------------------------------------------------------+-------+---------------------------+---------------+---------------------+-------------------------+--------------+---------------------+
| ROW_FORMAT=COMPACT                                          | 10.92 |                           | &lt;span style=&#34;color: #008000;&#34;&gt;Instant&lt;/span&gt;       | &lt;span style=&#34;color: #008000;&#34;&gt;Instant&lt;/span&gt;             | &lt;span style=&#34;color: #008000;&#34;&gt;Instant&lt;/span&gt;                 | &lt;span style=&#34;color: #800000;&#34;&gt;blocked&lt;/span&gt;      | &lt;span style=&#34;color: #800000;&#34;&gt;blocked&lt;/span&gt;             |
| AUTO_INCREMENT=16051                                        |  0.06 | Instant, no table rebuild | N/A           | N/A                 | N/A                     | N/A          | N/A                 |
| ADD INDEX(last_update)                                      |  2.37 |                           | &lt;span style=&#34;color: #800000;&#34;&gt;blocked&lt;/span&gt;       | &lt;span style=&#34;color: #800000;&#34;&gt;blocked&lt;/span&gt;             | &lt;span style=&#34;color: #800000;&#34;&gt;blocked&lt;/span&gt;                 | &lt;span style=&#34;color: #800000;&#34;&gt;blocked&lt;/span&gt;      | &lt;span style=&#34;color: #800000;&#34;&gt;blocked&lt;/span&gt;             |
| ADD INDEX(last_update), ALGORITHM=INPLACE                   |  1.83 |                           | &lt;span style=&#34;color: #800000;&#34;&gt;blocked&lt;/span&gt;       | &lt;span style=&#34;color: #800000;&#34;&gt;blocked&lt;/span&gt;             | &lt;span style=&#34;color: #800000;&#34;&gt;blocked&lt;/span&gt;                 | &lt;span style=&#34;color: #800000;&#34;&gt;blocked&lt;/span&gt;      | &lt;span style=&#34;color: #800000;&#34;&gt;blocked&lt;/span&gt;             |
| ADD INDEX(last_update), ALGORITHM=INPLACE, LOCK=NONE        |  0.00 | ERROR 1235 (42000): ...   | N/A           | N/A                 | N/A                     | N/A          | N/A                 |
| ADD COLUMN c CHAR(1) NOT NULL                               | 11.20 |                           | &lt;span style=&#34;color: #008000;&#34;&gt;Instant&lt;/span&gt;       | &lt;span style=&#34;color: #008000;&#34;&gt;Instant&lt;/span&gt;             | &lt;span style=&#34;color: #008000;&#34;&gt;Instant&lt;/span&gt;                 | &lt;span style=&#34;color: #800000;&#34;&gt;blocked&lt;/span&gt;      | &lt;span style=&#34;color: #800000;&#34;&gt;blocked&lt;/span&gt;             |
| ADD COLUMN c CHAR(1) NOT NULL, ALGORITHM=INPLACE, LOCK=NONE |  0.00 | ERROR 1235 (42000): .     | N/A           | N/A                 | N/A                     | N/A          | N/A                 |
+-------------------------------------------------------------+-------+---------------------------+---------------+---------------------+-------------------------+--------------+---------------------+&lt;/pre&gt;
&lt;/blockquote&gt;
&lt;p&gt;Rather surprising, I would say.&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;em&gt;None&lt;/em&gt; of my tests resolved with online write (&lt;strong&gt;UPDATE&lt;/strong&gt;). At best I could get online read (&lt;strong&gt;SEELCT&lt;/strong&gt;).&lt;br /&gt;
&lt;strong&gt;&lt;/strong&gt;&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;AUTO_INCREMENT&lt;/strong&gt; is instantaneous. High time for that! It&#39;s just some number in the &lt;strong&gt;.frm&lt;/strong&gt; file, never understood the need for table rebuild.&lt;/li&gt;
&lt;li&gt;Apparently &lt;strong&gt;ADD COLUMN&lt;/strong&gt; is &lt;em&gt;more online&lt;/em&gt; than &lt;strong&gt;ADD INDEX&lt;/strong&gt;, and I&#39;ve tested this again and again and again to make sure I was doing it right. This is quite weird, even according to the &lt;a href=&#34;http://dev.mysql.com/doc/refman/5.6/en/innodb-online-ddl.html&#34;&gt;docs&lt;/a&gt;.&lt;/li&gt;
&lt;li&gt;In none of the above tests (and others, non listed), have I been able to specify &lt;strong&gt;LOCK=NONE&lt;/strong&gt;. It&#39;s always &lt;strong&gt;ERROR 1235 (42000): This version of MySQL doesn&#39;t yet support &#39;alter table sakila.rental &amp;lt;whatever&amp;gt;, algorithm=inplace, lock=none&#39;&lt;/strong&gt;.&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;So what&#39;s so online about this? Online reads are nice, but most everyone cannot accept blocking writes (for same reason no one would use &lt;em&gt;mysqlhotcopy&lt;/em&gt;, also so wrongly named). This leaves us again with &lt;a href=&#34;http://openarkkit.googlecode.com/svn/trunk/openarkkit/doc/html/oak-online-alter-table.html&#34;&gt;oak-online-alter-table&lt;/a&gt; and &lt;a href=&#34;http://www.percona.com/doc/percona-toolkit/2.1/pt-online-schema-change.html&#34;&gt;pt-online-schema-change&lt;/a&gt;.&lt;/p&gt;
&lt;h4&gt;The butler did it&lt;/h4&gt;
&lt;p&gt;Apologies to the butler, the &lt;strong&gt;FOREIGN KEY&lt;/strong&gt;s did it. Let&#39;s try the same again without foreign keys:&lt;/p&gt;
&lt;blockquote&gt;
&lt;pre&gt;node1 5.6.8-rc-log sakila&amp;gt; create table rental2 like rental;
node1 5.6.8-rc-log sakila&amp;gt; insert into rental2 select * from rental;
node1 5.6.8-rc-log sakila&amp;gt; rename table rental to rental_old, rental2 to rental;
Query OK, 0 rows affected (0.31 sec)&lt;/pre&gt;
&lt;/blockquote&gt;
&lt;p&gt;Here are the results:&lt;/p&gt;
&lt;blockquote&gt;
&lt;pre&gt;+-------------------------------------------------------------+-------+---------------------------+----------------+---------------------+-------------------------+----------------+---------------------+
| ALTER statement                                             | Time  | General comments          | select max PK  | select min by index | select min by full scan | update by PK   | update by full scan |
+-------------------------------------------------------------+-------+---------------------------+----------------+---------------------+-------------------------+----------------+---------------------+
| ROW_FORMAT=COMPACT                                          | 11.03 |                           | &lt;span style=&#34;color: #008000;&#34;&gt;Instant&lt;/span&gt;        | &lt;span style=&#34;color: #008000;&#34;&gt;Instant&lt;/span&gt;             | &lt;span style=&#34;color: #008000;&#34;&gt;Instant&lt;/span&gt;                 | &lt;span style=&#34;color: #008000;&#34;&gt;Instant&lt;/span&gt;        | &lt;span style=&#34;color: #008000;&#34;&gt;Instant&lt;/span&gt;             |
| AUTO_INCREMENT=16051                                        |  0.05 | Instant, no table rebuild | N/A            | N/A                 | N/A                     | N/A            | N/A                 |
| ADD INDEX(last_update)                                      |  2.04 |                           | * &lt;span style=&#34;color: #ff6600;&#34;&gt;Inconsistent&lt;/span&gt; | * &lt;span style=&#34;color: #ff6600;&#34;&gt;Inconsistent&lt;/span&gt;      | * &lt;span style=&#34;color: #ff6600;&#34;&gt;Inconsistent&lt;/span&gt;          | &lt;span style=&#34;color: #800000;&#34;&gt;blocked&lt;/span&gt;        | &lt;span style=&#34;color: #800000;&#34;&gt;blocked&lt;/span&gt;             |
| ADD INDEX(last_update), ALGORITHM=INPLACE, LOCK=NONE        |  3.14 |                           | * &lt;span style=&#34;color: #ff6600;&#34;&gt;Inconsistent&lt;/span&gt; | * &lt;span style=&#34;color: #ff6600;&#34;&gt;Inconsistent&lt;/span&gt;      | * &lt;span style=&#34;color: #ff6600;&#34;&gt;Inconsistent&lt;/span&gt;          | &lt;span style=&#34;color: #800000;&#34;&gt;blocked&lt;/span&gt;        | &lt;span style=&#34;color: #800000;&#34;&gt;blocked&lt;/span&gt;             |
| ADD COLUMN c CHAR(1) NOT NULL                               |    ** |                           | * &lt;span style=&#34;color: #ff6600;&#34;&gt;Inconsistent&lt;/span&gt; | * &lt;span style=&#34;color: #ff6600;&#34;&gt;Inconsistent&lt;/span&gt;      | * &lt;span style=&#34;color: #ff6600;&#34;&gt;Inconsistent&lt;/span&gt;          | * &lt;span style=&#34;color: #ff6600;&#34;&gt;Inconsistent&lt;/span&gt; | * &lt;span style=&#34;color: #ff6600;&#34;&gt;Inconsistent&lt;/span&gt;      |
| ADD COLUMN c CHAR(1) NOT NULL, ALGORITHM=INPLACE, LOCK=NONE |    ** |                           | * &lt;span style=&#34;color: #ff6600;&#34;&gt;Inconsistent&lt;/span&gt; | * &lt;span style=&#34;color: #ff6600;&#34;&gt;Inconsistent&lt;/span&gt;      | * &lt;span style=&#34;color: #ff6600;&#34;&gt;Inconsistent&lt;/span&gt;          | * &lt;span style=&#34;color: #ff6600;&#34;&gt;Inconsistent&lt;/span&gt; | * &lt;span style=&#34;color: #ff6600;&#34;&gt;Inconsistent&lt;/span&gt;      |
+-------------------------------------------------------------+-------+---------------------------+----------------+---------------------+-------------------------+----------------+---------------------+&lt;/pre&gt;
&lt;/blockquote&gt;
&lt;p&gt;What&#39;s going on here?&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;ALGORITHM=INPLACE, LOCK=NONE&lt;/strong&gt; is accepted! Bad, bad foreign keys!&lt;br /&gt;
&lt;strong&gt;&lt;/strong&gt;&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;* ADD INDEX&lt;/strong&gt; usually allows for concurrent reads, but after repeated tests &lt;strong&gt;SELECT&lt;/strong&gt;s start to block. Then they don&#39;t work concurrently anymore until table is recreated. But even that not always, so I&#39;m not sure what the inconsistency is.&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;* ADD COLUMN&lt;/strong&gt; is still more concurrent than &lt;strong&gt;ADD INDEX&lt;/strong&gt;, and actually allows for concurrent writes! Though, inconsistently. Sometimes it does not allow for concurrent writes.&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;** ADD COLUMN&lt;/strong&gt; runtime highly affected by concurrent queries. It wents as high as &lt;strong&gt;45&lt;/strong&gt; seconds on my laptop. Now, to make things clear, I&#39;m not running an automated benchmark here: I&#39;m copying+pasting the statements from my editor to the mysql CLI. So, maybe &lt;strong&gt;10&lt;/strong&gt; or &lt;strong&gt;15&lt;/strong&gt;&lt;strong&gt;SELECT&lt;/strong&gt; and &lt;strong&gt;UPDATE&lt;/strong&gt; queries executes. How does that justify &lt;strong&gt;35&lt;/strong&gt; seconds delay in table rebuild?&lt;/li&gt;
&lt;/ul&gt;
&lt;h4&gt;Some conclusions:&lt;/h4&gt;
&lt;ul&gt;
&lt;li&gt;The documentation does not specify anything about &lt;strong&gt;FOREIGN KEY&lt;/strong&gt;s crashing the party. It should.&lt;/li&gt;
&lt;li&gt;The documentation specifically mentions the &lt;strong&gt;ADD/DROP INDEX&lt;/strong&gt; statements to be online. &lt;strong&gt;ADD INDEX&lt;/strong&gt; is less online than &lt;strong&gt;ADD COLUMN&lt;/strong&gt;.&lt;/li&gt;
&lt;li&gt;Everything is still shaky. Sometimes things work, sometimes they don&#39;t.&lt;/li&gt;
&lt;li&gt;Runtimes are unproportionally affected by concurrent queries.&lt;/li&gt;
&lt;li&gt;For the meantime, I keep to my online alter table scripts. Been using them for &lt;strong&gt;3.5&lt;/strong&gt; years now.&lt;/li&gt;
&lt;/ul&gt;</description>
    </item>
    
    <item>
      <title>Experimenting with 5.6 InnoDB Online DDL (bugs included)</title>
      <link>/blog/2012/10/18/experimenting-with-5-6-innodb-online-ddl-bugs-included/</link>
      <pubDate>Thu, 18 Oct 2012 14:41:46 +0000</pubDate>
      
      <guid>/blog/2012/10/18/experimenting-with-5-6-innodb-online-ddl-bugs-included/</guid>
      <description>&lt;p&gt;MySQL &lt;strong&gt;5.6&lt;/strong&gt; offers the groundbreaking online DDL operations for InnoDB. Most common use cases will enjoy this feature, and the need for &lt;a href=&#34;http://openarkkit.googlecode.com/svn/trunk/openarkkit/doc/html/oak-online-alter-table.html&#34;&gt;online alter table&lt;/a&gt; scripts will decrease. This is a killer feature!&lt;/p&gt;
&lt;p&gt;I&#39;ve put this new feature to the usability test. How did it go? Not too well, I&#39;m afraid.&lt;/p&gt;
&lt;p&gt;[Updates to this text inline], also see &lt;a href=&#34;http://code.openark.org/blog/mysql/innodb-ddl-kudos-to-quick-responders-on-bugs-mysql-com&#34;&gt;this followup&lt;/a&gt;.&lt;/p&gt;
&lt;h4&gt;sakila &amp;amp; DDL&lt;/h4&gt;
&lt;p&gt;&lt;a href=&#34;http://dev.mysql.com/doc/sakila/en/index.html&#34;&gt;sakila&lt;/a&gt; is still a very useful database. I say &#34;still&#34; because it is not very large, and computing power is getting stronger; yet on my laptop some operations can still take many seconds to complete, which is just fine for my tests.&lt;/p&gt;
&lt;p&gt;Sakila tables are mostly InnoDB, and rental being the largest, I do:&lt;/p&gt;
&lt;blockquote&gt;
&lt;pre&gt;node1 (sakila) &amp;gt; &lt;strong&gt;alter table sakila.rental engine=InnoDB;&lt;/strong&gt;
Query OK, 16044 rows affected (&lt;strong&gt;6.94&lt;/strong&gt; sec)
Records: 16044  Duplicates: 0  Warnings: 0&lt;/pre&gt;
&lt;/blockquote&gt;
&lt;p&gt;So what can be executed during these &lt;strong&gt;6.94&lt;/strong&gt; seconds? In a second terminal, I try the following:&lt;!--more--&gt;&lt;/p&gt;
&lt;h4&gt;Meta&lt;/h4&gt;
&lt;blockquote&gt;
&lt;pre&gt;node1 (sakila) &amp;gt; show create table sakila.rental\G
*************************** 1. row ***************************
       Table: rental
Create Table: CREATE TABLE `rental` (
  `rental_id` int(11) NOT NULL AUTO_INCREMENT,
  `rental_date` datetime NOT NULL,
  `inventory_id` mediumint(8) unsigned NOT NULL,
  `customer_id` smallint(5) unsigned NOT NULL,
  `return_date` timestamp NOT NULL DEFAULT CURRENT_TIMESTAMP ON UPDATE CURRENT_TIMESTAMP,
  `staff_id` tinyint(3) unsigned NOT NULL,
  `last_update` timestamp NOT NULL DEFAULT CURRENT_TIMESTAMP ON UPDATE CURRENT_TIMESTAMP,
  PRIMARY KEY (`rental_id`),
  UNIQUE KEY `rental_date` (`rental_date`,`inventory_id`,`customer_id`),
  KEY `idx_fk_inventory_id` (`inventory_id`),
  KEY `idx_fk_customer_id` (`customer_id`),
  KEY `idx_fk_staff_id` (`staff_id`),
  CONSTRAINT `fk_rental_customer` FOREIGN KEY (`customer_id`) REFERENCES `customer` (`customer_id`) ON UPDATE CASCADE,
  CONSTRAINT `fk_rental_inventory` FOREIGN KEY (`inventory_id`) REFERENCES `inventory` (`inventory_id`) ON UPDATE CASCADE,
  CONSTRAINT `fk_rental_staff` FOREIGN KEY (`staff_id`) REFERENCES `staff` (`staff_id`) ON UPDATE CASCADE
) ENGINE=InnoDB AUTO_INCREMENT=16050 DEFAULT CHARSET=utf8
1 row in set (&lt;strong&gt;1.08 sec&lt;/strong&gt;)&lt;/pre&gt;
&lt;/blockquote&gt;
&lt;p&gt;&lt;strong&gt;1.08&lt;/strong&gt; seconds for &lt;strong&gt;SHOW CREATE TABLE&lt;/strong&gt;. Consider: up till &lt;strong&gt;5.5&lt;/strong&gt; you can&#39;t run &lt;strong&gt;SHOW CREATE TABLE&lt;/strong&gt; while an &lt;strong&gt;ALTER&lt;/strong&gt; was running on that table.&lt;/p&gt;
&lt;h4&gt;Read&lt;/h4&gt;
&lt;p&gt;While ALTER TABLE runs, I execute:&lt;/p&gt;
&lt;blockquote&gt;
&lt;pre&gt;node1 (sakila) &amp;gt; select min(rental_date), max(return_date) from sakila.rental;
+---------------------+---------------------+
| min(rental_date)    | max(return_date)    |
+---------------------+---------------------+
| 2005-05-24 22:53:30 | 2005-09-02 02:35:22 |
+---------------------+---------------------+
1 row in set (2.77 sec)&lt;/pre&gt;
&lt;/blockquote&gt;
&lt;p&gt;So &lt;strong&gt;2.77&lt;/strong&gt; seconds for a query which uses a full table scan to return. I&#39;m not measuring performance here; am satisfies that query did actually succeed even while table was being altered.&lt;/p&gt;
&lt;h4&gt;Read &amp;amp; bug&lt;/h4&gt;
&lt;p&gt;But, unfortunately, being the type of geek who likes to make trouble, I am also able to consistently fail the &lt;strong&gt;ALTER TABLE&lt;/strong&gt;. Hang it, actually:&lt;/p&gt;
&lt;p&gt;See session &lt;strong&gt;#1&lt;/strong&gt;:&lt;/p&gt;
&lt;blockquote&gt;
&lt;pre&gt;node1 (sakila) &amp;gt; alter table sakila.rental engine=innodb; 

... (waiting forever)&lt;/pre&gt;
&lt;/blockquote&gt;
&lt;p&gt;And session &lt;strong&gt;#2&lt;/strong&gt;:&lt;/p&gt;
&lt;blockquote&gt;
&lt;pre&gt;node1 (sakila) &amp;gt; show processlist;
+----+----------+-----------+--------+---------+------+---------------------------------+-----------------------------------------+
| Id | User     | Host      | db     | Command | Time | State                           | Info                                    |
+----+----------+-----------+--------+---------+------+---------------------------------+-----------------------------------------+
|  6 | msandbox | localhost | sakila | Query   |  &lt;strong&gt;219&lt;/strong&gt; | &lt;strong&gt;Waiting for table metadata lock&lt;/strong&gt; | &lt;strong&gt;alter table sakila.rental engine=innodb&lt;/strong&gt; |
|  4 | msandbox | localhost | sakila | Query   |    0 | init                            | show processlist                        |
+----+----------+-----------+--------+---------+------+---------------------------------+-----------------------------------------+&lt;/pre&gt;
&lt;/blockquote&gt;
&lt;p&gt;Read all about it in &lt;a href=&#34;http://bugs.mysql.com/bug.php?id=67286&#34;&gt;bug report #67286&lt;/a&gt; .&lt;/p&gt;
&lt;h4&gt;Write: not so simple&lt;/h4&gt;
&lt;p&gt;The following &lt;strong&gt;UPDATE&lt;/strong&gt; query hangs till the &lt;strong&gt;ALTER&lt;/strong&gt; process is over:&lt;/p&gt;
&lt;blockquote&gt;
&lt;pre&gt;node1 (sakila) &amp;gt; update sakila.rental set return_date=now() where rental_id = floor(rand()*100);
Query OK, 3 rows affected, 1 warning (6.10 sec)&lt;/pre&gt;
&lt;/blockquote&gt;
&lt;p&gt;No online DDL for writes?&lt;/p&gt;
&lt;p&gt;Was I unfair? Is &#34;ENGINE=InnoDB&#34; really an online DDL operation? OK, let&#39;s try with:&lt;/p&gt;
&lt;blockquote&gt;
&lt;pre&gt;alter table sakila.rental &lt;strong&gt;row_format=compact&lt;/strong&gt;;&lt;/pre&gt;
&lt;/blockquote&gt;
&lt;p&gt;Which is documented as one of the supported online DDL operations. Same.&lt;/p&gt;
&lt;p&gt;The &lt;a href=&#34;http://dev.mysql.com/doc/refman/5.6/en/innodb-online-ddl.html&#34;&gt;manual&lt;/a&gt; says I can define the &lt;strong&gt;ALGORITHM&lt;/strong&gt; and the &lt;strong&gt;LOCK&lt;/strong&gt; properties for the &lt;strong&gt;ALTER TABLE&lt;/strong&gt; operation. But is gives no example, so I try my own:&lt;/p&gt;
&lt;blockquote&gt;
&lt;pre&gt;node1 (sakila) &amp;gt; alter table sakila.rental row_format=compact &lt;strong&gt;ALGORITHM=INPLACE LOCK=NONE&lt;/strong&gt;;
ERROR 1064 (42000): You have an error in your SQL syntax; check the manual that corresponds to your MySQL server version for the right syntax to use near &#39;ALGORITHM=INPLACE LOCK=NONE&#39; at line 1&lt;/pre&gt;
&lt;/blockquote&gt;
&lt;p&gt;Ummm.... then maybe:&lt;/p&gt;
&lt;blockquote&gt;
&lt;pre&gt;node1 (sakila) &amp;gt; alter table sakila.rental &lt;strong&gt;ALGORITHM=INPLACE LOCK=NONE&lt;/strong&gt; row_format=compact;
ERROR 1064 (42000): You have an error in your SQL syntax; check the manual that corresponds to your MySQL server version for the right syntax to use near &#39;LOCK=NONE row_format=compact&#39; at line 1&lt;/pre&gt;
&lt;/blockquote&gt;
&lt;p&gt;OK, how about:&lt;/p&gt;
&lt;blockquote&gt;
&lt;pre&gt;node1 (sakila) &amp;gt; alter table sakila.rental &lt;strong&gt;ALGORITHM=INPLACE&lt;/strong&gt; row_format=compact &lt;strong&gt;LOCK=NONE&lt;/strong&gt;;
ERROR 1064 (42000): You have an error in your SQL syntax; check the manual that corresponds to your MySQL server version for the right syntax to use near &#39;row_format=compact LOCK=NONE&#39; at line 1&lt;/pre&gt;
&lt;/blockquote&gt;
&lt;p&gt;Reading, rereading, re-verifying &lt;a href=&#34;http://dev.mysql.com/doc/refman/5.6/en/alter-table.html&#34;&gt;the manual&lt;/a&gt; -- I am typing a valid statement! What&#39;s wrong here?&lt;/p&gt;
&lt;p&gt;Yes, I&#39;m on &lt;strong&gt;5.6.7-rc-log&lt;/strong&gt;. No, I can&#39;t find, in &lt;strong&gt;5.6&lt;/strong&gt; documentation and slides from &lt;a href=&#34;https://oracleus.activeevents.com/connect/search.ww?event=openworld#loadSearch-event=openworld&amp;amp;searchPhrase=&amp;amp;searchType=session&amp;amp;tc=0&amp;amp;sortBy=&amp;amp;p=&amp;amp;i%2810942%29=15982&amp;amp;i%2811425%29=&amp;amp;i%2810053%29=&amp;amp;i%2811404%29=&amp;amp;i%2811562%29=&amp;amp;i%2811488%29=&amp;amp;i%2810089%29=&amp;amp;i%2811840%29=&#34;&gt;MySQL connect&lt;/a&gt;, any code sample that actually uses &lt;strong&gt;ALGORITHM&lt;/strong&gt; and &lt;strong&gt;LOCK&lt;/strong&gt; (!?)&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;[UPDATE]&lt;/strong&gt;, as Marc Alff point out, I did in fact use the wrong syntax, and was missing commas. The right syntax is:&lt;/p&gt;
&lt;blockquote&gt;
&lt;pre&gt;node1 (sakila) &amp;gt; &lt;strong&gt;alter table sakila.rental row_format=compact, algorithm=inplace, lock=none;&lt;/strong&gt;
ERROR 1235 (42000): This version of MySQL doesn&#39;t yet support &#39;alter table sakila.rental row_format=compact, algorithm=inplace, lock=none&#39;&lt;/pre&gt;
&lt;/blockquote&gt;
&lt;p&gt;Unfortunately this still results with an error. Another attempt shows that:&lt;/p&gt;
&lt;blockquote&gt;
&lt;pre&gt;node1 (sakila) &amp;gt; alter table sakila.rental row_format=compact, algorithm=inplace, lock=shared;
Query OK, 0 rows affected (11.08 sec)&lt;/pre&gt;
&lt;/blockquote&gt;
&lt;p&gt;works well. So, apparently, you can only run &lt;em&gt;this type&lt;/em&gt; of &lt;strong&gt;ALTER TABLE&lt;/strong&gt; a with a &lt;strong&gt;SHARED&lt;/strong&gt; lock. The bad news?&lt;/p&gt;
&lt;blockquote&gt;
&lt;pre&gt;node1 (sakila) &amp;gt; alter table sakila.rental &lt;strong&gt;add index(return_date)&lt;/strong&gt;, algorithm=inplace, lock=&lt;strong&gt;none&lt;/strong&gt;;
ERROR 1235 (42000): This version of MySQL doesn&#39;t yet support &#39;alter table sakila.rental add index(return_date), algorithm=inplace, lock=none&#39;
node1 (sakila) &amp;gt; alter table sakila.rental &lt;strong&gt;add column c char&lt;/strong&gt;, algorithm=inplace, lock=&lt;strong&gt;none&lt;/strong&gt;;
ERROR 1235 (42000): This version of MySQL doesn&#39;t yet support &#39;alter table sakila.rental add column c char, algorithm=inplace, lock=none&#39;&lt;/pre&gt;
&lt;/blockquote&gt;
&lt;p&gt;So I&#39;m not sure as yet what kind of DDL operations are available with &lt;strong&gt;LOCK=NONE&lt;/strong&gt;.&lt;/p&gt;
&lt;h4&gt;Conclusion&lt;/h4&gt;
&lt;p&gt;Little success with online DDL. SHARED-only is many times as good as completely blocked.&lt;/p&gt;
&lt;p&gt;My personal conclusion is (and I do take into account &lt;strong&gt;5.6&lt;/strong&gt; is RC at this time, not GA): &lt;em&gt;not there yet!&lt;/em&gt; Stick to &lt;a href=&#34;http://openarkkit.googlecode.com/svn/trunk/openarkkit/doc/html/introduction.html&#34;&gt;openark-kit&lt;/a&gt;, &lt;a href=&#34;http://www.percona.com/doc/percona-toolkit/2.1/&#34;&gt;Percona-toolkit&lt;/a&gt; or &lt;a href=&#34;http://www.facebook.com/notes/mysql-at-facebook/online-schema-change-for-mysql/430801045932&#34;&gt;Facebook OSC&lt;/a&gt; for some time. They all provide with online-alter-table operations via external scripts.&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>How common_schema split()s tables - internals</title>
      <link>/blog/2012/09/06/how-common_schema-splits-tables-internals/</link>
      <pubDate>Thu, 06 Sep 2012 07:25:07 +0000</pubDate>
      
      <guid>/blog/2012/09/06/how-common_schema-splits-tables-internals/</guid>
      <description>&lt;p&gt;This post exposes some of the internals, and the SQL behind QueryScript&#39;s &lt;em&gt;split&lt;/em&gt;. &lt;a href=&#34;http://common-schema.googlecode.com/svn/trunk/common_schema/doc/html/query_script.html&#34;&gt;common_schema/QueryScript&lt;/a&gt; &lt;strong&gt;1.1&lt;/strong&gt; introduces the &lt;a href=&#34;http://common-schema.googlecode.com/svn/trunk/common_schema/doc/html/query_script_split.html&#34;&gt;&lt;strong&gt;split&lt;/strong&gt;&lt;/a&gt; statement, which auto-breaks a &#34;large&#34; query (one which operates on large tables as a whole or without keys) into smaller queries, and executes them in sequence.&lt;/p&gt;
&lt;p&gt;This makes for easier transactions, less locks held, potentially (depending on the user) more idle time released back to the database. &lt;em&gt;split&lt;strong&gt;&lt;/strong&gt;&lt;/em&gt; has similar concepts to &lt;a href=&#34;http://openarkkit.googlecode.com/svn/trunk/openarkkit/doc/html/oak-chunk-update.html&#34;&gt;oak-chunk-update&lt;/a&gt; and &lt;a href=&#34;http://www.percona.com/doc/percona-toolkit/2.1/pt-archiver.html&#34;&gt;pt-archiver&lt;/a&gt;, but works differently, and implemented entirely in SQL on server side.&lt;/p&gt;
&lt;p&gt;Take the following statement as example:&lt;/p&gt;
&lt;blockquote&gt;
&lt;pre&gt;&lt;strong&gt;split&lt;/strong&gt; (&lt;strong&gt;UPDATE sakila.inventory SET last_update = last_update + INTERVAL 6 HOUR&lt;/strong&gt;)
  pass;&lt;/pre&gt;
&lt;/blockquote&gt;
&lt;p&gt;It yields with (roughly) the following statements:&lt;/p&gt;
&lt;blockquote&gt;
&lt;pre&gt;UPDATE sakila.inventory SET last_update = last_update + INTERVAL 6 HOUR &lt;strong&gt;WHERE&lt;/strong&gt; ((((`inventory`.`inventory_id` &amp;gt; &#39;1&#39;)) OR ((`inventory`.`inventory_id` = &#39;1&#39;))) AND (((`inventory`.`inventory_id` &amp;lt; &#39;1000&#39;)) OR ((`inventory`.`inventory_id` = &#39;1000&#39;))));
UPDATE sakila.inventory SET last_update = last_update + INTERVAL 6 HOUR &lt;strong&gt;WHERE&lt;/strong&gt; ((((`inventory`.`inventory_id` &amp;gt; &#39;1000&#39;))) AND (((`inventory`.`inventory_id` &amp;lt; &#39;2000&#39;)) OR ((`inventory`.`inventory_id` = &#39;2000&#39;))));
UPDATE sakila.inventory SET last_update = last_update + INTERVAL 6 HOUR &lt;strong&gt;WHERE&lt;/strong&gt; ((((`inventory`.`inventory_id` &amp;gt; &#39;2000&#39;))) AND (((`inventory`.`inventory_id` &amp;lt; &#39;3000&#39;)) OR ((`inventory`.`inventory_id` = &#39;3000&#39;))));
UPDATE sakila.inventory SET last_update = last_update + INTERVAL 6 HOUR &lt;strong&gt;WHERE&lt;/strong&gt; ((((`inventory`.`inventory_id` &amp;gt; &#39;3000&#39;))) AND (((`inventory`.`inventory_id` &amp;lt; &#39;4000&#39;)) OR ((`inventory`.`inventory_id` = &#39;4000&#39;))));
UPDATE sakila.inventory SET last_update = last_update + INTERVAL 6 HOUR &lt;strong&gt;WHERE&lt;/strong&gt; ((((`inventory`.`inventory_id` &amp;gt; &#39;4000&#39;))) AND (((`inventory`.`inventory_id` &amp;lt; &#39;4581&#39;)) OR ((`inventory`.`inventory_id` = &#39;4581&#39;))));&lt;/pre&gt;
&lt;/blockquote&gt;
&lt;p&gt;(I say &#34;roughly&#34; because internally there are user defined variables at play, but for convenience, I verbose the actual values as constants.)&lt;/p&gt;
&lt;h4&gt;How does that work?&lt;/h4&gt;
&lt;p&gt;&lt;em&gt;common_schema&lt;/em&gt; works on server side. There is no Perl script or anything. It must therefore use server-side operations to:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Identify table to be split&lt;/li&gt;
&lt;li&gt;Analyze the table in the first place, deciding how to split it&lt;/li&gt;
&lt;li&gt;Analyze the query, deciding on how to rewrite it&lt;/li&gt;
&lt;li&gt;Split the table (logically) into unique and distinct chunks&lt;/li&gt;
&lt;li&gt;Work out the query on each such chunk&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;Following is an internal look at how &lt;em&gt;common_schema&lt;/em&gt; does all the above.&lt;!--more--&gt;&lt;/p&gt;
&lt;h4&gt;Identifying the table&lt;/h4&gt;
&lt;p&gt;When query operates on a single table, &lt;em&gt;split&lt;/em&gt; is able to parse the query&#39;s SQL and find out that table. When multiple tables are involved, &lt;em&gt;split&lt;/em&gt; requires user instruction: which table is it that the query should be split by?&lt;/p&gt;
&lt;h4&gt;Analyzing the table&lt;/h4&gt;
&lt;p&gt;Table analysis is done via a &lt;em&gt;similar&lt;/em&gt; method to &lt;a href=&#34;http://common-schema.googlecode.com/svn/trunk/common_schema/doc/html/candidate_keys_recommended.html&#34;&gt;candidate_keys_recommended&lt;/a&gt;. It is almost identical, only it uses &lt;a href=&#34;http://dev.mysql.com/doc/refman/5.1/en/information-schema-optimization.html&#34;&gt;INFORMATION_SCHEMA optimizations&lt;/a&gt; to make the query short and lightweight. Simulating the analysis using &lt;strong&gt;candidate_keys_recommended&lt;/strong&gt;, we get:&lt;/p&gt;
&lt;blockquote&gt;
&lt;pre&gt;mysql&amp;gt; select * from candidate_keys_recommended where table_name=&#39;inventory&#39; \G
*************************** 1. row ***************************
          table_schema: sakila
            table_name: inventory
recommended_index_name: PRIMARY
          has_nullable: 0
            is_primary: 1
 count_column_in_index: 1
          column_names: inventory_id&lt;/pre&gt;
&lt;/blockquote&gt;
&lt;p&gt;This is cool, simple and very easy to work with: we choose to split the table via the &lt;strong&gt;inventory_id&lt;/strong&gt; column, which is conveniently an integer. We&#39;ll soon see &lt;em&gt;split&lt;/em&gt; can handle complex cases as well.&lt;/p&gt;
&lt;h4&gt;Analyzing the query&lt;/h4&gt;
&lt;p&gt;This is done in part via Roland&#39;s &lt;a href=&#34;http://common-schema.googlecode.com/svn/trunk/common_schema/doc/html/query_analysis_routines.html&#34;&gt;query_analysis_routines&lt;/a&gt;, and in part just parsing the query, looking for &lt;strong&gt;WHERE&lt;/strong&gt;,&lt;strong&gt; GROUP BY&lt;/strong&gt;, &lt;strong&gt;LIMIT&lt;/strong&gt; etc. clauses.&lt;/p&gt;
&lt;p&gt;The nice part is injecting a &lt;strong&gt;WHERE&lt;/strong&gt; condition, which didn&#39;t appear in the original query. That &lt;strong&gt;WHERE&lt;/strong&gt; condition is what limits the query to a distinct chunk of rows.&lt;/p&gt;
&lt;h4&gt;Splitting the table&lt;/h4&gt;
&lt;p&gt;With a single &lt;strong&gt;INTEGER PRIMARY KEY&lt;/strong&gt; this sounds simple, right? Take rows &lt;strong&gt;1..1,000&lt;/strong&gt;, then &lt;strong&gt;1,001..2,000&lt;/strong&gt;, then &lt;strong&gt;2,001..3,000&lt;/strong&gt; etc.&lt;/p&gt;
&lt;p&gt;Wrong: even with this simple scenario, things are much more complex. Are the numbers successive? What if there are holes? What if there is a &lt;strong&gt;1,000,000&lt;/strong&gt; gap between every two numbers? What if there are multiple holes of differing size and frequency?&lt;/p&gt;
&lt;p&gt;And if we have two columns in our &lt;strong&gt;UNIQUE KEY&lt;/strong&gt;? What if one of them is textual, not an &lt;strong&gt;INTEGER&lt;/strong&gt;, the other a &lt;strong&gt;TIMESTAMP&lt;/strong&gt;, not an &lt;strong&gt;INTEGER&lt;/strong&gt; either?&lt;/p&gt;
&lt;p&gt;&lt;em&gt;split&lt;/em&gt; doesn&#39;t work in that naive way. It makes no assumptions on the density of values. It only requires:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;some &lt;strong&gt;UNIQUE KEY&lt;/strong&gt; to work with,&lt;/li&gt;
&lt;li&gt;which has no &lt;strong&gt;NULL&lt;/strong&gt; values.&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;Given the above, it uses &lt;em&gt;User Defined Variables&lt;/em&gt; to setup the chunks. With our single &lt;strong&gt;INTEGER&lt;/strong&gt; column, the minimum value is set like this:&lt;/p&gt;
&lt;blockquote&gt;
&lt;pre&gt;select 
  inventory_id 
from 
  `sakila`.`inventory` 
order by 
  inventory_id ASC 
limit 1  
into @_split_column_variable_min_1
;&lt;/pre&gt;
&lt;/blockquote&gt;
&lt;p&gt;This sets the first value of the first chunk. What value terminates this chunk? It is calculated like this:&lt;/p&gt;
&lt;blockquote&gt;
&lt;pre&gt;select 
  inventory_id 
from (
  select 
    inventory_id 
  from 
    `sakila`.`inventory` 
  where 
    (((`inventory`.`inventory_id` &amp;gt; @_split_column_variable_range_start_1)) OR ((`inventory`.`inventory_id` = @_split_column_variable_range_start_1))) and (((`inventory`.`inventory_id` &amp;lt; @_split_column_variable_max_1)) OR ((`inventory`.`inventory_id` = @_split_column_variable_max_1))) 
  order by 
    inventory_id ASC limit 1000 
  ) sel_split_range  
order by 
  inventory_id DESC 
limit 1  
into @_split_column_variable_range_end_1
;&lt;/pre&gt;
&lt;/blockquote&gt;
&lt;p&gt;Now there&#39;s a query you wouldn&#39;t want to work by hand, now would you?&lt;/p&gt;
&lt;p&gt;The cool part here is that the above works well for any type of column; this doesn&#39;t have to be an &lt;strong&gt;INTEGER&lt;/strong&gt;. Dates, strings etc. are all just fine.&lt;/p&gt;
&lt;p&gt;The above also works well for multiple columns, where the query gets more complicated (see following).&lt;/p&gt;
&lt;h4&gt;Working out the query per chunk&lt;/h4&gt;
&lt;p&gt;This part is the easy one, now that all the hard work is done. We know ho to manipulate the query, we know the lower and upper boundaries of the chunk, so we just fill in the values and execute.&lt;/p&gt;
&lt;h4&gt;Multi-columns keys&lt;/h4&gt;
&lt;p&gt;Consider a similar query on &lt;strong&gt;sakila.film_actor&lt;/strong&gt;, where the &lt;strong&gt;PRIMARY KEY&lt;/strong&gt; is a compound of two columns:&lt;/p&gt;
&lt;blockquote&gt;
&lt;pre&gt;split (UPDATE sakila.film_actor SET last_update = last_update + INTERVAL 6 HOUR)
  throttle 2;&lt;/pre&gt;
&lt;/blockquote&gt;
&lt;p&gt;The chunked queries will look like this:&lt;/p&gt;
&lt;blockquote&gt;
&lt;pre&gt;UPDATE sakila.film_actor SET last_update = last_update + INTERVAL 6 HOUR &lt;strong&gt;WHERE&lt;/strong&gt; ((((`film_actor`.`actor_id` &amp;gt; &#39;1&#39;)) OR ((`film_actor`.`actor_id` = &#39;1&#39;) AND (`film_actor`.`film_id` &amp;gt; &#39;1&#39;)) OR ((`film_actor`.`actor_id` = &#39;1&#39;) AND (`film_actor`.`film_id` = &#39;1&#39;))) AND (((`film_actor`.`actor_id` &amp;lt; &#39;39&#39;)) OR ((`film_actor`.`actor_id` = &#39;39&#39;) AND (`film_actor`.`film_id` &amp;lt; &#39;293&#39;)) OR ((`film_actor`.`actor_id` = &#39;39&#39;) AND (`film_actor`.`film_id` = &#39;293&#39;))));
UPDATE sakila.film_actor SET last_update = last_update + INTERVAL 6 HOUR &lt;strong&gt;WHERE&lt;/strong&gt; ((((`film_actor`.`actor_id` &amp;gt; &#39;39&#39;)) OR ((`film_actor`.`actor_id` = &#39;39&#39;) AND (`film_actor`.`film_id` &amp;gt; &#39;293&#39;))) AND (((`film_actor`.`actor_id` &amp;lt; &#39;76&#39;)) OR ((`film_actor`.`actor_id` = &#39;76&#39;) AND (`film_actor`.`film_id` &amp;lt; &#39;234&#39;)) OR ((`film_actor`.`actor_id` = &#39;76&#39;) AND (`film_actor`.`film_id` = &#39;234&#39;))));
UPDATE sakila.film_actor SET last_update = last_update + INTERVAL 6 HOUR &lt;strong&gt;WHERE&lt;/strong&gt; ((((`film_actor`.`actor_id` &amp;gt; &#39;76&#39;)) OR ((`film_actor`.`actor_id` = &#39;76&#39;) AND (`film_actor`.`film_id` &amp;gt; &#39;234&#39;))) AND (((`film_actor`.`actor_id` &amp;lt; &#39;110&#39;)) OR ((`film_actor`.`actor_id` = &#39;110&#39;) AND (`film_actor`.`film_id` &amp;lt; &#39;513&#39;)) OR ((`film_actor`.`actor_id` = &#39;110&#39;) AND (`film_actor`.`film_id` = &#39;513&#39;))));
UPDATE sakila.film_actor SET last_update = last_update + INTERVAL 6 HOUR &lt;strong&gt;WHERE&lt;/strong&gt; ((((`film_actor`.`actor_id` &amp;gt; &#39;110&#39;)) OR ((`film_actor`.`actor_id` = &#39;110&#39;) AND (`film_actor`.`film_id` &amp;gt; &#39;513&#39;))) AND (((`film_actor`.`actor_id` &amp;lt; &#39;146&#39;)) OR ((`film_actor`.`actor_id` = &#39;146&#39;) AND (`film_actor`.`film_id` &amp;lt; &#39;278&#39;)) OR ((`film_actor`.`actor_id` = &#39;146&#39;) AND (`film_actor`.`film_id` = &#39;278&#39;))));
UPDATE sakila.film_actor SET last_update = last_update + INTERVAL 6 HOUR &lt;strong&gt;WHERE&lt;/strong&gt; ((((`film_actor`.`actor_id` &amp;gt; &#39;146&#39;)) OR ((`film_actor`.`actor_id` = &#39;146&#39;) AND (`film_actor`.`film_id` &amp;gt; &#39;278&#39;))) AND (((`film_actor`.`actor_id` &amp;lt; &#39;183&#39;)) OR ((`film_actor`.`actor_id` = &#39;183&#39;) AND (`film_actor`.`film_id` &amp;lt; &#39;862&#39;)) OR ((`film_actor`.`actor_id` = &#39;183&#39;) AND (`film_actor`.`film_id` = &#39;862&#39;))));
UPDATE sakila.film_actor SET last_update = last_update + INTERVAL 6 HOUR &lt;strong&gt;WHERE&lt;/strong&gt; ((((`film_actor`.`actor_id` &amp;gt; &#39;183&#39;)) OR ((`film_actor`.`actor_id` = &#39;183&#39;) AND (`film_actor`.`film_id` &amp;gt; &#39;862&#39;))) AND (((`film_actor`.`actor_id` &amp;lt; &#39;200&#39;)) OR ((`film_actor`.`actor_id` = &#39;200&#39;) AND (`film_actor`.`film_id` &amp;lt; &#39;993&#39;)) OR ((`film_actor`.`actor_id` = &#39;200&#39;) AND (`film_actor`.`film_id` = &#39;993&#39;))));&lt;/pre&gt;
&lt;/blockquote&gt;
&lt;p&gt;View the complete command to realize just how much more complex each query is, and how much more complex the chunking becomes. Here&#39;s how I evaluate the chunk&#39;s &#34;next range end&#34; variables:&lt;/p&gt;
&lt;blockquote&gt;
&lt;pre&gt;select 
  actor_id, film_id 
from (
  select 
    actor_id, film_id 
  from 
    `sakila`.`film_actor` 
  where 
    (((`film_actor`.`actor_id` &amp;gt; @_split_column_variable_range_start_1)) OR ((`film_actor`.
`actor_id` = @_split_column_variable_range_start_1) AND (`film_actor`.`film_id` &amp;gt; @_split_column_variable_range_start_2))) and (((`film_actor`.`actor_id` &amp;lt; @_split_column_variable_max_1)) OR ((`film_actor`.`actor_id` = @_split_column_variable_max_1) AND (`film_actor`.`film_id` &amp;lt; @_split_column_variable_max_2)) OR ((`film_actor`.`actor_id` = @_split_column_variable_max_1) AND (`film_actor`.`film_id` = @_split_column_variable_max_2))) 
  order by 
    actor_id ASC, film_id ASC 
  limit 1000 
  ) sel_split_range  
order by 
  actor_id DESC, film_id DESC 
limit 1  
into @_split_column_variable_range_end_1, @_split_column_variable_range_end_2
;&lt;/pre&gt;
&lt;/blockquote&gt;
&lt;p&gt;By the way, you may recall that everything is done server side. The &lt;strong&gt;WHERE&lt;/strong&gt; condition for the chunked queries is in itself generated via SQL statement, and not too much by programmatic logic. Here&#39;s &lt;em&gt;part&lt;/em&gt; of the query which computes the limiting condition:&lt;/p&gt;
&lt;blockquote&gt;
&lt;pre&gt;  select
    group_concat(&#39;(&#39;, partial_comparison, &#39;)&#39; order by n separator &#39; OR &#39;) as comparison
  from (
    select 
      n,
      group_concat(&#39;(&#39;, column_name, &#39; &#39;, if(is_last, comparison_operator, &#39;=&#39;), &#39; &#39;, variable_name, &#39;)&#39; order by column_order separator &#39; AND &#39;) as partial_comparison
    from (
      select 
        n, CONCAT(mysql_qualify(split_table_name), &#39;.&#39;, mysql_qualify(column_name)) AS column_name,
        case split_variable_type
          when &#39;range_start&#39; then range_start_variable_name
          when &#39;range_end&#39; then range_end_variable_name
          when &#39;max&#39; then max_variable_name
        end as variable_name,
        _split_column_names_table.column_order, _split_column_names_table.column_order = n as is_last 
      from 
        numbers, _split_column_names_table 
      where 
        n between _split_column_names_table.column_order and num_split_columns 
      order by n, _split_column_names_table.column_order
    ) s1
    group by n
  ) s2
  into return_value
  ;&lt;/pre&gt;
&lt;/blockquote&gt;
&lt;p&gt;There is a lot of complexity to &lt;em&gt;split&lt;/em&gt; to make it able to provide with as clean a syntax for the user as possible.&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>DELETE, don&#39;t INSERT</title>
      <link>/blog/2012/06/27/delete-dont-insert/</link>
      <pubDate>Wed, 27 Jun 2012 07:25:09 +0000</pubDate>
      
      <guid>/blog/2012/06/27/delete-dont-insert/</guid>
      <description>&lt;p&gt;Have just read &lt;a href=&#34;http://blog.9minutesnooze.com/insert-delete/&#34;&gt;INSERT, Don’t DELETE&lt;/a&gt; by Aaron Brown, and have some lengthy response, which is why I write this post instead of commenting on said post.&lt;/p&gt;
&lt;p&gt;I wish to offer my counter thought and suggest that &lt;strong&gt;DELETE&lt;/strong&gt;s are probably the better choice.&lt;/p&gt;
&lt;p&gt;Aaron suggests that, when one wishes to purge rows from some table, a trick can be used: instead of &lt;strong&gt;DELETE&lt;/strong&gt;ing unwanted rows, one can &lt;strong&gt;INSERT&lt;/strong&gt; &#34;good&#34; rows into a new table, then switch over with &lt;strong&gt;RENAME&lt;/strong&gt; (but please read referenced post for complete details).&lt;/p&gt;
&lt;p&gt;I respectfully disagree on several points discussed.&lt;/p&gt;
&lt;h4&gt;Lockdown&lt;/h4&gt;
&lt;p&gt;The fact one needs to block writes during the time of creation of new table is problematic: you need to essentially turn off parts of your application. The posts suggests one could use a slave - but this solution is far from being trivial as well. To switch over, you yet again need to turn off access to DB, even if for a short while.&lt;!--more--&gt;&lt;/p&gt;
&lt;p&gt;A switch over to a slave is quite a big deal, in my opinion, for the mere purpose of deletion of rows.&lt;/p&gt;
&lt;h4&gt;DELETEs are easy&lt;/h4&gt;
&lt;p&gt;The DELETEs are so much easier: the first thing to note is the following: &lt;em&gt;You don&#39;t actually have to delete all the rows *at once*&lt;/em&gt;.&lt;/p&gt;
&lt;p&gt;You just need to drop some rows, right? Why waste a huge transaction that takes minutes, when you can drop the rows by chunks, one at a time?&lt;br /&gt;
For that, you can use either &lt;a href=&#34;http://www.percona.com/doc/percona-toolkit/2.1/pt-archiver.html&#34;&gt;pt-archive&lt;/a&gt; from &lt;em&gt;Percona Toolkit&lt;/em&gt;, &lt;a href=&#34;http://openarkkit.googlecode.com/svn/trunk/openarkkit/doc/html/oak-chunk-update.html&#34;&gt;oak-chunk-update&lt;/a&gt; from &lt;em&gt;openark-kit&lt;/em&gt;, or write a simple &lt;a href=&#34;http://common-schema.googlecode.com/svn/trunk/common_schema/doc/html/query_script.html&#34;&gt;QueryScript&lt;/a&gt; code with &lt;em&gt;common_schema&lt;/em&gt;:&lt;/p&gt;
&lt;blockquote&gt;
&lt;pre&gt;while (DELETE FROM title WHERE title &amp;lt;= &#39;g&#39; LIMIT 1000)
{
  throttle 1;
}&lt;/pre&gt;
&lt;/blockquote&gt;
&lt;p&gt;So, drop &lt;strong&gt;1,000&lt;/strong&gt; rows or so at a time, then sleep some time, etc. The total runtime is longer, but who cares? The impact can be reduced to be unnoticeable.&lt;/p&gt;
&lt;h4&gt;Space reclaim&lt;/h4&gt;
&lt;p&gt;You can use online table operations to rebuild your table and reclaim the disk space. Either see &lt;a href=&#34;http://openarkkit.googlecode.com/svn/trunk/openarkkit/doc/html/oak-online-alter-table.html&#34;&gt;oak-online-alter-table&lt;/a&gt; or &lt;a href=&#34;http://www.percona.com/doc/percona-toolkit/2.1/pt-online-schema-change.html&#34;&gt;pt-online-schema-change&lt;/a&gt;. Again, both work in small chunks, so no long stalls.&lt;/p&gt;
&lt;p&gt;But more on this: my usual purge scenario shows that it is repetitive. You purge, data fills again, you purge again, and so on.&lt;/p&gt;
&lt;p&gt;Which is why it doesn&#39;t make much sense to rebuild the table and reclaim the disk space: it just grows again to roughly same dimensions.&lt;br /&gt;
For a one time operation (e.g. after neglect of cleanup for long time) -- yes, absolutely, do a rebuild and reclaim. For repetitive cleanup - I don&#39;t bother.&lt;/p&gt;
&lt;h4&gt;Conclusion&lt;/h4&gt;
&lt;p&gt;Aaron does make note at the end of his post that &lt;strong&gt;DELETE&lt;/strong&gt; operations can be done online, while the &lt;strong&gt;INSERT&lt;/strong&gt; trick requires downtime, and this is a fair assessment.&lt;/p&gt;
&lt;p&gt;But just to make a point: none of the &lt;strong&gt;DELETE&lt;/strong&gt; timings are interesting. Since we are not concerned with deleting the rows in a given time (no &#34;press the red button&#34;), we can spread them over time and make the impact negligible. So not only is everything done online, it also goes unnoticed by the user. And this, I believe, is the major thing to consider.&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>Webinar review: Zero-Downtime Schema Changes In MySQL</title>
      <link>/blog/2012/05/03/webinar-review-zero-downtime-schema-changes-in-mysql/</link>
      <pubDate>Thu, 03 May 2012 16:17:19 +0000</pubDate>
      
      <guid>/blog/2012/05/03/webinar-review-zero-downtime-schema-changes-in-mysql/</guid>
      <description>&lt;p&gt;Yesterday I attended the &lt;a href=&#34;http://www.percona.com/webinars/2012-05-02-zero-downtime-schema-changes-in-mysql/&#34;&gt;Zero-Downtime Schema Changes In MySQL&lt;/a&gt; webinar by Baron Schwartz, Percona (&lt;em&gt;do you say &#34;attended&#34; for something you listened to from your home office?&lt;/em&gt;)&lt;/p&gt;
&lt;p&gt;I was keen to learn about possible enhancements and improvements of &lt;a href=&#34;http://www.percona.com/doc/percona-toolkit/2.1/pt-online-schema-change.html&#34;&gt;pt-online-schema-change&lt;/a&gt; over &lt;a href=&#34;http://openarkkit.googlecode.com/svn/trunk/openarkkit/doc/html/oak-online-alter-table.html&#34;&gt;oak-online-alter-table&lt;/a&gt;. Here are my impressions:&lt;/p&gt;
&lt;p&gt;The base logic of &lt;em&gt;pt-online-schema-change&lt;/em&gt; is essentially the same as of &lt;em&gt;oak-online-alter-table&lt;/em&gt;. You create a ghost/shadow table, create complex triggers, copy in chunks, freeze and swap. Both work on any type of &lt;strong&gt;PRIMARY KEY&lt;/strong&gt; (&lt;em&gt;oak-online-alter-table&lt;/em&gt; can work with any &lt;strong&gt;UNIQUE KEY&lt;/strong&gt;, I&#39;m not sure about &lt;em&gt;pt-online-schema-change&lt;/em&gt; on this), be it an &lt;strong&gt;INTEGER&lt;/strong&gt;, other type, or a multi column one.&lt;/p&gt;
&lt;p&gt;However, &lt;em&gt;pt-online-schema-change&lt;/em&gt; also adds the following:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;It supports &lt;strong&gt;FOREIGN KEY&lt;/strong&gt;s (to some extent). This is something I&#39;ve wanted to do with &lt;em&gt;oak-online-alter-table&lt;/em&gt; but never got around to it. Foreign keys are very tricky, as Baron noted. With child-side keys, things are reasonably manageable. With parent-side this becomes a nightmare, sometimes unsolvable (when I say &#34;unsolvable&#34;, I mean that under the constraint of having the operation run in a non-blocking, transparent way).&lt;/li&gt;
&lt;li&gt;Chunk size is auto-calculated by the script. This is a cool addition. Instead of letting the user throwing out numbers like &lt;strong&gt;1,000&lt;/strong&gt; rows per chunk, in the hope that this is neither too small nor too large, the tool monitors the time it takes a chunk to complete, then adjusts the size of next chunk accordingly. Hopefully this leads to a more optimized run, where locks are only held for very short periods, yet enough rows are being processed at a time.&lt;/li&gt;
&lt;li&gt;The tool looks into replicating slaves to verify they&#39;re up to the job. If the slave lags too far, the tool slows down the work. This is an excellent feature, and again, one that I always wanted to have. Great work!&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;So the three bullets above are what I understand to be the major advantages of Percona&#39;s tool over &lt;em&gt;oak-online-alter-table&lt;/em&gt;.&lt;/p&gt;
&lt;h4&gt;Q &amp;amp; A&lt;/h4&gt;
&lt;p&gt;The presentation itself was very good, and Baron answered some questions. There was one question he did not answer during the webinar, nor here, and I though I may pop in and answer it. Although I can&#39;t speak for the coders of &lt;em&gt;pt-online-schema-change&lt;/em&gt;, I safely assume that since the logic follows that of &lt;em&gt;oak-online-alter-table&lt;/em&gt;, the same answer applies in the case of Percona&#39;s toolkit.&lt;!--more--&gt;&lt;/p&gt;
&lt;p&gt;But, first, a background question (asked and answered during the webinar):&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Q&lt;/strong&gt;: What if my table already has &lt;strong&gt;AFTER TRIGGER&lt;/strong&gt;s?&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;A&lt;/strong&gt;: Then this can&#39;t work out. The table must not have triggers.&lt;/p&gt;
&lt;p&gt;Which led to the next question:&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Q&lt;/strong&gt;: Can&#39;t the tool use &lt;strong&gt;BEFORE TRIGGER&lt;/strong&gt;s instead?&lt;/p&gt;
&lt;p&gt;Imagine a &lt;strong&gt;MyISAM&lt;/strong&gt; table being altered to &lt;strong&gt;InnoDB&lt;/strong&gt; (this is a major task for which my tool was built). Suppose we used a &lt;strong&gt;BEFORE&lt;/strong&gt; trigger on an &lt;strong&gt;INSERT&lt;/strong&gt;, but the &lt;strong&gt;INSERT&lt;/strong&gt; failed. That would make the shadow table inconsistent with the original table. Which is the reason why the trigger must be an &lt;strong&gt;AFTER&lt;/strong&gt; trigger.&lt;/p&gt;
&lt;p&gt;With &lt;strong&gt;InnoDB&lt;/strong&gt; this should not be an issue, since triggers and actions all play within the same transaction, so all succeed or all fail. I have this nagging feeling at the back of my head which says I&#39;ve already had thoughts on this and have found a problem with &lt;strong&gt;InnoDB&lt;/strong&gt; tables as well. I can&#39;t put my finger on it now, so no comment on this one at this stage.&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>Documentation in SQL: CALL for help()</title>
      <link>/blog/2012/01/11/documentation-in-sql-call-for-help/</link>
      <pubDate>Wed, 11 Jan 2012 09:01:54 +0000</pubDate>
      
      <guid>/blog/2012/01/11/documentation-in-sql-call-for-help/</guid>
      <description>&lt;p&gt;Documentation is an important part of any project. On the projects I maintain I put a lot of effort on documentation, and, frankly, the majority of time spent on my projects is on documentation.&lt;/p&gt;
&lt;p&gt;The matter of keeping the documentation faithful is a topic of interest. I&#39;d like to outline a few documentation bundling possibilities, and the present the coming new documentation method for &lt;a href=&#34;http://code.google.com/p/common-schema/&#34; rel=&#34;nofollow&#34;&gt;common_schema&lt;/a&gt;. I&#39;ll talk about any bundling that is NOT &lt;em&gt;man pages&lt;/em&gt;.&lt;/p&gt;
&lt;h4&gt;High level: web docs&lt;/h4&gt;
&lt;p&gt;This is the initial method of documentation I used for &lt;a title=&#34;openark kit&#34; href=&#34;../../forge/openark-kit&#34;&gt;openark kit&lt;/a&gt; and &lt;a title=&#34;mycheckpoint&#34; href=&#34;../../forge/mycheckpoint&#34;&gt;mycheckpoint&lt;/a&gt;. It&#39;s still valid for &lt;em&gt;mycheckpoint&lt;/em&gt;. Documentation is web-based. You need Internet access to read it. It&#39;s in HTML format.&lt;/p&gt;
&lt;p&gt;Well, not exactly HTML format: I wrote it in WordPress. Yes, it&#39;s HTML, but there&#39;s a lot of noise around (theme, menus, etc.) which is not strictly part of the documentation.&lt;/p&gt;
&lt;p&gt;While this is perhaps the easiest way to go, here&#39;s a few drawbacks:&lt;!--more--&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;You&#39;re bound to some framework (WordPress in this case)&lt;/li&gt;
&lt;li&gt;Docs are split between MySQL database (my underlying WordPRess storage) &amp;amp; WordPress files (themes, style, header, footer etc.)&lt;/li&gt;
&lt;li&gt;Documentation is separate from your code - they&#39;re just not in the same place&lt;/li&gt;
&lt;li&gt;There is no version control over the documentation.&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;The result is a single source of documentation, which applies to whatever version is latest. It&#39;s impossible to maintain docs for multiple versions. You must manually synchronize your WordPress updates with code commits (or rather - code release!).&lt;/p&gt;
&lt;h4&gt;Mid level: version controlled HTML docs&lt;/h4&gt;
&lt;p&gt;I first saw this approach on Baron&#39;s &lt;a href=&#34;http://www.xaprb.com/blog/2010/09/22/aspersa-gets-a-user-manual/&#34; rel=&#34;bookmark&#34;&gt;Aspersa gets a user manual&lt;/a&gt; post. I loved it: the documentation is HTML, but stored as part of your project&#39;s code, in same version control.&lt;/p&gt;
&lt;p&gt;This means one can &lt;a href=&#34;http://openarkkit.googlecode.com/svn/trunk/openarkkit/doc/html/introduction.html&#34;&gt;browse the documentation&lt;/a&gt; (&lt;em&gt;openark kit&lt;/em&gt; in this example) exactly as it appears in the baseline. Depending on your project hosting, one may be able to do so per version.&lt;/p&gt;
&lt;p&gt;The approach has the great benefit of having the docs tightly coupled with the code in terms of development. Before committing code, one updates documentation for that code, then commits/releases both together.&lt;/p&gt;
&lt;p&gt;You&#39;re also not bound to any development framework. You may edit with &lt;em&gt;vim, emacs, gedit, bluefish, eclipse,&lt;/em&gt; ... any tool of your choice. It&#39;s all down to plain old text files.&lt;/p&gt;
&lt;h4&gt;Mid level #2: documentation bundling&lt;/h4&gt;
&lt;p&gt;One thing I started doing with common_schema is to release a doc bundle with the code. So one can download a compressed bundle of all HTML files. That way one is absolutely certain what&#39;s the right documentation for revision &lt;strong&gt;178&lt;/strong&gt;. There&#39;s no effort about it: the docs are already tightly coupled with code versions. Just compress and distribute.&lt;/p&gt;
&lt;h4&gt;Low level: documentation coupled with your code&lt;/h4&gt;
&lt;p&gt;Perl scripts can be written as Perl modules, in which case they are eligible for using the &lt;em&gt;perldoc&lt;/em&gt; convention. You code your documentation within your script itself, as comment. &lt;em&gt;Perldoc&lt;/em&gt; can extract the documentation and present in man-like format. Same happens with Python&#39;s &lt;em&gt;pydoc&lt;/em&gt;. Baron&#39;s &lt;a href=&#34;http://www.xaprb.com/blog/2011/11/07/when-documentation-is-code/&#34; rel=&#34;bookmark&#34;&gt;When documentation is code&lt;/a&gt; illustrates that approach. &lt;a href=&#34;http://www.maatkit.org/&#34;&gt;Maatkit&lt;/a&gt; (now &lt;em&gt;Percona Toolkit&lt;/em&gt;) has been using it for years.&lt;/p&gt;
&lt;p&gt;This method has the advantage of having the documentation ready right within your shell. You don&#39;t need a browser, nor firewall access. The docs are just there for you in the same environment where you&#39;re executing the code.&lt;/p&gt;
&lt;h4&gt;SQL Low level: CALL for help()&lt;/h4&gt;
&lt;p&gt;&lt;em&gt;common_schema&lt;/em&gt; is a different type of project. It is merely a schema. There&#39;s no Perl nor Python. One imports the schema into one&#39;s MySQL server.&lt;/p&gt;
&lt;p&gt;What&#39;s the low-level approach for this type of code?&lt;/p&gt;
&lt;p&gt;For &lt;em&gt;common_schema&lt;/em&gt; I use three levels of documentation: the mid-level, where one can &lt;a href=&#34;http://common-schema.googlecode.com/svn/trunk/common_schema/doc/html/introduction.html&#34;&gt;browse through the versioned docs&lt;/a&gt;, the 2nd mid-level, where one can &lt;a href=&#34;http://code.google.com/p/common-schema/downloads/list&#34;&gt;download bundled documentation&lt;/a&gt;, and then a low-level approach: documentation embedded within the code.&lt;/p&gt;
&lt;p&gt;MySQL&#39;s documentation is also built into the server: see the &lt;strong&gt;help_*&lt;/strong&gt; tables within the &lt;strong&gt;mysql&lt;/strong&gt; schema. The &lt;em&gt;mysql&lt;/em&gt; command line client allows one to access help by supporting the help command, e.g.&lt;/p&gt;
&lt;blockquote&gt;
&lt;pre&gt;mysql&amp;gt; help create table;&lt;/pre&gt;
&lt;/blockquote&gt;
&lt;p&gt;The client intercepts this command (this is not server side command) and searches through the &lt;strong&gt;mysql.help_*&lt;/strong&gt; docs.&lt;/p&gt;
&lt;p&gt;With &lt;em&gt;common_schema&lt;/em&gt;, I don&#39;t have control over the client; it&#39;s all on server side. But the code being a schema, what with stored routines and tables, it&#39;s easy enough to set up documentation.&lt;/p&gt;
&lt;p&gt;As of the next version of &lt;em&gt;common_schema&lt;/em&gt;, and following MySQL&#39;s method, &lt;em&gt;common_schema&lt;/em&gt; provides a &lt;strong&gt;help&lt;/strong&gt; table:&lt;/p&gt;
&lt;blockquote&gt;
&lt;pre&gt;DESC help;
+--------------+-------------+------+-----+---------+-------+
| Field        | Type        | Null | Key | Default | Extra |
+--------------+-------------+------+-----+---------+-------+
| topic        | varchar(32) | NO   | PRI | NULL    |       |
| help_message | text        | NO   |     | NULL    |       |
+--------------+-------------+------+-----+---------+-------+&lt;/pre&gt;
&lt;/blockquote&gt;
&lt;p&gt;And a &lt;strong&gt;help()&lt;/strong&gt; procedure, so that you can call for &lt;em&gt;help()&lt;/em&gt;. The procedure will look for the best matching document based on your search expression:&lt;/p&gt;
&lt;blockquote&gt;
&lt;pre&gt;root@mysql-5.1.51&amp;gt; &lt;strong&gt;CALL help(&#39;match&#39;);&lt;/strong&gt;
&lt;strong&gt;+---------------------------------------&lt;/strong&gt;----------------------------------------+
| help                                                                          |
+-------------------------------------------------------------------------------+
|                                                                               |
| NAME                                                                          |
|                                                                               |
| match_grantee(): Match an existing account based on user+host.                |
|                                                                               |
| TYPE                                                                          |
|                                                                               |
| Function                                                                      |
|                                                                               |
| DESCRIPTION                                                                   |
|                                                                               |
| MySQL does not provide with identification of logged in accounts. It only     |
| provides with user + host:port combination within processlist. Alas, these do |
| not directly map to accounts, as MySQL lists the host:port from which the     |
| connection is made, but not the (possibly wildcard) user or host.             |
| This function matches a user+host combination against the known accounts,     |
| using the same matching method as the MySQL server, to detect the account     |
| which MySQL identifies as the one matching. It is similar in essence to       |
| CURRENT_USER(), only it works for all sessions, not just for the current      |
| session.                                                                      |
|                                                                               |
| SYNOPSIS                                                                      |
|                                                                               |
|                                                                               |
|                                                                               |
|        match_grantee(connection_user char(16) CHARSET utf8,                   |
|        connection_host char(70) CHARSET utf8)                                 |
|          RETURNS VARCHAR(100) CHARSET utf8                                    |
|                                                                               |
|                                                                               |
| Input:                                                                        |
|                                                                               |
| * connection_user: user login (e.g. as specified by PROCESSLIST)              |
| * connection_host: login host. May optionally specify port number (e.g.       |
|   webhost:12345), which is discarded by the function. This is to support      |
|   immediate input from as specified by PROCESSLIST.                           |
|                                                                               |
|                                                                               |
| EXAMPLES                                                                      |
|                                                                               |
| Find an account matching the given use+host combination:                      |
|                                                                               |
|                                                                               |
|        mysql&amp;gt; SELECT match_grantee(&#39;apps&#39;, &#39;192.128.0.1:12345&#39;) AS            |
|        grantee;                                                               |
|        +------------+                                                         |
|        | grantee    |                                                         |
|        +------------+                                                         |
|        | &#39;apps&#39;@&#39;%&#39; |                                                         |
|        +------------+                                                         |
|                                                                               |
|                                                                               |
|                                                                               |
| ENVIRONMENT                                                                   |
|                                                                               |
| MySQL 5.1 or newer                                                            |
|                                                                               |
| SEE ALSO                                                                      |
|                                                                               |
| processlist_grantees                                                          |
|                                                                               |
| AUTHOR                                                                        |
|                                                                               |
| Shlomi Noach                                                                  |
|                                                                               |
+-------------------------------------------------------------------------------+&lt;/pre&gt;
&lt;/blockquote&gt;
&lt;p&gt;I like HTML for documentation. I think it&#39;s a good format, provided you don&#39;t start doing funny things. Perhaps &lt;em&gt;TROFF&lt;/em&gt; is more suitable; certainly more popular on Unix machines. But I already have everything in HTML. So, what do I do?&lt;/p&gt;
&lt;p&gt;My decision was to keep documentation in HTML, and use the handy &lt;em&gt;html2text&lt;/em&gt; tool to do the job. And it does it pretty well! The sample you see above is an automated translation of HTML to plain text.&lt;/p&gt;
&lt;p&gt;I add a few touches of my own: SELECTing long texts is ugly, whether you do it via &#34;&lt;strong&gt;;&lt;/strong&gt;&#34; or &#34;&lt;strong&gt;\G&lt;/strong&gt;&#34;. The &lt;strong&gt;help()&lt;/strong&gt; routine breaks the text by &#39;&lt;strong&gt;\n&lt;/strong&gt;&#39;, returning a multi row result set. The above sample makes for some &lt;strong&gt;60+&lt;/strong&gt; rows, nicely formatted, broken from the original single text appearing in the &lt;strong&gt;help&lt;/strong&gt; table.&lt;/p&gt;
&lt;p&gt;So now you have an internal help method for &lt;em&gt;common_schema&lt;/em&gt;, right where the code is. You don&#39;t have to leave the command line client in order to get help.&lt;/p&gt;
&lt;p&gt;&lt;a href=&#34;http://datacharmer.blogspot.com/&#34;&gt;Giuseppe&lt;/a&gt; offered me the idea for this, even while my own thinking about it was in early stages.&lt;/p&gt;
&lt;p&gt;The next version of &lt;em&gt;common_schema&lt;/em&gt; will be available in a few weeks. The code is pretty much ready. I just need to work on, ahem..., the documentation.&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>Slides for &#34;openark-kit: MySQL utilities for everyday use&#34;</title>
      <link>/blog/2011/04/14/slides-for-openark-kit-mysql-utilities-for-everyday-use/</link>
      <pubDate>Thu, 14 Apr 2011 00:16:20 +0000</pubDate>
      
      <guid>/blog/2011/04/14/slides-for-openark-kit-mysql-utilities-for-everyday-use/</guid>
      <description>&lt;p&gt;Today I have delivered my talk, &lt;a href=&#34;http://en.oreilly.com/mysql2011/public/schedule/detail/17155&#34;&gt;openark-kit: MySQL utilities for everyday use&lt;/a&gt;, at the &lt;em&gt;O&#39;REILLY  MySQL Conference 2011&lt;/em&gt;.&lt;/p&gt;
&lt;p&gt;The slides are uploaded to the O&#39;Reilly site, and I&#39;m attaching them here as well. Feel free to download the PDF: &lt;a href=&#34;http://code.openark.org/blog/wp-content/uploads/2011/04/openark-kit-mysqlconf11.pdf&#34;&gt;openark-kit-mysqlconf11.pdf&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;I wish to thank all who attended my talk!&lt;/p&gt;
&lt;p&gt;&amp;nbsp;&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>Checking for AUTO_INCREMENT capacity with single query</title>
      <link>/blog/2011/04/05/checking-for-auto_increment-capacity-with-single-query/</link>
      <pubDate>Tue, 05 Apr 2011 07:36:56 +0000</pubDate>
      
      <guid>/blog/2011/04/05/checking-for-auto_increment-capacity-with-single-query/</guid>
      <description>&lt;p&gt;&lt;em&gt;Darn!&lt;/em&gt; This means &lt;a href=&#34;http://openarkkit.googlecode.com/svn/trunk/openarkkit/doc/html/oak-show-limits.html&#34;&gt;oak-show-limits&lt;/a&gt; becomes redundant. Am I not supposed to speak about it on my &lt;a href=&#34;http://en.oreilly.com/mysql2011/public/schedule/detail/17155&#34;&gt;coming presentation&lt;/a&gt;? Bad timing!&lt;/p&gt;
&lt;p&gt;You have &lt;strong&gt;AUTO_INCREMENT&lt;/strong&gt; columns. How far are you pushing the limits? Are you going to run out of &lt;strong&gt;AUTO_INCREMENT&lt;/strong&gt; values soon? Perhaps you wonder whether you should &lt;strong&gt;ALTER&lt;/strong&gt; from &lt;strong&gt;INT&lt;/strong&gt; to &lt;strong&gt;BIGINT&lt;/strong&gt;?&lt;/p&gt;
&lt;p&gt;The answer is all there in &lt;strong&gt;INFORMATION_SCHEMA&lt;/strong&gt;. The &lt;strong&gt;TABLES&lt;/strong&gt; table shows the current &lt;strong&gt;AUTO_INCREMENT&lt;/strong&gt; value per table, and the &lt;strong&gt;COLUMNS&lt;/strong&gt; table tells us all about a column&#39;s data type.&lt;/p&gt;
&lt;p&gt;It takes some ugly code to deduce the maximum value per column type, what with signed/unsigned and data type, but then its very simple. Here is the query:&lt;!--more--&gt;&lt;/p&gt;
&lt;blockquote&gt;
&lt;pre&gt;SELECT
  TABLE_SCHEMA,
  TABLE_NAME,
  COLUMN_NAME,
  DATA_TYPE,
  COLUMN_TYPE,
  IF(
    LOCATE(&#39;unsigned&#39;, COLUMN_TYPE) &amp;gt; 0,
    1,
    0
  ) AS IS_UNSIGNED,
  (
    CASE DATA_TYPE
      WHEN &#39;tinyint&#39; THEN 255
      WHEN &#39;smallint&#39; THEN 65535
      WHEN &#39;mediumint&#39; THEN 16777215
      WHEN &#39;int&#39; THEN 4294967295
      WHEN &#39;bigint&#39; THEN 18446744073709551615
    END &amp;gt;&amp;gt; IF(LOCATE(&#39;unsigned&#39;, COLUMN_TYPE) &amp;gt; 0, 0, 1)
  ) AS MAX_VALUE,
  AUTO_INCREMENT,
  AUTO_INCREMENT / (
    CASE DATA_TYPE
      WHEN &#39;tinyint&#39; THEN 255
      WHEN &#39;smallint&#39; THEN 65535
      WHEN &#39;mediumint&#39; THEN 16777215
      WHEN &#39;int&#39; THEN 4294967295
      WHEN &#39;bigint&#39; THEN 18446744073709551615
    END &amp;gt;&amp;gt; IF(LOCATE(&#39;unsigned&#39;, COLUMN_TYPE) &amp;gt; 0, 0, 1)
  ) AS AUTO_INCREMENT_RATIO
FROM
  INFORMATION_SCHEMA.COLUMNS
  INNER JOIN INFORMATION_SCHEMA.TABLES USING (TABLE_SCHEMA, TABLE_NAME)
WHERE
  TABLE_SCHEMA NOT IN (&#39;mysql&#39;, &#39;INFORMATION_SCHEMA&#39;, &#39;performance_schema&#39;)
  AND EXTRA=&#39;auto_increment&#39;
;
&lt;/pre&gt;
&lt;/blockquote&gt;
&lt;p&gt;There&#39;s one row in the result set for each &lt;strong&gt;AUTO_INCREMENT&lt;/strong&gt; column. since at most one &lt;strong&gt;AUTO_INCREMENT&lt;/strong&gt; column can exist for any given table, each row also identifies a unique table. Resulting columns are mostly self-explanatory, but here&#39;s some details on some of the columns:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;IS_UNSIGNED&lt;/strong&gt;: &lt;strong&gt;1&lt;/strong&gt; when the column is &lt;strong&gt;UNSIGNED&lt;/strong&gt;, &lt;strong&gt;0&lt;/strong&gt; otherwise.&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;MAX_VALUE&lt;/strong&gt;: maximum value that can be contained within column.&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;AUTO_INCREMENT&lt;/strong&gt;: current &lt;strong&gt;AUTO_INCREMENT&lt;/strong&gt; value for table.&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;AUTO_INCREMENT_RATIO&lt;/strong&gt;: value in the range &lt;strong&gt;[0..1]&lt;/strong&gt;, where &lt;strong&gt;1&lt;/strong&gt; means &#34;100% full&#34;.&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;A sample output:&lt;/p&gt;
&lt;blockquote&gt;
&lt;pre&gt;+--------------+------------+--------------+-----------+-----------------------+-------------+------------+----------------+----------------------+
| TABLE_SCHEMA | TABLE_NAME | COLUMN_NAME  | DATA_TYPE | COLUMN_TYPE           | IS_UNSIGNED | MAX_VALUE  | AUTO_INCREMENT | AUTO_INCREMENT_RATIO |
+--------------+------------+--------------+-----------+-----------------------+-------------+------------+----------------+----------------------+
| sakila       | actor      | actor_id     | smallint  | smallint(5) unsigned  |           1 |      65535 |            201 |               0.0031 |
| sakila       | address    | address_id   | smallint  | smallint(5) unsigned  |           1 |      65535 |            606 |               0.0092 |
| sakila       | category   | category_id  | tinyint   | tinyint(3) unsigned   |           1 |        255 |             17 |               0.0667 |
| sakila       | city       | city_id      | smallint  | smallint(5) unsigned  |           1 |      65535 |            601 |               0.0092 |
| sakila       | country    | country_id   | smallint  | smallint(5) unsigned  |           1 |      65535 |            110 |               0.0017 |
| sakila       | customer   | customer_id  | smallint  | smallint(5) unsigned  |           1 |      65535 |            600 |               0.0092 |
| sakila       | film       | film_id      | smallint  | smallint(5) unsigned  |           1 |      65535 |           1001 |               0.0153 |
| sakila       | inventory  | inventory_id | mediumint | mediumint(8) unsigned |           1 |   16777215 |           4582 |               0.0003 |
| sakila       | language   | language_id  | tinyint   | tinyint(3) unsigned   |           1 |        255 |              7 |               0.0275 |
| sakila       | payment    | payment_id   | smallint  | smallint(5) unsigned  |           1 |      65535 |          16050 |               0.2449 |
| sakila       | rental     | rental_id    | int       | int(11)               |           0 | 2147483647 |          16050 |               0.0000 |
| sakila       | staff      | staff_id     | tinyint   | tinyint(3) unsigned   |           1 |        255 |              3 |               0.0118 |
| sakila       | store      | store_id     | tinyint   | tinyint(3) unsigned   |           1 |        255 |              3 |               0.0118 |
+--------------+------------+--------------+-----------+-----------------------+-------------+------------+----------------+----------------------+
&lt;/pre&gt;
&lt;/blockquote&gt;
&lt;h4&gt;Bonus: free advice on increasing your AUTO_INCREMENT capacity&lt;/h4&gt;
&lt;p&gt;Make it &lt;strong&gt;UNSIGNED&lt;/strong&gt;. No, really. Check your definitions now.&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>Would you be my friend on mysqlconf? (tempting offer inside)</title>
      <link>/blog/2011/03/09/would-you-be-my-friend-on-mysqlconf-tempting-offer-inside/</link>
      <pubDate>Wed, 09 Mar 2011 08:22:37 +0000</pubDate>
      
      <guid>/blog/2011/03/09/would-you-be-my-friend-on-mysqlconf-tempting-offer-inside/</guid>
      <description>&lt;p&gt;I&#39;m still throwing papers to the trash and starting all over, fixing, rewriting and improving my talk at &lt;a href=&#34;http://www.mysqlconf.com/&#34;&gt;mysqlconf 2011&lt;/a&gt;, where I will be presenting &lt;a href=&#34;http://en.oreilly.com/mysql2011/public/schedule/detail/17155&#34;&gt;openark-kit: MySQL utilities for everyday use&lt;/a&gt;.&lt;/p&gt;
&lt;p&gt;However I&#39;ve got something up my sleeve: a benefit many can enjoy, that&#39;ll make me a respectful, popular and sought after speaker. While others may try and lure you with such &lt;em&gt;earthly&lt;/em&gt; temptations as a &lt;strong&gt;20%&lt;/strong&gt; off discount, I am in a position to offer you a more &lt;em&gt;spiritual&lt;/em&gt; gift: my friendship!&lt;/p&gt;
&lt;p&gt;See, if you become my friend, I can offer you a &lt;strong&gt;25%&lt;/strong&gt; discount on the MySQL conference. Yes, that&#39;s &lt;strong&gt;5%&lt;/strong&gt; more than my competitors! The only thing I ask in return is that you be my friend (hey, it&#39;s called &#34;friends of speaker&#34;). Not like a FB virtual friend, but a &lt;em&gt;real&lt;/em&gt; friendship! One where you can buy me &lt;em&gt;beer&lt;/em&gt; or &lt;em&gt;dinner&lt;/em&gt;!&lt;/p&gt;
&lt;p&gt;If you agree to such humane terms, I will be in the position to let you know that all you have to do is fill in &lt;strong&gt;﻿﻿﻿mys11fsd&lt;/strong&gt; in your registration form.&lt;/p&gt;
&lt;p&gt;No, wait! I let it slip! Rewrite: You should fill in &lt;del&gt;&lt;strong&gt;﻿﻿﻿mys11fsd &lt;/strong&gt;&lt;/del&gt;&lt;em&gt;[will only tell you this password after your commitment to a beer]&lt;/em&gt; in your registration form.&lt;/p&gt;
&lt;p&gt;&lt;em&gt;Oh no, not again! &lt;/em&gt;&lt;/p&gt;
&lt;p&gt;Don&#39;t use &lt;a href=&#34;https://en.oreilly.com/mysql2011/public/regwith/mys11fsd&#34;&gt;&lt;strong&gt;﻿﻿﻿mys11fsd&lt;/strong&gt;&lt;/a&gt; without talking to me first... You&#39;re not supposed to... &lt;em&gt;Oh, my beer!&lt;/em&gt;&lt;/p&gt;
&lt;p&gt;&lt;em&gt;Argghhh!&lt;/em&gt;&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>Speaking at the O&#39;Reilly MySQL Conference 2011</title>
      <link>/blog/2011/01/03/speaking-at-the-oreilly-mysql-conference-2011/</link>
      <pubDate>Mon, 03 Jan 2011 18:53:20 +0000</pubDate>
      
      <guid>/blog/2011/01/03/speaking-at-the-oreilly-mysql-conference-2011/</guid>
      <description>&lt;p&gt;I&#39;m very pleased and humbled to announce that my submission to the upcoming O&#39;Reilly MySQL Conference, April 2011, has been accepted.&lt;/p&gt;
&lt;p&gt;I will present a 45 minute session titled &lt;a href=&#34;http://en.oreilly.com/mysql2011/public/schedule/detail/17155&#34;&gt;&lt;strong&gt;openark-kit: MySQL utilities for everyday use&lt;/strong&gt;&lt;/a&gt;.&lt;/p&gt;
&lt;p&gt;In this session, I will present some of the tools in the &lt;em&gt;openark kit&lt;/em&gt;. We&#39;ll discuss some limitations of the MySQL server, and how openark kit tools overcome those limitations and provide with solutions to common maintenance and audit problems.&lt;/p&gt;
&lt;p&gt;This will be a technical session and will discuss various topics of the MySQL server: security, execution plans, replication, triggers and more. I do not intend to discuss all tools, nor to cover the various options. Instead, I&#39;ll present the &#34;&lt;em&gt;behind the scenes&lt;/em&gt;&#34;, show &lt;em&gt;why the tools work&lt;/em&gt;, present common problems and typical use case.&lt;/p&gt;
&lt;p&gt;This will be the first time I present at the MySQL Conference (or any conference outside Israel, for that matter). I hope to have a good session. As extra measure of safety, I&#39;ll bring along a couple basketballs; if the sun shines, we can all go outside and have a good time!&lt;/p&gt;
&lt;p&gt;The idea to submit this talk (credit Roland Bouman) has given me the inspiration to put effort in making a new release with new and updated tools. So this talk is already a success as far as I&#39;m concerned.&lt;/p&gt;
&lt;p&gt;Hope to see you there!&lt;/p&gt;
&lt;p&gt;[&lt;strong&gt;PS&lt;/strong&gt; shameless plug: &lt;a href=&#34;http://code.openark.org/forge/openark-kit&#34;&gt;openark kit&lt;/a&gt;.]&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>oak-hook-general-log: your poor man&#39;s Query Analyzer</title>
      <link>/blog/2010/12/15/oak-hook-general-log-your-poor-mans-query-analyzer/</link>
      <pubDate>Wed, 15 Dec 2010 19:46:06 +0000</pubDate>
      
      <guid>/blog/2010/12/15/oak-hook-general-log-your-poor-mans-query-analyzer/</guid>
      <description>&lt;p&gt;The latest release of &lt;a href=&#34;http://code.openark.org/forge/openark-kit&#34;&gt;openark kit&lt;/a&gt; introduces &lt;a href=&#34;http://openarkkit.googlecode.com/svn/trunk/openarkkit/doc/html/oak-hook-general-log.html&#34;&gt;oak-hook-general-log&lt;/a&gt;, a handy tool which allows for some analysis of executing queries.&lt;/p&gt;
&lt;p&gt;Initially I just intended for the tool to be able to dump the general log to standard output, from any machine capable to connect to MySQL. Quick enough, I realized the power it brings.&lt;/p&gt;
&lt;p&gt;With this tool, one can dump to standard output all queries using temporary tables; or using a specific index; or doing a full index scan; or just follow up on connections; or... For example, the following execution will only log queries which make for filesort:&lt;/p&gt;
&lt;blockquote&gt;
&lt;pre&gt;oak-hook-general-log --user=root --host=localhost --password=123456 --filter-explain-filesort&lt;/pre&gt;
&lt;/blockquote&gt;
&lt;h4&gt;The problem with using the standard logs&lt;/h4&gt;
&lt;p&gt;So you have the &lt;em&gt;general log&lt;/em&gt;, which you don&#39;t often enable, since it tends to grow huge within moments. You then have the &lt;em&gt;slow log&lt;/em&gt;. Slow log is great, and is among the top tools for MySQL diagnosis.&lt;/p&gt;
&lt;p&gt;The slow log allows for &lt;strong&gt;log-queries-not-using-indexes&lt;/strong&gt;, which is yet another nice feature. Not only should you log any query running for over &lt;strong&gt;X&lt;/strong&gt; seconds, but also log any query which does not use an index.&lt;/p&gt;
&lt;p&gt;Wait. This logs all single-row tables (no single row table will use an index), as well as very small tables (a common &lt;strong&gt;20&lt;/strong&gt; rows lookup table will most often be scanned). These are OK scans. This makes for some noise in the slow log.&lt;/p&gt;
&lt;p&gt;And how about queries which do use an index, but do so poorly? They use an index, but retrieve some &lt;strong&gt;12,500,000&lt;/strong&gt; rows, &lt;em&gt;using temporary&lt;/em&gt; table &amp;amp; &lt;em&gt;filesort&lt;/em&gt;?&lt;/p&gt;
&lt;h4&gt;What oak-hook-general-log does for you&lt;/h4&gt;
&lt;p&gt;This tool streams out the general log, and filters out queries based on their &lt;em&gt;role&lt;/em&gt; or on their &lt;em&gt;execution plan&lt;/em&gt;.&lt;/p&gt;
&lt;p&gt;To work at all, it must enable the general log. Moreover, it directs the general log to log table. Mind that this makes for a performance impact, which is why the tool auto-terminates and restores original log settings (default is &lt;strong&gt;1&lt;/strong&gt; minute, configurable). It&#39;s really not a tool you should keep running for days. But during the few moments it runs, it will:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Routinely rotate the &lt;strong&gt;mysql.general_log&lt;/strong&gt; table so that it doesn&#39;t fill up&lt;/li&gt;
&lt;li&gt;Examine entries found in the general log&lt;/li&gt;
&lt;li&gt;Cross reference entries to the PROCESSLIST so as to deduce database context (&lt;a href=&#34;http://bugs.mysql.com/bug.php?id=52554&#34;&gt;bug #52554&lt;/a&gt;)&lt;/li&gt;
&lt;li&gt;If required and appropriate, evaluate a query&#39;s execution plan&lt;/li&gt;
&lt;li&gt;Decide whether to dump each entry based on filtering rules&lt;/li&gt;
&lt;/ul&gt;
&lt;h4&gt;Filtering rules&lt;/h4&gt;
&lt;p&gt;Filtering rules are passed as command line options. At current, only one filtering rule applies (if more than one specified only one is used, so no point in passing more than one). Some of the rules are:&lt;!--more--&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;filter-connection&lt;/strong&gt;: only log connect/quit entries&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;filter-explain-fullscan&lt;/strong&gt;: only log full table scans&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;filter-explain-temporary&lt;/strong&gt;: only log queries which create implicit temporary tables&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;filter-explain-rows-exceed&lt;/strong&gt;: only log queries where more than &lt;strong&gt;X&lt;/strong&gt; number of rows are being accessed on some table (estimated)&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;filter-explain-total-rows-exceed&lt;/strong&gt;: only log queries where more than &lt;strong&gt;X&lt;/strong&gt; number of rows are accessed on all tables combined (estimated, with possibly incorrect numbers on some queries)&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;filter-explain-key&lt;/strong&gt;: only log queries using a specific index. This feature somewhat overlaps with Maatkit&#39;s &lt;em&gt;mk-index-usage&lt;/em&gt; (read &lt;a href=&#34;http://www.mysqlperformanceblog.com/2010/11/11/advanced-index-analysis-with-mk-index-usage/&#34;&gt;announcement&lt;/a&gt;).&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;filter-explain-contains&lt;/strong&gt;: a general purpose &lt;em&gt;grep&lt;/em&gt; on the execution plan. Log queries where the execution plan contains &lt;em&gt;some text&lt;/em&gt;.&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;There are other filters, and I will possibly add more in due time.&lt;/p&gt;
&lt;p&gt;Here are a couple cases I used &lt;em&gt;oak-hook-general-log&lt;/em&gt; for:&lt;/p&gt;
&lt;h4&gt;Use case: temporary tables&lt;/h4&gt;
&lt;p&gt;I have a server with this alarming chart (courtesy &lt;a href=&#34;http://code.openark.org/forge/mycheckpoint&#34;&gt;mycheckpoint&lt;/a&gt;) of temporary tables:&lt;/p&gt;
&lt;blockquote&gt;
&lt;pre /&gt;&lt;img class=&#34;alignnone&#34; title=&#34;Created tmp tables per second&#34; src=&#34;/blog/blog/assets/chart?cht=lc&amp;amp;chs=370x180&amp;amp;chts=303030,12&amp;amp;chtt=Latest+24+hours:+Dec+9,+06:30++-++Dec+10,+06:30&amp;amp;chf=c,s,ffffff&amp;amp;chdl=created_tmp_tables_psec|created_tmp_disk_tables_psec&amp;amp;chdlp=b&amp;amp;chco=ff8c00,4682b4&amp;amp;chd=s:yzzy02zzz100zzz0rv9zz0zyzyz0yy2xz1t11xzztz0xr1xt2tz07vwzz100100z31z111yz1vzzzzz1zs80r902s1111010y20z03z11487zz011z11011002w0q5rxxz0y00z0s02xy1yy0,gggfghggfgggghhgYekhhghhhhhghfjghhdihfhgdghgZhgcicihpcehhhhhhhifkigjihghjehgiigjgYqiYqgiaihiifkhekhfijgiihhggggggggggfhgghffZoYgggggggggdihfggghg&amp;amp;chxt=x,y&amp;amp;chxr=1,0,35.060000&amp;amp;chxl=0:||08:00||+||12:00||+||16:00||+||20:00||+||00:00||+||04:00||+|&amp;amp;chxs=0,505050,10,0,lt&amp;amp;chg=4.17,25,1,2,2.08,0&amp;amp;chxp=0,2.08,6.25,10.42,14.59,18.76,22.93,27.10,31.27,35.44,39.61,43.78,47.95,52.12,56.29,60.46,64.63,68.80,72.97,77.14,81.31,85.48,89.65,93.82,97.99&amp;amp;tsstart=2010-12-09+06:30:00&amp;amp;tsstep=600&#34; alt=&#34;&#34; width=&#34;370&#34; height=&#34;180&#34; /&gt;

&lt;/blockquote&gt;
What could possibly create &lt;strong&gt;30&lt;/strong&gt; temporary tables per second on average?

The slow log produced nothing helpful, even with &lt;strong&gt;log-queries-not-using-indexes&lt;/strong&gt; enabled. There were a lot of queries not using indexes there, but nothing at these numbers. With:
&lt;blockquote&gt;
&lt;pre&gt;oak-hook-general-log --filter-explain-temporary&lt;/pre&gt;
&lt;/blockquote&gt;
&lt;p&gt;enabled for &lt;strong&gt;1&lt;/strong&gt; minute, nothing came out. Weird. Enabled for &lt;strong&gt;5&lt;/strong&gt; minutes, I got one entry. Turned out a scheduled script, acting once per &lt;strong&gt;5&lt;/strong&gt; minutes, was making a single complicated query involving many nested views, which accounted for some &lt;em&gt;hundreds&lt;/em&gt; of temporary tables created. All of them very small, query time was very fast. There is no temporary tables problem with this server, case closed.&lt;/p&gt;
&lt;h4&gt;Use case: connections&lt;/h4&gt;
&lt;p&gt;A server had issues with some exceptions being thrown on the client side. There was a large number of new connections created per second although the client was using a connection pool. Suspecting the pool didn&#39;t work well, I issued:&lt;/p&gt;
&lt;blockquote&gt;
&lt;pre&gt;oak-hook-general-log --filter-connect&lt;/pre&gt;
&lt;/blockquote&gt;
&lt;p&gt;The pool was working well, all right. No entries for that client were recorder in &lt;strong&gt;1&lt;/strong&gt; minute of testing. However, it turned out some old script was flooding the MySQL server with requests, every second. The log showed root@somehost, and sure enough, the script was disabled. Exceptions were due to another reason; it was good to eliminate a suspect.&lt;/p&gt;
&lt;p&gt;Some of the tool&#39;s use case is relatively easy to solve with tail, grep &amp;amp; awk; others are not. I am using it more and more often, and find it to make significant shortcuts in tracking down queries.&lt;/p&gt;
&lt;h4&gt;Get it&lt;/h4&gt;
&lt;p&gt;Download the tool as part of &lt;em&gt;openark kit&lt;/em&gt;: access the &lt;a href=&#34;http://code.google.com/p/openarkkit/&#34;&gt;openark kit project page&lt;/a&gt;.&lt;/p&gt;
&lt;p&gt;Or get the &lt;a href=&#34;http://openarkkit.googlecode.com/svn/trunk/openarkkit/src/oak/oak-hook-general-log.py&#34;&gt;source code&lt;/a&gt; directly.&lt;/p&gt;
&lt;p&gt;Feedback is most welcome.&lt;/p&gt;</description>
    </item>
    
  </channel>
</rss>