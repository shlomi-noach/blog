<!DOCTYPE html>
<html lang="en">

<head>
  <meta http-equiv="content-type" content="text/html; charset=utf-8">
  <meta name="viewport" content="width=device-width, initial-scale=1.0">
  <meta name="description" content="">
  <meta name="generator" content="Hugo 0.16" />

  <title>Tokudb &middot; code.openark.org</title>

  
  
  <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/pure/0.6.0/pure-min.css">

  <!--[if lte IE 8]>
  <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/pure/0.6.0/grids-responsive-old-ie-min.css">
  <![endif]-->
  <!--[if gt IE 8]><!-->
  <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/pure/0.6.0/grids-responsive-min.css">
  <!--<![endif]-->

  <!--[if lte IE 8]>
  <link rel="stylesheet" href="/css/side-menu-old-ie.css">
  <![endif]-->
  <!--[if gt IE 8]><!-->
  <link rel="stylesheet" href="/blog/css/side-menu.css">
  <!--<![endif]-->

  <link rel="stylesheet" href="/blog/css/blackburn.css">

  
  <link rel="stylesheet" href="https://maxcdn.bootstrapcdn.com/font-awesome/4.5.0/css/font-awesome.min.css">

  
  <link href="https://fonts.googleapis.com/css?family=Raleway" rel="stylesheet" type="text/css">

  
  
  <link rel="alternate" type="application/rss+xml" title="code.openark.org" href="/blog/tags/tokudb/index.xml" />
  

  
  <link rel="stylesheet" href="//cdnjs.cloudflare.com/ajax/libs/highlight.js/9.1.0/styles/androidstudio.min.css">
  <script src="//cdnjs.cloudflare.com/ajax/libs/highlight.js/9.1.0/highlight.min.js"></script>
  <script>hljs.initHighlightingOnLoad();</script>
  

  <link rel="shortcut icon" href="/blogimg/favicon.ico" type="image/x-icon" />

  
  

</head>


<body>
<div id="layout">

  
<a href="#menu" id="menuLink" class="menu-link">
  
  <span></span>
</a>
<div id="menu">

  

  <a class="pure-menu-heading brand" href="/blog">openark.org</a>


  <div class="pure-menu">
    <ul class="pure-menu-list">
      
      
        <li class="pure-menu-item">
          <a class="pure-menu-link" href="/blog/"><i class='fa fa-home fa-fw'></i>Home</a>
      
        </li>
      
      
        <li class="pure-menu-item">
          <a class="pure-menu-link" href="/blog/post/"><i class='fa fa-list fa-fw'></i>Posts</a>
      
        </li>
      
      
        <li class="pure-menu-item">
          <a class="pure-menu-link" href="/blog/page/about"><i class='fa fa-user fa-fw'></i>About</a>
      
        </li>
      
      
      <li class="pure-menu-item">
        <a class="pure-menu-link" href="/blog/tags/tokudb/index.xml"><i class="fa fa-rss fa-fw"></i>RSS</a>
      </li>
      
    </ul>
  </div>

  <div class="pure-menu social">
  <ul class="pure-menu-list">
    <li class="pure-menu-item">
      <a class="pure-menu-link">
        Shlomi Noach
        
          <div class="avatar-container">
        	  <div class="avatar-img-border">
                <img class="avatar-img" src="/blog/images/shlomi-noach.png" alt="code.openark.org" />
        	  </div>
        	</div>
        
      </a>
    </li>

    
    <li class="pure-menu-item">
      <a class="pure-menu-link" href="https://github.com/shlomi-noach" target="_blank"><i class="fa fa-github-square fa-fw"></i>GitHub</a>
    </li>
    

    

    
    <li class="pure-menu-item">
      <a class="pure-menu-link" href="https://twitter.com/ShlomiNoach" target="_blank"><i class="fa fa-twitter-square fa-fw"></i>Twitter</a>
    </li>
    

    

    

    

    

    

    

    

    

    

    

    

    

    

    
    <li class="pure-menu-item">
      <a class="pure-menu-link" href="https://linkedin.com/in/shlominoach" target="_blank"><i class="fa fa-linkedin-square fa-fw"></i>LinkedIn</a>
    </li>
    

    

    

    

    

    

    

    

    

    

    

    

    

    

    

  </ul>
</div>





  <div>
  <div class="small-print">
    <small>&copy; 2016. All rights reserved.</small>
  </div>
  <div class="small-print">
    <small>Built with&nbsp;<a href="https://gohugo.io/" target="_blank">Hugo</a></small>
    <small>Theme&nbsp;<a href="https://github.com/yoshiharuyamashita/blackburn" target="_blank">Blackburn</a></small>
  </div>
</div>

</div>


  <div id="main">


<div class="header">
  <h1>Tokudb</h1>
</div>

<div class="content">
  
    <article>
  <header>
    <h2><a href="/blog/2015/04/18/percona-live-2015-reflections/">Percona Live 2015: Reflections</a></h2>

    <div class="post-meta">

  <div>

    <time>18 Apr 2015</time>
  </div>

  

  

  <div>
    
      
      
        <span>
          
            <a class="post-taxonomy-category" href="/blogcategories/mysql">MySQL</a>
          
        </span>
      
    

    
      
      
        <span>
          <i class="fa fa-tags fa-fw"></i>
          
            <a class="post-taxonomy-tag" href="/blogtags/opinions">Opinions</a>&nbsp;&#47;
          
            <a class="post-taxonomy-tag" href="/blogtags/perconalive">PerconaLive</a>&nbsp;&#47;
          
            <a class="post-taxonomy-tag" href="/blogtags/secondary">secondary</a>&nbsp;&#47;
          
            <a class="post-taxonomy-tag" href="/blogtags/tokudb">TokuDB</a>
          
        </span>
      
    
  </div>

</div>


  </header>

  <p>
  Some personal reflections on PerconaLive 2015: Percona acquires Tokutek Well done! Tokutek develops the TokuDB storage engine for MySQL and TokuMX engine for MongoDB. I will discuss the MySQL aspect only. TokuDB was released as open source in 2013. It has attained a lot of traction and I have used it myself for some time. I met issues with locking or otherwise operational difficulties which I reported, and otherwise was fascinated by such features as great compression, online schema changes, and more.
  </p>

  
  <footer>
    <a href="/blog/2015/04/18/percona-live-2015-reflections/">Read more<i class="fa fa-angle-double-right fa-fw"></i></a>
  </footer>
  
</article>

  
    <article>
  <header>
    <h2><a href="/blog/2013/10/23/tokudb-configuration-variables-of-interest/">TokuDB configuration variables of interest</a></h2>

    <div class="post-meta">

  <div>

    <time>23 Oct 2013</time>
  </div>

  

  

  <div>
    
      
      
        <span>
          
            <a class="post-taxonomy-category" href="/blogcategories/mysql">MySQL</a>
          
        </span>
      
    

    
      
      
        <span>
          <i class="fa fa-tags fa-fw"></i>
          
            <a class="post-taxonomy-tag" href="/blogtags/configuration">Configuration</a>&nbsp;&#47;
          
            <a class="post-taxonomy-tag" href="/blogtags/innodb">InnoDB</a>&nbsp;&#47;
          
            <a class="post-taxonomy-tag" href="/blogtags/performance">Performance</a>&nbsp;&#47;
          
            <a class="post-taxonomy-tag" href="/blogtags/tokudb">TokuDB</a>
          
        </span>
      
    
  </div>

</div>


  </header>

  <p>
  <p><p>During our experiments I came upon a few TokuDB variables of interest; if you are using TokuDB you might want to look into these:</p>
<ul>
<li>
<h4>tokudb_analyze_time</h4>
</li>
</ul>
<p style="padding-left: 30px;">This is a boundary on the number of seconds an <strong>ANALYZE TABLE</strong> will operate on each index on each partition on a TokuDB table.</p>
<p style="padding-left: 30px;">That is, if <strong>tokudb_analyze_time = 5</strong>, and your table has <strong>4</strong> indexes (including <strong>PRIMARY</strong>) and <strong>7</strong> partitions, then the total runtime is limited to <strong>5*4*7 = 140</strong> seconds.</p>
<p style="padding-left: 30px;">Default in <strong>7.1.0</strong>: <strong>5</strong> seconds</p>
<ul>
<li>
<h4>tokudb_cache_size</h4>
</li>
</ul>
<p style="padding-left: 30px;">Similar to <strong>innodb_buffer_pool_size</strong>, this variable sets the amount of memory allocated by TokuDB for caching pages. Like InnoDB the table is clustered within the index, so the cache includes pages for both indexes and data.</p>
<p style="padding-left: 30px;">Default: <strong>50%</strong> of total memory</p>
<ul>
<li>
<h4>tokudb_directio</h4>
</li>
</ul>
<p style="padding-left: 30px;">Boolean, values are <strong>0/1</strong>. Setting <strong>tokudb_directio = 1</strong> is like specifying <strong>innodb_flush_method = O_DIRECT</strong>. Which in turn means the OS should not cache pages requested by TokuDB. Default: <strong>0</strong>.</p>
<p style="padding-left: 30px;">Now here&rsquo;s the interesting part: we are used to tell InnoDB to get the most memory we can provide (because we want it to cache as much as it can) and to avoid OS caching (because that would mean a page would appear both in the buffer pool and in OS memory, which is a waste). So the following setup is common:</p>

  </p>

  
  <footer>
    <a href="/blog/2013/10/23/tokudb-configuration-variables-of-interest/">Read more<i class="fa fa-angle-double-right fa-fw"></i></a>
  </footer>
  
</article>

  
    <article>
  <header>
    <h2><a href="/blog/2013/10/14/converting-an-olap-database-to-tokudb-part-3-operational-stuff/">Converting an OLAP database to TokuDB, part 3: operational stuff</a></h2>

    <div class="post-meta">

  <div>

    <time>14 Oct 2013</time>
  </div>

  

  

  <div>
    
      
      
        <span>
          
            <a class="post-taxonomy-category" href="/blogcategories/mysql">MySQL</a>
          
        </span>
      
    

    
      
      
        <span>
          <i class="fa fa-tags fa-fw"></i>
          
            <a class="post-taxonomy-tag" href="/blogtags/common_schema">common_schema</a>&nbsp;&#47;
          
            <a class="post-taxonomy-tag" href="/blogtags/innodb">InnoDB</a>&nbsp;&#47;
          
            <a class="post-taxonomy-tag" href="/blogtags/tokudb">TokuDB</a>
          
        </span>
      
    
  </div>

</div>


  </header>

  <p>
  <p><p>This is the third post in a series of posts describing our experience in migrating a large DWH server to TokuDB (see <a href="http://code.openark.org/blog/mysql/converting-an-olap-database-to-tokudb-part-1">1st</a> and <a href="http://code.openark.org/blog/mysql/converting-an-olap-database-to-tokudb-part-2-the-process-of-migration">2nd</a> parts). This post discusses operations; namely ALTER TABLE operations in TokuDB. We ran into quite a few use cases by this time that we can shed light on.</p>
<p>Quick recap: we&rsquo;ve altered one of out DWH slaves to TokuDB, with the goal of migrating most of out servers, including the master, to TokuDB.</p>
<h4>Adding an index</h4>
<p>Shortly after migrating our server to TokuDB we noticed an unreasonably disproportionate slave lag on our TokuDB slave (red line in chart below) as compared to other slaves.</p>
<blockquote><a href="http://code.openark.org/blog/wp-content/uploads/2013/09/tokudb-slave-lag.png"><img alt="tokudb-slave-lag" src="/blog/assets/tokudb-slave-lag.png" width="700" height="329" /></a></blockquote>
<p>Quick investigation led to the fact that, coincidentally, a manual heavy-duty operation was just taking place, which updated some year&rsquo;s worth of data retroactively. OK, but why so slow on TokuDB? Another quick investigation led to an apples vs. oranges problem: as depicted in <a href="http://code.openark.org/blog/mysql/converting-an-olap-database-to-tokudb-part-1">part 1</a>, our original setup included MONTHly partitioning on our larger tables, whereas we could not do the same in TokuDB, where we settled for YEARly partitioning.</p>
<p>The heavy-duty operation included a query that was relying on the MONTHly partitioning to do reasonable pruning: a <strong>WHERE</strong> condition on a date column did the right partition pruning; but where on InnoDB that would filter <strong>1</strong> month&rsquo;s worth of data, on TokuDB it would filter <strong>1</strong> <em>year</em>.</p>
<p>Wasn&rsquo;t it suggested that TokuDB has online table operations? I decided to give it a shot, and add a proper index on our date column (I actually created a compound index, but irrelevant).</p>
<p>It took <strong>13</strong> minutes to add an index on a <strong>1GB</strong> TokuDB table (approx. <strong>20GB</strong> InnoDB uncompressed equivalent):</p>
<ul>
<li>The <strong>ALTER</strong> was non blocking: table was unlocked at that duration</li>
<li>The client issuing the <strong>ALTER</strong> <em>was</em> blocked (I thought it would happen completely in the background) &ndash; but who cares?</li>
<li>I would say <strong>13</strong> minutes is fast</li>
</ul>
<p>Not surprisingly adding the index eliminated the problem altogether.</p>
<h4>Modifying a PRIMARY KEY</h4>
<p>It was suggested by our DBA that there was a long time standing need to modify our <strong>PRIMARY KEY</strong>. It was impossible to achieve with our InnoDB setup (not enough disk space for the operation, would take weeks to complete if we did have the disk space). Would it be possible to modify our TokuDB tables? On some of our medium-sized tables we issued an <strong>ALTER</strong> of the form:</p>

  </p>

  
  <footer>
    <a href="/blog/2013/10/14/converting-an-olap-database-to-tokudb-part-3-operational-stuff/">Read more<i class="fa fa-angle-double-right fa-fw"></i></a>
  </footer>
  
</article>

  
    <article>
  <header>
    <h2><a href="/blog/2013/09/09/converting-an-olap-database-to-tokudb-part-2-the-process-of-migration/">Converting an OLAP database to TokuDB, part 2: the process of migration</a></h2>

    <div class="post-meta">

  <div>

    <time>09 Sep 2013</time>
  </div>

  

  

  <div>
    
      
      
        <span>
          
            <a class="post-taxonomy-category" href="/blogcategories/mysql">MySQL</a>
          
        </span>
      
    

    
      
      
        <span>
          <i class="fa fa-tags fa-fw"></i>
          
            <a class="post-taxonomy-tag" href="/blogtags/common_schema">common_schema</a>&nbsp;&#47;
          
            <a class="post-taxonomy-tag" href="/blogtags/percona-toolkit">Percona Toolkit</a>&nbsp;&#47;
          
            <a class="post-taxonomy-tag" href="/blogtags/tokudb">TokuDB</a>
          
        </span>
      
    
  </div>

</div>


  </header>

  <p>
  <p><p>This is a second in a series of posts describing our experience in migrating a large DWH server to TokuDB. This post discusses the process of migration itself.</p>
<p>As a quick recap (<a href="http://code.openark.org/blog/mysql/converting-an-olap-database-to-tokudb-part-1">read part 1 here</a>), we have a <strong>2TB</strong> compressed InnoDB (<strong>4TB</strong> uncompressed) based DWH server. Space is running low, and we&rsquo;re looking at TokuDB for answers. Early experiments show that TokuDB&rsquo;s compression could make a good impact on disk space usage. I&rsquo;m still not discussing performance &ndash; keeping this till later post.</p>
<p>Those with weak hearts can skip right to the end, where we finally have a complete conversion. You can also peek at the very end to find out how much <strong>4TB</strong> uncompressed InnoDB data is worth in TokuDB. But you might want to read through. The process was not smooth, and not as expected (it&rsquo;s a war story thing). Throughout the migration we got a lot of insight on TokuDB&rsquo;s behaviour, limitations, conveniences, inconveniences and more.</p>
<p>Disclosure: I have no personal interests and no company interests; throughout the process we were in touch with Tokutek engineers, getting free, friendly &amp; professional advice and providing with input of our own. Most of this content has already been presented to Tokutek throughout the process. TokuDB is open source and free to use, though commercial license is also available.</p>
<h4>How do you convert 4TB worth of data to TokuDB?</h4>
<p>Obviously one table at a time. But we had another restriction: you may recall I took a live slave for the migration process. And we wanted to end the process with a live slave. So the restriction was: keep it replicating!</p>
<p>How easy would that be? Based on our initial tests, I extrapolated over <strong>20</strong> days of conversion from InnoDB to TokuDB. Even with one table at a time, our largest table was expected to convert in some <strong>12-14</strong> days. Can we retain <strong>14</strong> days of binary logs on a server already running low on disk space? If only I knew then what I know today :)</p>

  </p>

  
  <footer>
    <a href="/blog/2013/09/09/converting-an-olap-database-to-tokudb-part-2-the-process-of-migration/">Read more<i class="fa fa-angle-double-right fa-fw"></i></a>
  </footer>
  
</article>

  
    <article>
  <header>
    <h2><a href="/blog/2013/09/03/converting-an-olap-database-to-tokudb-part-1/">Converting an OLAP database to TokuDB, part 1</a></h2>

    <div class="post-meta">

  <div>

    <time>03 Sep 2013</time>
  </div>

  

  

  <div>
    
      
      
        <span>
          
            <a class="post-taxonomy-category" href="/blogcategories/mysql">MySQL</a>
          
        </span>
      
    

    
      
      
        <span>
          <i class="fa fa-tags fa-fw"></i>
          
            <a class="post-taxonomy-tag" href="/blogtags/common_schema">common_schema</a>&nbsp;&#47;
          
            <a class="post-taxonomy-tag" href="/blogtags/compression">compression</a>&nbsp;&#47;
          
            <a class="post-taxonomy-tag" href="/blogtags/innodb">InnoDB</a>&nbsp;&#47;
          
            <a class="post-taxonomy-tag" href="/blogtags/open-source">Open Source</a>&nbsp;&#47;
          
            <a class="post-taxonomy-tag" href="/blogtags/performance">Performance</a>&nbsp;&#47;
          
            <a class="post-taxonomy-tag" href="/blogtags/queryscript">QueryScript</a>&nbsp;&#47;
          
            <a class="post-taxonomy-tag" href="/blogtags/tokudb">TokuDB</a>
          
        </span>
      
    
  </div>

</div>


  </header>

  <p>
  <p><p>This is the first in a series of posts describing my impressions of converting a large OLAP server to TokuDB. There&rsquo;s a lot to tell, and the experiment is not yet complete, so this is an ongoing blogging. In this post I will describe the case at hand and out initial reasons for looking at TokuDB.</p>
<p>Disclosure: I have no personal interests and no company interests; we did get friendly, useful and free advice from Tokutek engineers. TokuDB is open source and free to use, though commercial license is also available.</p>
<h4>The case at hand</h4>
<p>We have a large and fast growing DWH MySQL setup. This data warehouse is but one component in a larger data setup, which includes Hadoop, Cassandra and more. For online dashboards and most reports, MySQL is our service. We populate this warehouse mainly via Hive/Hadoop. Thus, we have an hourly load of data from Hive, as well as a larger daily load.</p>
<p>There are some updates on the data, but the majority of writes are just <strong>mysqlimport</strong>s of Hive queries.</p>
<p>Usage of this database is OLAP: no concurrency issues here; we have some should-be-fast-running queries issued by our dashboards, as well as ok-to-run-longer queries issued for reports.</p>
<p>Our initial and most burning trouble is with size. Today we use <strong>COMPRESSED</strong> InnoDB tables (<strong>KEY_BLOCK_SIZE</strong> is default, i.e. <strong>8</strong>). Our data volume sums right now at about <strong>2TB</strong>. I happen to know this translates as <strong>4TB</strong> of uncompressed data.</p>
<p>However growth of data is accelerating. A year ago we would capture a dozen GB per month. Today it is a <strong>100GB</strong> per month, and by the end of this year it may climb to <strong>150GB</strong> per month or more.</p>
<p>Our data is not sharded. We have a simple replication topology of some <strong>6</strong> servers. Machines are quite generous as detailed following. And yet, we will be running out of resources shortly: disk space (total <strong>2.7TB</strong>) is now running low and is expected to run out in about six months. One of my first tasks in Outbrain is to find a solution to our DWH growth problem. The solution could be sharding; it could be a commercial DWH product; anything that works.</p>

  </p>

  
  <footer>
    <a href="/blog/2013/09/03/converting-an-olap-database-to-tokudb-part-1/">Read more<i class="fa fa-angle-double-right fa-fw"></i></a>
  </footer>
  
</article>

  
    <article>
  <header>
    <h2><a href="/blog/2013/06/05/converting-compressed-innodb-tables-to-tokudb-7-0-1/">Converting compressed InnoDB tables to TokuDB 7.0.1</a></h2>

    <div class="post-meta">

  <div>

    <time>05 Jun 2013</time>
  </div>

  

  

  <div>
    
      
      
        <span>
          
            <a class="post-taxonomy-category" href="/blogcategories/mysql">MySQL</a>
          
        </span>
      
    

    
      
      
        <span>
          <i class="fa fa-tags fa-fw"></i>
          
            <a class="post-taxonomy-tag" href="/blogtags/innodb">InnoDB</a>&nbsp;&#47;
          
            <a class="post-taxonomy-tag" href="/blogtags/tokudb">TokuDB</a>
          
        </span>
      
    
  </div>

</div>


  </header>

  <p>
  <p><p>Or: how to make it work in TokuDB version <strong>7.0.1</strong>. This is a follow up on a <a href="https://groups.google.com/forum/?fromgroups=#!topic/tokudb-user/hLlHwlp2AL0">discussion on the tokudb-user group</a>.</p>
<h4>Background</h4>
<p>I wanted to test TokuDB&rsquo;s compression. I took a staging machine of mine, with production data, and migrated it from <strong>Percona Server 5.5</strong> To <strong>MariaDB 5.5+TokuDB 7.0.1</strong>. Migration went well, no problems.</p>
<p>To my surprise, when I converted tables from InnoDB to TokuDB, I saw an <em>increase</em> in table file size on disk. As explained by Tim Callaghan, this was due to TokuDB interpreting my compressed table&rsquo;s <strong>&ldquo;KEY_BLOCK_SIZE=4&rdquo;</strong> as an instruction for TokuDB&rsquo;s page size. TokuDB should be using <strong>4MB</strong> block size, but thinks it&rsquo;s being instructed to use <strong>4KB</strong>. Problem is, you <a href="http://bugs.mysql.com/bug.php?id=67727">can&rsquo;t get rid of table options</a>. When one converts a table to InnoDB in <strong>ROW_FORMAT=COMPACT</strong>, or even to MyISAM, the <strong>KEY_BLOCK_SIZE</strong> option keeps lurking in the dark.</p>
<p>So until this is hopefully resolved in TokuDB&rsquo;s next version, here&rsquo;s a way to go around the problem.</p>

  </p>

  
  <footer>
    <a href="/blog/2013/06/05/converting-compressed-innodb-tables-to-tokudb-7-0-1/">Read more<i class="fa fa-angle-double-right fa-fw"></i></a>
  </footer>
  
</article>

  
    <article>
  <header>
    <h2><a href="/blog/2013/05/02/on-compiling-tokudb-from-source/">On compiling TokuDB from source</a></h2>

    <div class="post-meta">

  <div>

    <time>02 May 2013</time>
  </div>

  

  

  <div>
    
      
      
        <span>
          
            <a class="post-taxonomy-category" href="/blogcategories/mysql">MySQL</a>
          
        </span>
      
    

    
      
      
        <span>
          <i class="fa fa-tags fa-fw"></i>
          
            <a class="post-taxonomy-tag" href="/blogtags/tokudb">TokuDB</a>
          
        </span>
      
    
  </div>

</div>


  </header>

  <p>
  <p><p>Sharing my experience of compiling TokuDB + MariaDB <strong>5.5</strong>. Why? Because I must have <a href="http://code.openark.org/blog/mysql/sphinx-sphinx_snippets-mysql-5-5">this patch</a> to Sphinx <strong>2.0.4</strong>.</p>
<p><strong>Note</strong>: I was using what seems to be the &ldquo;old&rdquo; method of compiling; quoting Leif Walsh:</p>
<blockquote>&hellip; We are looking at deprecating that method of building (MariaDB source plus binary fractal tree handlerton).  It only really needed to be that complex when we were closed source.</blockquote>
<p>I also tried the &ldquo;new&rdquo; method of compiling, which I couldn&rsquo;t work out.</p>
<p>Here&rsquo;s how it goes: TokuDB is newly <a href="http://www.tokutek.com/2013/04/announcing-tokudb-v7-open-source-and-more/">released as open source</a>. As such, it got a lot of attention, many downloads and I hope it will succeed.</p>
<p>However as stable as the product may be, it&rsquo;s new to open source, which means anyone compiling it from source is an early adopter (at least for the compilation process).</p>
<h4>Installation process</h4>
<p>This is an unorthodox, and actually weird process. See <a href="http://www.tokutek.com/wp-content/uploads/2013/04/mariadb-5.5.30-tokudb-7.0.1-users-guide.pdf">section 6 on the Tokutek docs</a>. In order to compile the project you must download:</p>
<ul>
<li>The source code tar.gz</li>
<li><em>And</em> the binary (?!) tar.gz</li>
<li>And the binary checksum</li>
<li>And the Tokutek patches</li>
<li>And the patches checksum</p>

  </p>

  
  <footer>
    <a href="/blog/2013/05/02/on-compiling-tokudb-from-source/">Read more<i class="fa fa-angle-double-right fa-fw"></i></a>
  </footer>
  
</article>

  
</div>

</div>
</div>
<script src="/blogjs/ui.js"></script>


<script>
  (function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
  (i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
  m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
  })(window,document,'script','//www.google-analytics.com/analytics.js','ga');

  ga('create', 'Your Google Analytics tracking ID', 'auto');
  ga('send', 'pageview');

</script>



</body>
</html>
